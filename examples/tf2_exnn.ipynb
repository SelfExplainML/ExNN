{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from exnn import ExNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simu_loader(generator, datanum, testnum, noise_sigma):\n",
    "    def wrapper(rand_seed=0):\n",
    "        return generator(datanum, testnum=testnum, noise_sigma=noise_sigma, rand_seed=rand_seed)\n",
    "    return wrapper\n",
    "\n",
    "def mse(label, pred, scaler):\n",
    "    pred = scaler.inverse_transform(pred.reshape([-1, 1]))\n",
    "    label = scaler.inverse_transform(label.reshape([-1, 1]))\n",
    "    return np.mean((pred - label)**2)\n",
    "\n",
    "\n",
    "def metric_wrapper(metric, scaler):\n",
    "    def wrapper(label, pred):\n",
    "        return metric(label, pred, scaler=scaler)\n",
    "    return wrapper\n",
    "\n",
    "def data_generator1(datanum, testnum=10000, noise_sigma=1, rand_seed=0):\n",
    "    \n",
    "    corr = 0.5\n",
    "    np.random.seed(rand_seed)\n",
    "    proj_matrix = np.zeros((10, 4))\n",
    "    proj_matrix[:7, 0] = np.array([1,0,0,0,0,0,0])\n",
    "    proj_matrix[:7, 1] = np.array([0,1,0,0,0,0,0])\n",
    "    proj_matrix[:7, 2] = np.array([0,0,0.5,0.5,0,0,0])\n",
    "    proj_matrix[:7, 3] = np.array([0,0,0,0,0.2,0.3,0.5])\n",
    "    u = np.random.uniform(-1, 1, [datanum + testnum, 1])\n",
    "    t = np.sqrt(corr / (1 - corr))\n",
    "    x = np.zeros((datanum + testnum, 10))\n",
    "    for i in range(10):\n",
    "        x[:, i:i + 1] = (np.random.uniform(-1, 1, [datanum + testnum, 1]) + t * u) / (1 + t)\n",
    "\n",
    "    y = np.reshape(2 * np.dot(x, proj_matrix[:, 0]) + 0.2 * np.exp(-4 * np.dot(x, proj_matrix[:, 1])) + \\\n",
    "                   3 * (np.dot(x, proj_matrix[:, 2]))**2 + 2.5 * np.sin(np.pi * np.dot(x, proj_matrix[:, 3])), [-1, 1]) + \\\n",
    "              noise_sigma * np.random.normal(0, 1, [datanum + testnum, 1])\n",
    "    \n",
    "    task_type = \"Regression\"\n",
    "    meta_info = {\"X1\":{\"type\":\"continuous\"},\n",
    "             \"X2\":{\"type\":\"continuous\"},\n",
    "             \"X3\":{\"type\":\"continuous\"},\n",
    "             \"X4\":{\"type\":\"continuous\"},\n",
    "             \"X5\":{\"type\":\"continuous\"},\n",
    "             \"X6\":{\"type\":\"continuous\"},\n",
    "             \"X7\":{\"type\":\"continuous\"},\n",
    "             \"X8\":{\"type\":\"continuous\"},\n",
    "             \"X9\":{\"type\":\"continuous\"},\n",
    "             \"X10\":{\"type\":\"continuous\"},\n",
    "             \"Y\":{\"type\":\"target\"}}\n",
    "    for i, (key, item) in enumerate(meta_info.items()):\n",
    "        if item['type'] == \"target\":\n",
    "            sy = MinMaxScaler((-1, 1))\n",
    "            y = sy.fit_transform(y)\n",
    "            meta_info[key][\"scaler\"] = sy\n",
    "        elif item['type'] == \"categorical\":\n",
    "            enc = OrdinalEncoder()\n",
    "            enc.fit(x[:,[i]])\n",
    "            ordinal_feature = enc.transform(x[:,[i]])\n",
    "            x[:,[i]] = ordinal_feature\n",
    "            meta_info[key][\"values\"] = enc.categories_[0].tolist()\n",
    "        else:\n",
    "            sx = MinMaxScaler((-1, 1))\n",
    "            x[:,[i]] = sx.fit_transform(x[:,[i]])\n",
    "            meta_info[key][\"scaler\"] = sx\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=testnum, random_state=rand_seed)\n",
    "    return train_x, test_x, train_y, test_y, task_type, meta_info, metric_wrapper(mse, sy)\n",
    "\n",
    "train_x, test_x, train_y, test_y, task_type, meta_info, get_metric = data_generator1(datanum=10000, testnum=10000,\n",
    "                                                                                     noise_sigma=1, rand_seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search in Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exnn_repeat(folder, name, data_generator,\n",
    "                  subnet_num=10,\n",
    "                  subnet_arch=[10, 6],\n",
    "                  task=\"Regression\",\n",
    "                  activation_func=tf.tanh,\n",
    "                  lr_bp=0.001,\n",
    "                  lr_cl=0.1,\n",
    "                  l1_proj=0.001,\n",
    "                  l1_subnet=0.001,\n",
    "                  smooth_lambda=0.00001,\n",
    "                  batch_size=1000,\n",
    "                  training_epochs=5000,\n",
    "                  tuning_epochs=500,\n",
    "                  beta_threshold=0.05,\n",
    "                  verbose=False,\n",
    "                  val_ratio=0.2,\n",
    "                  early_stop_thres=1000,\n",
    "                  rand_seed=0):\n",
    "\n",
    "    train_x, test_x, train_y, test_y, task_type, meta_info, get_metric = data_generator(rand_seed)\n",
    "\n",
    "    input_num = train_x.shape[1]\n",
    "    model = ExNN(meta_info=meta_info,\n",
    "                   subnet_num=min(10, input_num),\n",
    "                   subnet_arch=subnet_arch,\n",
    "                   task_type=task_type,\n",
    "                   activation_func=tf.tanh,\n",
    "                   batch_size=min(batch_size, int(train_x.shape[0] * 0.2)),\n",
    "                   training_epochs=training_epochs,\n",
    "                   lr_bp=lr_bp,\n",
    "                   lr_cl=lr_cl,\n",
    "                   beta_threshold=beta_threshold,\n",
    "                   tuning_epochs=tuning_epochs,\n",
    "                   l1_proj=l1_proj,\n",
    "                   l1_subnet=l1_subnet,\n",
    "                   smooth_lambda=smooth_lambda,\n",
    "                   verbose=verbose,\n",
    "                   val_ratio=val_ratio,\n",
    "                   early_stop_thres=early_stop_thres)\n",
    "    model.fit(train_x, train_y)\n",
    "    model.visualize(folder=folder,\n",
    "                    name=name,\n",
    "                    save_png=True,\n",
    "                    save_eps=True)\n",
    "\n",
    "    tr_x = train_x[model.tr_idx]\n",
    "    tr_y = train_y[model.tr_idx]\n",
    "    val_x = train_x[model.val_idx]\n",
    "    val_y = train_y[model.val_idx]\n",
    "\n",
    "    pred_train = model.predict(tr_x)\n",
    "    pred_val = model.predict(val_x)\n",
    "    pred_test = model.predict(test_x)\n",
    "\n",
    "    stat = np.hstack([np.round(get_metric(tr_y, pred_train), 5),\\\n",
    "                np.round(get_metric(val_y, pred_val), 5),\\\n",
    "                np.round(get_metric(test_y, pred_test), 5)])\n",
    "    res_stat = pd.DataFrame(stat.reshape([1, -1]), columns=['train_metric', 'val_metric', \"test_metric\"])\n",
    "    res_stat[\"Subnet_Number\"] = min(input_num, 10)\n",
    "    res_stat[\"lr_BP\"] = lr_bp\n",
    "    res_stat[\"lr_CL\"] = lr_cl\n",
    "    res_stat[\"L1_Penalty_Proj\"] = l1_proj\n",
    "    res_stat[\"L1_Penalty_Subnet\"] = l1_subnet\n",
    "    res_stat[\"Smooth_labmda\"] = smooth_lambda\n",
    "    res_stat[\"Training_Epochs\"] = training_epochs\n",
    "    return res_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_metric</th>\n",
       "      <th>val_metric</th>\n",
       "      <th>test_metric</th>\n",
       "      <th>Subnet_Number</th>\n",
       "      <th>lr_BP</th>\n",
       "      <th>lr_CL</th>\n",
       "      <th>L1_Penalty_Proj</th>\n",
       "      <th>L1_Penalty_Subnet</th>\n",
       "      <th>Smooth_labmda</th>\n",
       "      <th>Training_Epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00967</td>\n",
       "      <td>1.03250</td>\n",
       "      <td>0.99072</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00974</td>\n",
       "      <td>1.03406</td>\n",
       "      <td>0.99062</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.01211</td>\n",
       "      <td>1.03646</td>\n",
       "      <td>0.99345</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.01224</td>\n",
       "      <td>1.04256</td>\n",
       "      <td>1.00040</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.01944</td>\n",
       "      <td>1.04368</td>\n",
       "      <td>1.00114</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.03299</td>\n",
       "      <td>1.06288</td>\n",
       "      <td>1.01930</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.03497</td>\n",
       "      <td>1.06415</td>\n",
       "      <td>1.01893</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.02672</td>\n",
       "      <td>1.06472</td>\n",
       "      <td>1.01462</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.03830</td>\n",
       "      <td>1.07028</td>\n",
       "      <td>1.02324</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.05309</td>\n",
       "      <td>1.07877</td>\n",
       "      <td>1.02796</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.04798</td>\n",
       "      <td>1.08099</td>\n",
       "      <td>1.03936</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.04855</td>\n",
       "      <td>1.08210</td>\n",
       "      <td>1.03294</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.05840</td>\n",
       "      <td>1.08329</td>\n",
       "      <td>1.03335</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.06883</td>\n",
       "      <td>1.10155</td>\n",
       "      <td>1.04572</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.11808</td>\n",
       "      <td>1.14639</td>\n",
       "      <td>1.10058</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.13623</td>\n",
       "      <td>1.17733</td>\n",
       "      <td>1.11430</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.13927</td>\n",
       "      <td>1.18258</td>\n",
       "      <td>1.11860</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.14840</td>\n",
       "      <td>1.18510</td>\n",
       "      <td>1.12545</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.15495</td>\n",
       "      <td>1.19012</td>\n",
       "      <td>1.13702</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.15690</td>\n",
       "      <td>1.19142</td>\n",
       "      <td>1.12922</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.16452</td>\n",
       "      <td>1.19852</td>\n",
       "      <td>1.14755</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.15942</td>\n",
       "      <td>1.19863</td>\n",
       "      <td>1.13210</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.16154</td>\n",
       "      <td>1.20617</td>\n",
       "      <td>1.13507</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.17340</td>\n",
       "      <td>1.22100</td>\n",
       "      <td>1.14451</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.17855</td>\n",
       "      <td>1.22708</td>\n",
       "      <td>1.14906</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_metric  val_metric  test_metric  Subnet_Number  lr_BP  lr_CL  \\\n",
       "0       1.00967     1.03250      0.99072             10  0.001    0.1   \n",
       "0       1.00974     1.03406      0.99062             10  0.001    0.1   \n",
       "0       1.01211     1.03646      0.99345             10  0.001    0.1   \n",
       "0       1.01224     1.04256      1.00040             10  0.001    0.1   \n",
       "0       1.01944     1.04368      1.00114             10  0.001    0.1   \n",
       "0       1.03299     1.06288      1.01930             10  0.001    0.1   \n",
       "0       1.03497     1.06415      1.01893             10  0.001    0.1   \n",
       "0       1.02672     1.06472      1.01462             10  0.001    0.1   \n",
       "0       1.03830     1.07028      1.02324             10  0.001    0.1   \n",
       "0       1.05309     1.07877      1.02796             10  0.001    0.1   \n",
       "0       1.04798     1.08099      1.03936             10  0.001    0.1   \n",
       "0       1.04855     1.08210      1.03294             10  0.001    0.1   \n",
       "0       1.05840     1.08329      1.03335             10  0.001    0.1   \n",
       "0       1.06883     1.10155      1.04572             10  0.001    0.1   \n",
       "0       1.11808     1.14639      1.10058             10  0.001    0.1   \n",
       "0       1.13623     1.17733      1.11430             10  0.001    0.1   \n",
       "0       1.13927     1.18258      1.11860             10  0.001    0.1   \n",
       "0       1.14840     1.18510      1.12545             10  0.001    0.1   \n",
       "0       1.15495     1.19012      1.13702             10  0.001    0.1   \n",
       "0       1.15690     1.19142      1.12922             10  0.001    0.1   \n",
       "0       1.16452     1.19852      1.14755             10  0.001    0.1   \n",
       "0       1.15942     1.19863      1.13210             10  0.001    0.1   \n",
       "0       1.16154     1.20617      1.13507             10  0.001    0.1   \n",
       "0       1.17340     1.22100      1.14451             10  0.001    0.1   \n",
       "0       1.17855     1.22708      1.14906             10  0.001    0.1   \n",
       "\n",
       "   L1_Penalty_Proj  L1_Penalty_Subnet  Smooth_labmda  Training_Epochs  \n",
       "0         0.000316           0.010000       0.000001            10000  \n",
       "0         0.000100           0.010000       0.000001            10000  \n",
       "0         0.000316           0.003162       0.000001            10000  \n",
       "0         0.000100           0.000100       0.000001            10000  \n",
       "0         0.000100           0.003162       0.000001            10000  \n",
       "0         0.000316           0.001000       0.000001            10000  \n",
       "0         0.000316           0.000316       0.000001            10000  \n",
       "0         0.000100           0.001000       0.000001            10000  \n",
       "0         0.000316           0.000100       0.000001            10000  \n",
       "0         0.001000           0.010000       0.000001            10000  \n",
       "0         0.000100           0.000316       0.000001            10000  \n",
       "0         0.001000           0.000100       0.000001            10000  \n",
       "0         0.001000           0.003162       0.000001            10000  \n",
       "0         0.001000           0.000316       0.000001            10000  \n",
       "0         0.001000           0.001000       0.000001            10000  \n",
       "0         0.003162           0.010000       0.000001            10000  \n",
       "0         0.010000           0.000100       0.000001            10000  \n",
       "0         0.010000           0.003162       0.000001            10000  \n",
       "0         0.003162           0.000100       0.000001            10000  \n",
       "0         0.010000           0.010000       0.000001            10000  \n",
       "0         0.003162           0.001000       0.000001            10000  \n",
       "0         0.010000           0.001000       0.000001            10000  \n",
       "0         0.010000           0.000316       0.000001            10000  \n",
       "0         0.003162           0.000316       0.000001            10000  \n",
       "0         0.003162           0.003162       0.000001            10000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = Parallel(n_jobs=10)(delayed(exnn_repeat)(folder=\"./results/S1_exnn/\",\n",
    "                      name=str(i + 1).zfill(2) + \"_\" + str(j + 1).zfill(2),\n",
    "                      data_generator=simu_loader(data_generator1, 10000, 10000, 1),\n",
    "                      task=task_type,\n",
    "                      subnet_arch=[10, 6],\n",
    "                      beta_threshold=0.05,\n",
    "                      l1_proj=10**(-2 - i*0.5),\n",
    "                      l1_subnet=10**(-2 - j*0.5),\n",
    "                      smooth_lambda=10**(-5 - k),\n",
    "                      training_epochs=10000,\n",
    "                      lr_bp=0.001,\n",
    "                      lr_cl=0.1,\n",
    "                      batch_size=1000,\n",
    "                      early_stop_thres=500,\n",
    "                      tuning_epochs=100,\n",
    "                      rand_seed=0) for i in range(5) for j in range(5) for k in [1])\n",
    "exnn_stat_all = pd.concat(cv_results)\n",
    "exnn_stat_all.sort_values(\"val_metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_l1_prob = exnn_stat_all.sort_values(\"val_metric\").loc[:,\"L1_Penalty_Proj\"].iloc[0]\n",
    "best_l1_subnet = exnn_stat_all.sort_values(\"val_metric\").loc[:,\"L1_Penalty_Subnet\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ExNN(meta_info=meta_info,\n",
    "               subnet_num=10,\n",
    "               subnet_arch=[10, 6],\n",
    "               task_type=task_type,\n",
    "               activation_func=tf.tanh,\n",
    "               batch_size=min(1000, int(train_x.shape[0] * 0.2)),\n",
    "               training_epochs=10000,\n",
    "               lr_bp=0.001,\n",
    "               lr_cl=0.1,\n",
    "               beta_threshold=0.05,\n",
    "               tuning_epochs=100,\n",
    "               l1_proj=best_l1_prob,\n",
    "               l1_subnet=best_l1_subnet,\n",
    "               smooth_lambda=10**(-6),\n",
    "               verbose=False,\n",
    "               val_ratio=0.2,\n",
    "               early_stop_thres=500)\n",
    "\n",
    "model.fit(train_x, train_y)\n",
    "model.visualize(\"./\", \"exnn_demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_pred = model.predict(train_x[model.tr_idx]) \n",
    "val_pred = model.predict(train_x[model.val_idx]) \n",
    "pred_test = model.predict(test_x)\n",
    "\n",
    "mse_stat = np.hstack([np.round(get_metric(train_y[model.tr_idx], tr_pred), 5),\\\n",
    "                      np.round(get_metric(train_y[model.val_idx], val_pred),5),\\\n",
    "                      np.round(get_metric(test_y, pred_test),5)])\n",
    "print(mse_stat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf2)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
