{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T06:15:33.201823Z",
     "start_time": "2020-07-21T06:13:37.923721Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training.\n",
      "Training epoch: 1, train loss: 0.15248, val loss: 0.15325\n",
      "Training epoch: 2, train loss: 0.13367, val loss: 0.13557\n",
      "Training epoch: 3, train loss: 0.11582, val loss: 0.11764\n",
      "Training epoch: 4, train loss: 0.09918, val loss: 0.10050\n",
      "Training epoch: 5, train loss: 0.08543, val loss: 0.08640\n",
      "Training epoch: 6, train loss: 0.07818, val loss: 0.07827\n",
      "Training epoch: 7, train loss: 0.06875, val loss: 0.06865\n",
      "Training epoch: 8, train loss: 0.06563, val loss: 0.06523\n",
      "Training epoch: 9, train loss: 0.05757, val loss: 0.05775\n",
      "Training epoch: 10, train loss: 0.05770, val loss: 0.05791\n",
      "Training epoch: 11, train loss: 0.04955, val loss: 0.05008\n",
      "Training epoch: 12, train loss: 0.04903, val loss: 0.04945\n",
      "Training epoch: 13, train loss: 0.04844, val loss: 0.04874\n",
      "Training epoch: 14, train loss: 0.04466, val loss: 0.04488\n",
      "Training epoch: 15, train loss: 0.04277, val loss: 0.04296\n",
      "Training epoch: 16, train loss: 0.03933, val loss: 0.03972\n",
      "Training epoch: 17, train loss: 0.04030, val loss: 0.04039\n",
      "Training epoch: 18, train loss: 0.03780, val loss: 0.03791\n",
      "Training epoch: 19, train loss: 0.03727, val loss: 0.03747\n",
      "Training epoch: 20, train loss: 0.03549, val loss: 0.03573\n",
      "Training epoch: 21, train loss: 0.03513, val loss: 0.03545\n",
      "Training epoch: 22, train loss: 0.03354, val loss: 0.03372\n",
      "Training epoch: 23, train loss: 0.03204, val loss: 0.03219\n",
      "Training epoch: 24, train loss: 0.03263, val loss: 0.03277\n",
      "Training epoch: 25, train loss: 0.03101, val loss: 0.03101\n",
      "Training epoch: 26, train loss: 0.03086, val loss: 0.03092\n",
      "Training epoch: 27, train loss: 0.03000, val loss: 0.03007\n",
      "Training epoch: 28, train loss: 0.02992, val loss: 0.03000\n",
      "Training epoch: 29, train loss: 0.02911, val loss: 0.02925\n",
      "Training epoch: 30, train loss: 0.02797, val loss: 0.02806\n",
      "Training epoch: 31, train loss: 0.02812, val loss: 0.02838\n",
      "Training epoch: 32, train loss: 0.02673, val loss: 0.02695\n",
      "Training epoch: 33, train loss: 0.02774, val loss: 0.02781\n",
      "Training epoch: 34, train loss: 0.02628, val loss: 0.02649\n",
      "Training epoch: 35, train loss: 0.02623, val loss: 0.02635\n",
      "Training epoch: 36, train loss: 0.02549, val loss: 0.02578\n",
      "Training epoch: 37, train loss: 0.02553, val loss: 0.02563\n",
      "Training epoch: 38, train loss: 0.02468, val loss: 0.02498\n",
      "Training epoch: 39, train loss: 0.02540, val loss: 0.02566\n",
      "Training epoch: 40, train loss: 0.02479, val loss: 0.02508\n",
      "Training epoch: 41, train loss: 0.02460, val loss: 0.02492\n",
      "Training epoch: 42, train loss: 0.02424, val loss: 0.02450\n",
      "Training epoch: 43, train loss: 0.02567, val loss: 0.02605\n",
      "Training epoch: 44, train loss: 0.02370, val loss: 0.02399\n",
      "Training epoch: 45, train loss: 0.02404, val loss: 0.02429\n",
      "Training epoch: 46, train loss: 0.02341, val loss: 0.02370\n",
      "Training epoch: 47, train loss: 0.02293, val loss: 0.02330\n",
      "Training epoch: 48, train loss: 0.02338, val loss: 0.02367\n",
      "Training epoch: 49, train loss: 0.02346, val loss: 0.02388\n",
      "Training epoch: 50, train loss: 0.02285, val loss: 0.02318\n",
      "Training epoch: 51, train loss: 0.02293, val loss: 0.02328\n",
      "Training epoch: 52, train loss: 0.02311, val loss: 0.02353\n",
      "Training epoch: 53, train loss: 0.02336, val loss: 0.02372\n",
      "Training epoch: 54, train loss: 0.02251, val loss: 0.02283\n",
      "Training epoch: 55, train loss: 0.02229, val loss: 0.02269\n",
      "Training epoch: 56, train loss: 0.02248, val loss: 0.02274\n",
      "Training epoch: 57, train loss: 0.02236, val loss: 0.02270\n",
      "Training epoch: 58, train loss: 0.02234, val loss: 0.02260\n",
      "Training epoch: 59, train loss: 0.02227, val loss: 0.02268\n",
      "Training epoch: 60, train loss: 0.02227, val loss: 0.02253\n",
      "Training epoch: 61, train loss: 0.02176, val loss: 0.02218\n",
      "Training epoch: 62, train loss: 0.02179, val loss: 0.02214\n",
      "Training epoch: 63, train loss: 0.02194, val loss: 0.02234\n",
      "Training epoch: 64, train loss: 0.02170, val loss: 0.02212\n",
      "Training epoch: 65, train loss: 0.02156, val loss: 0.02192\n",
      "Training epoch: 66, train loss: 0.02155, val loss: 0.02194\n",
      "Training epoch: 67, train loss: 0.02151, val loss: 0.02190\n",
      "Training epoch: 68, train loss: 0.02176, val loss: 0.02225\n",
      "Training epoch: 69, train loss: 0.02162, val loss: 0.02209\n",
      "Training epoch: 70, train loss: 0.02210, val loss: 0.02251\n",
      "Training epoch: 71, train loss: 0.02157, val loss: 0.02207\n",
      "Training epoch: 72, train loss: 0.02201, val loss: 0.02233\n",
      "Training epoch: 73, train loss: 0.02172, val loss: 0.02213\n",
      "Training epoch: 74, train loss: 0.02128, val loss: 0.02171\n",
      "Training epoch: 75, train loss: 0.02127, val loss: 0.02170\n",
      "Training epoch: 76, train loss: 0.02196, val loss: 0.02235\n",
      "Training epoch: 77, train loss: 0.02139, val loss: 0.02185\n",
      "Training epoch: 78, train loss: 0.02117, val loss: 0.02163\n",
      "Training epoch: 79, train loss: 0.02113, val loss: 0.02145\n",
      "Training epoch: 80, train loss: 0.02107, val loss: 0.02149\n",
      "Training epoch: 81, train loss: 0.02117, val loss: 0.02167\n",
      "Training epoch: 82, train loss: 0.02104, val loss: 0.02153\n",
      "Training epoch: 83, train loss: 0.02119, val loss: 0.02169\n",
      "Training epoch: 84, train loss: 0.02120, val loss: 0.02164\n",
      "Training epoch: 85, train loss: 0.02086, val loss: 0.02128\n",
      "Training epoch: 86, train loss: 0.02103, val loss: 0.02152\n",
      "Training epoch: 87, train loss: 0.02097, val loss: 0.02140\n",
      "Training epoch: 88, train loss: 0.02114, val loss: 0.02166\n",
      "Training epoch: 89, train loss: 0.02094, val loss: 0.02137\n",
      "Training epoch: 90, train loss: 0.02103, val loss: 0.02148\n",
      "Training epoch: 91, train loss: 0.02078, val loss: 0.02123\n",
      "Training epoch: 92, train loss: 0.02069, val loss: 0.02117\n",
      "Training epoch: 93, train loss: 0.02075, val loss: 0.02113\n",
      "Training epoch: 94, train loss: 0.02070, val loss: 0.02115\n",
      "Training epoch: 95, train loss: 0.02103, val loss: 0.02139\n",
      "Training epoch: 96, train loss: 0.02168, val loss: 0.02211\n",
      "Training epoch: 97, train loss: 0.02069, val loss: 0.02112\n",
      "Training epoch: 98, train loss: 0.02099, val loss: 0.02142\n",
      "Training epoch: 99, train loss: 0.02063, val loss: 0.02106\n",
      "Training epoch: 100, train loss: 0.02091, val loss: 0.02142\n",
      "Training epoch: 101, train loss: 0.02058, val loss: 0.02108\n",
      "Training epoch: 102, train loss: 0.02081, val loss: 0.02137\n",
      "Training epoch: 103, train loss: 0.02073, val loss: 0.02113\n",
      "Training epoch: 104, train loss: 0.02057, val loss: 0.02107\n",
      "Training epoch: 105, train loss: 0.02045, val loss: 0.02098\n",
      "Training epoch: 106, train loss: 0.02070, val loss: 0.02109\n",
      "Training epoch: 107, train loss: 0.02077, val loss: 0.02126\n",
      "Training epoch: 108, train loss: 0.02040, val loss: 0.02090\n",
      "Training epoch: 109, train loss: 0.02043, val loss: 0.02088\n",
      "Training epoch: 110, train loss: 0.02051, val loss: 0.02102\n",
      "Training epoch: 111, train loss: 0.02036, val loss: 0.02085\n",
      "Training epoch: 112, train loss: 0.02072, val loss: 0.02112\n",
      "Training epoch: 113, train loss: 0.02076, val loss: 0.02123\n",
      "Training epoch: 114, train loss: 0.02029, val loss: 0.02074\n",
      "Training epoch: 115, train loss: 0.02036, val loss: 0.02094\n",
      "Training epoch: 116, train loss: 0.02026, val loss: 0.02067\n",
      "Training epoch: 117, train loss: 0.02057, val loss: 0.02102\n",
      "Training epoch: 118, train loss: 0.02042, val loss: 0.02089\n",
      "Training epoch: 119, train loss: 0.02053, val loss: 0.02092\n",
      "Training epoch: 120, train loss: 0.02030, val loss: 0.02073\n",
      "Training epoch: 121, train loss: 0.02057, val loss: 0.02104\n",
      "Training epoch: 122, train loss: 0.02018, val loss: 0.02074\n",
      "Training epoch: 123, train loss: 0.02116, val loss: 0.02158\n",
      "Training epoch: 124, train loss: 0.02046, val loss: 0.02100\n",
      "Training epoch: 125, train loss: 0.02084, val loss: 0.02151\n",
      "Training epoch: 126, train loss: 0.02116, val loss: 0.02184\n",
      "Training epoch: 127, train loss: 0.02028, val loss: 0.02078\n",
      "Training epoch: 128, train loss: 0.02006, val loss: 0.02061\n",
      "Training epoch: 129, train loss: 0.02056, val loss: 0.02110\n",
      "Training epoch: 130, train loss: 0.02039, val loss: 0.02098\n",
      "Training epoch: 131, train loss: 0.02034, val loss: 0.02081\n",
      "Training epoch: 132, train loss: 0.02032, val loss: 0.02083\n",
      "Training epoch: 133, train loss: 0.02000, val loss: 0.02053\n",
      "Training epoch: 134, train loss: 0.02005, val loss: 0.02063\n",
      "Training epoch: 135, train loss: 0.02015, val loss: 0.02071\n",
      "Training epoch: 136, train loss: 0.02004, val loss: 0.02058\n",
      "Training epoch: 137, train loss: 0.02041, val loss: 0.02100\n",
      "Training epoch: 138, train loss: 0.01996, val loss: 0.02046\n",
      "Training epoch: 139, train loss: 0.01989, val loss: 0.02045\n",
      "Training epoch: 140, train loss: 0.02012, val loss: 0.02056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 141, train loss: 0.02019, val loss: 0.02076\n",
      "Training epoch: 142, train loss: 0.01987, val loss: 0.02043\n",
      "Training epoch: 143, train loss: 0.01997, val loss: 0.02046\n",
      "Training epoch: 144, train loss: 0.01988, val loss: 0.02035\n",
      "Training epoch: 145, train loss: 0.01988, val loss: 0.02046\n",
      "Training epoch: 146, train loss: 0.01991, val loss: 0.02040\n",
      "Training epoch: 147, train loss: 0.01995, val loss: 0.02058\n",
      "Training epoch: 148, train loss: 0.02026, val loss: 0.02087\n",
      "Training epoch: 149, train loss: 0.01972, val loss: 0.02024\n",
      "Training epoch: 150, train loss: 0.02097, val loss: 0.02165\n",
      "Training epoch: 151, train loss: 0.01993, val loss: 0.02054\n",
      "Training epoch: 152, train loss: 0.02037, val loss: 0.02087\n",
      "Training epoch: 153, train loss: 0.01970, val loss: 0.02024\n",
      "Training epoch: 154, train loss: 0.02011, val loss: 0.02082\n",
      "Training epoch: 155, train loss: 0.01970, val loss: 0.02024\n",
      "Training epoch: 156, train loss: 0.01988, val loss: 0.02050\n",
      "Training epoch: 157, train loss: 0.01963, val loss: 0.02016\n",
      "Training epoch: 158, train loss: 0.01995, val loss: 0.02059\n",
      "Training epoch: 159, train loss: 0.01971, val loss: 0.02024\n",
      "Training epoch: 160, train loss: 0.02027, val loss: 0.02081\n",
      "Training epoch: 161, train loss: 0.01959, val loss: 0.02017\n",
      "Training epoch: 162, train loss: 0.01970, val loss: 0.02024\n",
      "Training epoch: 163, train loss: 0.01978, val loss: 0.02046\n",
      "Training epoch: 164, train loss: 0.01968, val loss: 0.02032\n",
      "Training epoch: 165, train loss: 0.01962, val loss: 0.02018\n",
      "Training epoch: 166, train loss: 0.01969, val loss: 0.02037\n",
      "Training epoch: 167, train loss: 0.01964, val loss: 0.02014\n",
      "Training epoch: 168, train loss: 0.01977, val loss: 0.02027\n",
      "Training epoch: 169, train loss: 0.01996, val loss: 0.02058\n",
      "Training epoch: 170, train loss: 0.01975, val loss: 0.02024\n",
      "Training epoch: 171, train loss: 0.01984, val loss: 0.02056\n",
      "Training epoch: 172, train loss: 0.01955, val loss: 0.02017\n",
      "Training epoch: 173, train loss: 0.01968, val loss: 0.02026\n",
      "Training epoch: 174, train loss: 0.01960, val loss: 0.02010\n",
      "Training epoch: 175, train loss: 0.02007, val loss: 0.02085\n",
      "Training epoch: 176, train loss: 0.01938, val loss: 0.01997\n",
      "Training epoch: 177, train loss: 0.02073, val loss: 0.02118\n",
      "Training epoch: 178, train loss: 0.01971, val loss: 0.02031\n",
      "Training epoch: 179, train loss: 0.01969, val loss: 0.02022\n",
      "Training epoch: 180, train loss: 0.01938, val loss: 0.01998\n",
      "Training epoch: 181, train loss: 0.01933, val loss: 0.01998\n",
      "Training epoch: 182, train loss: 0.01950, val loss: 0.01999\n",
      "Training epoch: 183, train loss: 0.01977, val loss: 0.02028\n",
      "Training epoch: 184, train loss: 0.01961, val loss: 0.02027\n",
      "Training epoch: 185, train loss: 0.01964, val loss: 0.02039\n",
      "Training epoch: 186, train loss: 0.01928, val loss: 0.01990\n",
      "Training epoch: 187, train loss: 0.01976, val loss: 0.02051\n",
      "Training epoch: 188, train loss: 0.01936, val loss: 0.02002\n",
      "Training epoch: 189, train loss: 0.01941, val loss: 0.02006\n",
      "Training epoch: 190, train loss: 0.01927, val loss: 0.01981\n",
      "Training epoch: 191, train loss: 0.02006, val loss: 0.02060\n",
      "Training epoch: 192, train loss: 0.01964, val loss: 0.02017\n",
      "Training epoch: 193, train loss: 0.01946, val loss: 0.02000\n",
      "Training epoch: 194, train loss: 0.01938, val loss: 0.01990\n",
      "Training epoch: 195, train loss: 0.01924, val loss: 0.01993\n",
      "Training epoch: 196, train loss: 0.01952, val loss: 0.02023\n",
      "Training epoch: 197, train loss: 0.02008, val loss: 0.02054\n",
      "Training epoch: 198, train loss: 0.01918, val loss: 0.01973\n",
      "Training epoch: 199, train loss: 0.01936, val loss: 0.01988\n",
      "Training epoch: 200, train loss: 0.01926, val loss: 0.01999\n",
      "Training epoch: 201, train loss: 0.01936, val loss: 0.01991\n",
      "Training epoch: 202, train loss: 0.01965, val loss: 0.02043\n",
      "Training epoch: 203, train loss: 0.01957, val loss: 0.02026\n",
      "Training epoch: 204, train loss: 0.01907, val loss: 0.01960\n",
      "Training epoch: 205, train loss: 0.01902, val loss: 0.01965\n",
      "Training epoch: 206, train loss: 0.01931, val loss: 0.01991\n",
      "Training epoch: 207, train loss: 0.01904, val loss: 0.01968\n",
      "Training epoch: 208, train loss: 0.01895, val loss: 0.01959\n",
      "Training epoch: 209, train loss: 0.01893, val loss: 0.01959\n",
      "Training epoch: 210, train loss: 0.01917, val loss: 0.01975\n",
      "Training epoch: 211, train loss: 0.01912, val loss: 0.01977\n",
      "Training epoch: 212, train loss: 0.02022, val loss: 0.02107\n",
      "Training epoch: 213, train loss: 0.01902, val loss: 0.01972\n",
      "Training epoch: 214, train loss: 0.01885, val loss: 0.01945\n",
      "Training epoch: 215, train loss: 0.01887, val loss: 0.01949\n",
      "Training epoch: 216, train loss: 0.01922, val loss: 0.01976\n",
      "Training epoch: 217, train loss: 0.01913, val loss: 0.01985\n",
      "Training epoch: 218, train loss: 0.01909, val loss: 0.01972\n",
      "Training epoch: 219, train loss: 0.01888, val loss: 0.01954\n",
      "Training epoch: 220, train loss: 0.01918, val loss: 0.01995\n",
      "Training epoch: 221, train loss: 0.02130, val loss: 0.02227\n",
      "Training epoch: 222, train loss: 0.01902, val loss: 0.01972\n",
      "Training epoch: 223, train loss: 0.01939, val loss: 0.02019\n",
      "Training epoch: 224, train loss: 0.01899, val loss: 0.01974\n",
      "Training epoch: 225, train loss: 0.01913, val loss: 0.01988\n",
      "Training epoch: 226, train loss: 0.01902, val loss: 0.01974\n",
      "Training epoch: 227, train loss: 0.01873, val loss: 0.01948\n",
      "Training epoch: 228, train loss: 0.01870, val loss: 0.01933\n",
      "Training epoch: 229, train loss: 0.01917, val loss: 0.01987\n",
      "Training epoch: 230, train loss: 0.01929, val loss: 0.02003\n",
      "Training epoch: 231, train loss: 0.01867, val loss: 0.01932\n",
      "Training epoch: 232, train loss: 0.01863, val loss: 0.01927\n",
      "Training epoch: 233, train loss: 0.01853, val loss: 0.01920\n",
      "Training epoch: 234, train loss: 0.01895, val loss: 0.01945\n",
      "Training epoch: 235, train loss: 0.01878, val loss: 0.01928\n",
      "Training epoch: 236, train loss: 0.01855, val loss: 0.01920\n",
      "Training epoch: 237, train loss: 0.01872, val loss: 0.01943\n",
      "Training epoch: 238, train loss: 0.01887, val loss: 0.01958\n",
      "Training epoch: 239, train loss: 0.01864, val loss: 0.01940\n",
      "Training epoch: 240, train loss: 0.01857, val loss: 0.01915\n",
      "Training epoch: 241, train loss: 0.01868, val loss: 0.01933\n",
      "Training epoch: 242, train loss: 0.01838, val loss: 0.01907\n",
      "Training epoch: 243, train loss: 0.01854, val loss: 0.01917\n",
      "Training epoch: 244, train loss: 0.01868, val loss: 0.01940\n",
      "Training epoch: 245, train loss: 0.01930, val loss: 0.02020\n",
      "Training epoch: 246, train loss: 0.01875, val loss: 0.01955\n",
      "Training epoch: 247, train loss: 0.01869, val loss: 0.01949\n",
      "Training epoch: 248, train loss: 0.01834, val loss: 0.01901\n",
      "Training epoch: 249, train loss: 0.01852, val loss: 0.01929\n",
      "Training epoch: 250, train loss: 0.01872, val loss: 0.01923\n",
      "Training epoch: 251, train loss: 0.01874, val loss: 0.01943\n",
      "Training epoch: 252, train loss: 0.01843, val loss: 0.01900\n",
      "Training epoch: 253, train loss: 0.01838, val loss: 0.01896\n",
      "Training epoch: 254, train loss: 0.01856, val loss: 0.01921\n",
      "Training epoch: 255, train loss: 0.01835, val loss: 0.01915\n",
      "Training epoch: 256, train loss: 0.01815, val loss: 0.01885\n",
      "Training epoch: 257, train loss: 0.01887, val loss: 0.01971\n",
      "Training epoch: 258, train loss: 0.01812, val loss: 0.01883\n",
      "Training epoch: 259, train loss: 0.01826, val loss: 0.01885\n",
      "Training epoch: 260, train loss: 0.01826, val loss: 0.01888\n",
      "Training epoch: 261, train loss: 0.01807, val loss: 0.01877\n",
      "Training epoch: 262, train loss: 0.01858, val loss: 0.01915\n",
      "Training epoch: 263, train loss: 0.01931, val loss: 0.02029\n",
      "Training epoch: 264, train loss: 0.01809, val loss: 0.01878\n",
      "Training epoch: 265, train loss: 0.01811, val loss: 0.01874\n",
      "Training epoch: 266, train loss: 0.01822, val loss: 0.01900\n",
      "Training epoch: 267, train loss: 0.01831, val loss: 0.01894\n",
      "Training epoch: 268, train loss: 0.01856, val loss: 0.01909\n",
      "Training epoch: 269, train loss: 0.01872, val loss: 0.01945\n",
      "Training epoch: 270, train loss: 0.01791, val loss: 0.01862\n",
      "Training epoch: 271, train loss: 0.01807, val loss: 0.01878\n",
      "Training epoch: 272, train loss: 0.01829, val loss: 0.01888\n",
      "Training epoch: 273, train loss: 0.01803, val loss: 0.01868\n",
      "Training epoch: 274, train loss: 0.01798, val loss: 0.01862\n",
      "Training epoch: 275, train loss: 0.01851, val loss: 0.01919\n",
      "Training epoch: 276, train loss: 0.01792, val loss: 0.01859\n",
      "Training epoch: 277, train loss: 0.01799, val loss: 0.01862\n",
      "Training epoch: 278, train loss: 0.01796, val loss: 0.01860\n",
      "Training epoch: 279, train loss: 0.01776, val loss: 0.01848\n",
      "Training epoch: 280, train loss: 0.01773, val loss: 0.01839\n",
      "Training epoch: 281, train loss: 0.01813, val loss: 0.01881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 282, train loss: 0.01782, val loss: 0.01853\n",
      "Training epoch: 283, train loss: 0.01800, val loss: 0.01867\n",
      "Training epoch: 284, train loss: 0.01795, val loss: 0.01855\n",
      "Training epoch: 285, train loss: 0.01767, val loss: 0.01831\n",
      "Training epoch: 286, train loss: 0.01791, val loss: 0.01875\n",
      "Training epoch: 287, train loss: 0.01810, val loss: 0.01886\n",
      "Training epoch: 288, train loss: 0.01813, val loss: 0.01887\n",
      "Training epoch: 289, train loss: 0.01770, val loss: 0.01835\n",
      "Training epoch: 290, train loss: 0.01797, val loss: 0.01858\n",
      "Training epoch: 291, train loss: 0.01809, val loss: 0.01890\n",
      "Training epoch: 292, train loss: 0.01807, val loss: 0.01889\n",
      "Training epoch: 293, train loss: 0.01761, val loss: 0.01832\n",
      "Training epoch: 294, train loss: 0.01783, val loss: 0.01867\n",
      "Training epoch: 295, train loss: 0.01821, val loss: 0.01909\n",
      "Training epoch: 296, train loss: 0.01758, val loss: 0.01834\n",
      "Training epoch: 297, train loss: 0.01767, val loss: 0.01839\n",
      "Training epoch: 298, train loss: 0.01821, val loss: 0.01882\n",
      "Training epoch: 299, train loss: 0.01768, val loss: 0.01840\n",
      "Training epoch: 300, train loss: 0.01781, val loss: 0.01863\n",
      "Training epoch: 301, train loss: 0.01745, val loss: 0.01820\n",
      "Training epoch: 302, train loss: 0.01812, val loss: 0.01892\n",
      "Training epoch: 303, train loss: 0.01781, val loss: 0.01849\n",
      "Training epoch: 304, train loss: 0.01783, val loss: 0.01868\n",
      "Training epoch: 305, train loss: 0.01794, val loss: 0.01871\n",
      "Training epoch: 306, train loss: 0.01789, val loss: 0.01879\n",
      "Training epoch: 307, train loss: 0.01768, val loss: 0.01844\n",
      "Training epoch: 308, train loss: 0.01787, val loss: 0.01854\n",
      "Training epoch: 309, train loss: 0.01755, val loss: 0.01822\n",
      "Training epoch: 310, train loss: 0.01751, val loss: 0.01820\n",
      "Training epoch: 311, train loss: 0.01760, val loss: 0.01832\n",
      "Training epoch: 312, train loss: 0.01821, val loss: 0.01912\n",
      "Training epoch: 313, train loss: 0.01792, val loss: 0.01856\n",
      "Training epoch: 314, train loss: 0.01727, val loss: 0.01797\n",
      "Training epoch: 315, train loss: 0.01736, val loss: 0.01806\n",
      "Training epoch: 316, train loss: 0.01797, val loss: 0.01862\n",
      "Training epoch: 317, train loss: 0.01771, val loss: 0.01841\n",
      "Training epoch: 318, train loss: 0.01730, val loss: 0.01798\n",
      "Training epoch: 319, train loss: 0.01735, val loss: 0.01811\n",
      "Training epoch: 320, train loss: 0.01729, val loss: 0.01799\n",
      "Training epoch: 321, train loss: 0.01733, val loss: 0.01797\n",
      "Training epoch: 322, train loss: 0.01761, val loss: 0.01829\n",
      "Training epoch: 323, train loss: 0.01815, val loss: 0.01880\n",
      "Training epoch: 324, train loss: 0.01716, val loss: 0.01785\n",
      "Training epoch: 325, train loss: 0.01717, val loss: 0.01795\n",
      "Training epoch: 326, train loss: 0.01716, val loss: 0.01784\n",
      "Training epoch: 327, train loss: 0.01721, val loss: 0.01791\n",
      "Training epoch: 328, train loss: 0.01749, val loss: 0.01815\n",
      "Training epoch: 329, train loss: 0.01712, val loss: 0.01783\n",
      "Training epoch: 330, train loss: 0.01711, val loss: 0.01782\n",
      "Training epoch: 331, train loss: 0.01767, val loss: 0.01841\n",
      "Training epoch: 332, train loss: 0.01762, val loss: 0.01847\n",
      "Training epoch: 333, train loss: 0.01956, val loss: 0.02053\n",
      "Training epoch: 334, train loss: 0.01763, val loss: 0.01820\n",
      "Training epoch: 335, train loss: 0.01785, val loss: 0.01841\n",
      "Training epoch: 336, train loss: 0.01710, val loss: 0.01777\n",
      "Training epoch: 337, train loss: 0.01777, val loss: 0.01856\n",
      "Training epoch: 338, train loss: 0.01817, val loss: 0.01871\n",
      "Training epoch: 339, train loss: 0.01698, val loss: 0.01770\n",
      "Training epoch: 340, train loss: 0.01746, val loss: 0.01815\n",
      "Training epoch: 341, train loss: 0.01880, val loss: 0.01972\n",
      "Training epoch: 342, train loss: 0.01873, val loss: 0.01965\n",
      "Training epoch: 343, train loss: 0.01741, val loss: 0.01814\n",
      "Training epoch: 344, train loss: 0.01760, val loss: 0.01822\n",
      "Training epoch: 345, train loss: 0.01720, val loss: 0.01785\n",
      "Training epoch: 346, train loss: 0.01739, val loss: 0.01819\n",
      "Training epoch: 347, train loss: 0.01748, val loss: 0.01817\n",
      "Training epoch: 348, train loss: 0.01713, val loss: 0.01794\n",
      "Training epoch: 349, train loss: 0.01717, val loss: 0.01794\n",
      "Training epoch: 350, train loss: 0.01690, val loss: 0.01759\n",
      "Training epoch: 351, train loss: 0.01731, val loss: 0.01814\n",
      "Training epoch: 352, train loss: 0.01705, val loss: 0.01781\n",
      "Training epoch: 353, train loss: 0.01743, val loss: 0.01822\n",
      "Training epoch: 354, train loss: 0.01708, val loss: 0.01789\n",
      "Training epoch: 355, train loss: 0.01770, val loss: 0.01835\n",
      "Training epoch: 356, train loss: 0.01746, val loss: 0.01809\n",
      "Training epoch: 357, train loss: 0.01704, val loss: 0.01771\n",
      "Training epoch: 358, train loss: 0.01734, val loss: 0.01810\n",
      "Training epoch: 359, train loss: 0.01726, val loss: 0.01787\n",
      "Training epoch: 360, train loss: 0.01692, val loss: 0.01758\n",
      "Training epoch: 361, train loss: 0.01727, val loss: 0.01806\n",
      "Training epoch: 362, train loss: 0.01717, val loss: 0.01787\n",
      "Training epoch: 363, train loss: 0.01722, val loss: 0.01798\n",
      "Training epoch: 364, train loss: 0.01694, val loss: 0.01774\n",
      "Training epoch: 365, train loss: 0.01697, val loss: 0.01771\n",
      "Training epoch: 366, train loss: 0.01698, val loss: 0.01766\n",
      "Training epoch: 367, train loss: 0.01675, val loss: 0.01750\n",
      "Training epoch: 368, train loss: 0.01699, val loss: 0.01774\n",
      "Training epoch: 369, train loss: 0.01701, val loss: 0.01779\n",
      "Training epoch: 370, train loss: 0.01709, val loss: 0.01768\n",
      "Training epoch: 371, train loss: 0.01708, val loss: 0.01772\n",
      "Training epoch: 372, train loss: 0.01681, val loss: 0.01755\n",
      "Training epoch: 373, train loss: 0.01695, val loss: 0.01767\n",
      "Training epoch: 374, train loss: 0.01697, val loss: 0.01763\n",
      "Training epoch: 375, train loss: 0.01713, val loss: 0.01777\n",
      "Training epoch: 376, train loss: 0.01715, val loss: 0.01784\n",
      "Training epoch: 377, train loss: 0.01669, val loss: 0.01742\n",
      "Training epoch: 378, train loss: 0.01695, val loss: 0.01762\n",
      "Training epoch: 379, train loss: 0.01691, val loss: 0.01768\n",
      "Training epoch: 380, train loss: 0.01682, val loss: 0.01748\n",
      "Training epoch: 381, train loss: 0.01669, val loss: 0.01739\n",
      "Training epoch: 382, train loss: 0.01664, val loss: 0.01729\n",
      "Training epoch: 383, train loss: 0.01722, val loss: 0.01794\n",
      "Training epoch: 384, train loss: 0.01714, val loss: 0.01777\n",
      "Training epoch: 385, train loss: 0.01687, val loss: 0.01754\n",
      "Training epoch: 386, train loss: 0.01811, val loss: 0.01884\n",
      "Training epoch: 387, train loss: 0.01701, val loss: 0.01764\n",
      "Training epoch: 388, train loss: 0.01692, val loss: 0.01760\n",
      "Training epoch: 389, train loss: 0.01680, val loss: 0.01749\n",
      "Training epoch: 390, train loss: 0.01667, val loss: 0.01732\n",
      "Training epoch: 391, train loss: 0.01678, val loss: 0.01745\n",
      "Training epoch: 392, train loss: 0.01670, val loss: 0.01737\n",
      "Training epoch: 393, train loss: 0.01684, val loss: 0.01745\n",
      "Training epoch: 394, train loss: 0.01706, val loss: 0.01780\n",
      "Training epoch: 395, train loss: 0.01690, val loss: 0.01768\n",
      "Training epoch: 396, train loss: 0.01664, val loss: 0.01734\n",
      "Training epoch: 397, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 398, train loss: 0.01778, val loss: 0.01844\n",
      "Training epoch: 399, train loss: 0.01738, val loss: 0.01813\n",
      "Training epoch: 400, train loss: 0.01668, val loss: 0.01742\n",
      "Training epoch: 401, train loss: 0.01670, val loss: 0.01731\n",
      "Training epoch: 402, train loss: 0.01673, val loss: 0.01745\n",
      "Training epoch: 403, train loss: 0.01710, val loss: 0.01778\n",
      "Training epoch: 404, train loss: 0.01650, val loss: 0.01716\n",
      "Training epoch: 405, train loss: 0.01656, val loss: 0.01717\n",
      "Training epoch: 406, train loss: 0.01651, val loss: 0.01717\n",
      "Training epoch: 407, train loss: 0.01671, val loss: 0.01743\n",
      "Training epoch: 408, train loss: 0.01673, val loss: 0.01738\n",
      "Training epoch: 409, train loss: 0.01719, val loss: 0.01792\n",
      "Training epoch: 410, train loss: 0.01669, val loss: 0.01730\n",
      "Training epoch: 411, train loss: 0.01695, val loss: 0.01760\n",
      "Training epoch: 412, train loss: 0.01669, val loss: 0.01735\n",
      "Training epoch: 413, train loss: 0.01682, val loss: 0.01752\n",
      "Training epoch: 414, train loss: 0.01649, val loss: 0.01710\n",
      "Training epoch: 415, train loss: 0.01746, val loss: 0.01815\n",
      "Training epoch: 416, train loss: 0.01670, val loss: 0.01743\n",
      "Training epoch: 417, train loss: 0.01705, val loss: 0.01775\n",
      "Training epoch: 418, train loss: 0.01654, val loss: 0.01716\n",
      "Training epoch: 419, train loss: 0.01676, val loss: 0.01737\n",
      "Training epoch: 420, train loss: 0.01824, val loss: 0.01884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 421, train loss: 0.01682, val loss: 0.01748\n",
      "Training epoch: 422, train loss: 0.01670, val loss: 0.01739\n",
      "Training epoch: 423, train loss: 0.01684, val loss: 0.01747\n",
      "Training epoch: 424, train loss: 0.01662, val loss: 0.01727\n",
      "Training epoch: 425, train loss: 0.01688, val loss: 0.01757\n",
      "Training epoch: 426, train loss: 0.01641, val loss: 0.01703\n",
      "Training epoch: 427, train loss: 0.01650, val loss: 0.01716\n",
      "Training epoch: 428, train loss: 0.01677, val loss: 0.01744\n",
      "Training epoch: 429, train loss: 0.01677, val loss: 0.01750\n",
      "Training epoch: 430, train loss: 0.01828, val loss: 0.01911\n",
      "Training epoch: 431, train loss: 0.01657, val loss: 0.01719\n",
      "Training epoch: 432, train loss: 0.01645, val loss: 0.01707\n",
      "Training epoch: 433, train loss: 0.01660, val loss: 0.01726\n",
      "Training epoch: 434, train loss: 0.01664, val loss: 0.01735\n",
      "Training epoch: 435, train loss: 0.01712, val loss: 0.01777\n",
      "Training epoch: 436, train loss: 0.01638, val loss: 0.01702\n",
      "Training epoch: 437, train loss: 0.01711, val loss: 0.01769\n",
      "Training epoch: 438, train loss: 0.01673, val loss: 0.01728\n",
      "Training epoch: 439, train loss: 0.01658, val loss: 0.01718\n",
      "Training epoch: 440, train loss: 0.01652, val loss: 0.01715\n",
      "Training epoch: 441, train loss: 0.01675, val loss: 0.01745\n",
      "Training epoch: 442, train loss: 0.01672, val loss: 0.01737\n",
      "Training epoch: 443, train loss: 0.01653, val loss: 0.01710\n",
      "Training epoch: 444, train loss: 0.01661, val loss: 0.01727\n",
      "Training epoch: 445, train loss: 0.01717, val loss: 0.01791\n",
      "Training epoch: 446, train loss: 0.01660, val loss: 0.01713\n",
      "Training epoch: 447, train loss: 0.01663, val loss: 0.01732\n",
      "Training epoch: 448, train loss: 0.01650, val loss: 0.01715\n",
      "Training epoch: 449, train loss: 0.01626, val loss: 0.01685\n",
      "Training epoch: 450, train loss: 0.01650, val loss: 0.01707\n",
      "Training epoch: 451, train loss: 0.01688, val loss: 0.01753\n",
      "Training epoch: 452, train loss: 0.01685, val loss: 0.01754\n",
      "Training epoch: 453, train loss: 0.01656, val loss: 0.01715\n",
      "Training epoch: 454, train loss: 0.01715, val loss: 0.01784\n",
      "Training epoch: 455, train loss: 0.01640, val loss: 0.01702\n",
      "Training epoch: 456, train loss: 0.01646, val loss: 0.01706\n",
      "Training epoch: 457, train loss: 0.01729, val loss: 0.01794\n",
      "Training epoch: 458, train loss: 0.01704, val loss: 0.01765\n",
      "Training epoch: 459, train loss: 0.01725, val loss: 0.01781\n",
      "Training epoch: 460, train loss: 0.01703, val loss: 0.01771\n",
      "Training epoch: 461, train loss: 0.01707, val loss: 0.01777\n",
      "Training epoch: 462, train loss: 0.01655, val loss: 0.01710\n",
      "Training epoch: 463, train loss: 0.01632, val loss: 0.01697\n",
      "Training epoch: 464, train loss: 0.01647, val loss: 0.01714\n",
      "Training epoch: 465, train loss: 0.01672, val loss: 0.01729\n",
      "Training epoch: 466, train loss: 0.01643, val loss: 0.01705\n",
      "Training epoch: 467, train loss: 0.01658, val loss: 0.01720\n",
      "Training epoch: 468, train loss: 0.01647, val loss: 0.01707\n",
      "Training epoch: 469, train loss: 0.01713, val loss: 0.01777\n",
      "Training epoch: 470, train loss: 0.01691, val loss: 0.01760\n",
      "Training epoch: 471, train loss: 0.01627, val loss: 0.01692\n",
      "Training epoch: 472, train loss: 0.01703, val loss: 0.01774\n",
      "Training epoch: 473, train loss: 0.01642, val loss: 0.01701\n",
      "Training epoch: 474, train loss: 0.01861, val loss: 0.01919\n",
      "Training epoch: 475, train loss: 0.01683, val loss: 0.01746\n",
      "Training epoch: 476, train loss: 0.01631, val loss: 0.01698\n",
      "Training epoch: 477, train loss: 0.01652, val loss: 0.01718\n",
      "Training epoch: 478, train loss: 0.01642, val loss: 0.01711\n",
      "Training epoch: 479, train loss: 0.01618, val loss: 0.01680\n",
      "Training epoch: 480, train loss: 0.01652, val loss: 0.01711\n",
      "Training epoch: 481, train loss: 0.01625, val loss: 0.01690\n",
      "Training epoch: 482, train loss: 0.01652, val loss: 0.01712\n",
      "Training epoch: 483, train loss: 0.01702, val loss: 0.01779\n",
      "Training epoch: 484, train loss: 0.01647, val loss: 0.01702\n",
      "Training epoch: 485, train loss: 0.01782, val loss: 0.01841\n",
      "Training epoch: 486, train loss: 0.01635, val loss: 0.01699\n",
      "Training epoch: 487, train loss: 0.01656, val loss: 0.01718\n",
      "Training epoch: 488, train loss: 0.01619, val loss: 0.01683\n",
      "Training epoch: 489, train loss: 0.01631, val loss: 0.01704\n",
      "Training epoch: 490, train loss: 0.01761, val loss: 0.01811\n",
      "Training epoch: 491, train loss: 0.01637, val loss: 0.01695\n",
      "Training epoch: 492, train loss: 0.01680, val loss: 0.01741\n",
      "Training epoch: 493, train loss: 0.01646, val loss: 0.01704\n",
      "Training epoch: 494, train loss: 0.01622, val loss: 0.01689\n",
      "Training epoch: 495, train loss: 0.01620, val loss: 0.01678\n",
      "Training epoch: 496, train loss: 0.01649, val loss: 0.01720\n",
      "Training epoch: 497, train loss: 0.01635, val loss: 0.01691\n",
      "Training epoch: 498, train loss: 0.01617, val loss: 0.01680\n",
      "Training epoch: 499, train loss: 0.01618, val loss: 0.01681\n",
      "Training epoch: 500, train loss: 0.01618, val loss: 0.01677\n",
      "Training epoch: 501, train loss: 0.01639, val loss: 0.01700\n",
      "Training epoch: 502, train loss: 0.01611, val loss: 0.01675\n",
      "Training epoch: 503, train loss: 0.01714, val loss: 0.01787\n",
      "Training epoch: 504, train loss: 0.01745, val loss: 0.01808\n",
      "Training epoch: 505, train loss: 0.01727, val loss: 0.01791\n",
      "Training epoch: 506, train loss: 0.01638, val loss: 0.01697\n",
      "Training epoch: 507, train loss: 0.01617, val loss: 0.01673\n",
      "Training epoch: 508, train loss: 0.01654, val loss: 0.01717\n",
      "Training epoch: 509, train loss: 0.01655, val loss: 0.01716\n",
      "Training epoch: 510, train loss: 0.01642, val loss: 0.01705\n",
      "Training epoch: 511, train loss: 0.01623, val loss: 0.01680\n",
      "Training epoch: 512, train loss: 0.01627, val loss: 0.01696\n",
      "Training epoch: 513, train loss: 0.01622, val loss: 0.01687\n",
      "Training epoch: 514, train loss: 0.01619, val loss: 0.01672\n",
      "Training epoch: 515, train loss: 0.01621, val loss: 0.01687\n",
      "Training epoch: 516, train loss: 0.01643, val loss: 0.01707\n",
      "Training epoch: 517, train loss: 0.01621, val loss: 0.01685\n",
      "Training epoch: 518, train loss: 0.01707, val loss: 0.01770\n",
      "Training epoch: 519, train loss: 0.01646, val loss: 0.01705\n",
      "Training epoch: 520, train loss: 0.01620, val loss: 0.01682\n",
      "Training epoch: 521, train loss: 0.01729, val loss: 0.01808\n",
      "Training epoch: 522, train loss: 0.01615, val loss: 0.01671\n",
      "Training epoch: 523, train loss: 0.01620, val loss: 0.01686\n",
      "Training epoch: 524, train loss: 0.01632, val loss: 0.01690\n",
      "Training epoch: 525, train loss: 0.01634, val loss: 0.01699\n",
      "Training epoch: 526, train loss: 0.01604, val loss: 0.01665\n",
      "Training epoch: 527, train loss: 0.01612, val loss: 0.01674\n",
      "Training epoch: 528, train loss: 0.01607, val loss: 0.01663\n",
      "Training epoch: 529, train loss: 0.01613, val loss: 0.01672\n",
      "Training epoch: 530, train loss: 0.01805, val loss: 0.01869\n",
      "Training epoch: 531, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 532, train loss: 0.01640, val loss: 0.01705\n",
      "Training epoch: 533, train loss: 0.01620, val loss: 0.01685\n",
      "Training epoch: 534, train loss: 0.01661, val loss: 0.01732\n",
      "Training epoch: 535, train loss: 0.01666, val loss: 0.01734\n",
      "Training epoch: 536, train loss: 0.01613, val loss: 0.01672\n",
      "Training epoch: 537, train loss: 0.01845, val loss: 0.01910\n",
      "Training epoch: 538, train loss: 0.01617, val loss: 0.01676\n",
      "Training epoch: 539, train loss: 0.01652, val loss: 0.01716\n",
      "Training epoch: 540, train loss: 0.01637, val loss: 0.01702\n",
      "Training epoch: 541, train loss: 0.01660, val loss: 0.01733\n",
      "Training epoch: 542, train loss: 0.01761, val loss: 0.01835\n",
      "Training epoch: 543, train loss: 0.01718, val loss: 0.01793\n",
      "Training epoch: 544, train loss: 0.01716, val loss: 0.01772\n",
      "Training epoch: 545, train loss: 0.01658, val loss: 0.01714\n",
      "Training epoch: 546, train loss: 0.01615, val loss: 0.01682\n",
      "Training epoch: 547, train loss: 0.01606, val loss: 0.01673\n",
      "Training epoch: 548, train loss: 0.01708, val loss: 0.01766\n",
      "Training epoch: 549, train loss: 0.01615, val loss: 0.01676\n",
      "Training epoch: 550, train loss: 0.01612, val loss: 0.01673\n",
      "Training epoch: 551, train loss: 0.01632, val loss: 0.01685\n",
      "Training epoch: 552, train loss: 0.01630, val loss: 0.01696\n",
      "Training epoch: 553, train loss: 0.01600, val loss: 0.01660\n",
      "Training epoch: 554, train loss: 0.01604, val loss: 0.01672\n",
      "Training epoch: 555, train loss: 0.01614, val loss: 0.01673\n",
      "Training epoch: 556, train loss: 0.01623, val loss: 0.01681\n",
      "Training epoch: 557, train loss: 0.01632, val loss: 0.01702\n",
      "Training epoch: 558, train loss: 0.01607, val loss: 0.01668\n",
      "Training epoch: 559, train loss: 0.01639, val loss: 0.01693\n",
      "Training epoch: 560, train loss: 0.01638, val loss: 0.01702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 561, train loss: 0.01661, val loss: 0.01731\n",
      "Training epoch: 562, train loss: 0.01613, val loss: 0.01679\n",
      "Training epoch: 563, train loss: 0.01722, val loss: 0.01802\n",
      "Training epoch: 564, train loss: 0.01617, val loss: 0.01679\n",
      "Training epoch: 565, train loss: 0.01674, val loss: 0.01727\n",
      "Training epoch: 566, train loss: 0.01683, val loss: 0.01751\n",
      "Training epoch: 567, train loss: 0.01655, val loss: 0.01713\n",
      "Training epoch: 568, train loss: 0.01641, val loss: 0.01707\n",
      "Training epoch: 569, train loss: 0.01635, val loss: 0.01706\n",
      "Training epoch: 570, train loss: 0.01617, val loss: 0.01678\n",
      "Training epoch: 571, train loss: 0.01610, val loss: 0.01674\n",
      "Training epoch: 572, train loss: 0.01610, val loss: 0.01667\n",
      "Training epoch: 573, train loss: 0.01601, val loss: 0.01668\n",
      "Training epoch: 574, train loss: 0.01693, val loss: 0.01763\n",
      "Training epoch: 575, train loss: 0.01624, val loss: 0.01694\n",
      "Training epoch: 576, train loss: 0.01600, val loss: 0.01662\n",
      "Training epoch: 577, train loss: 0.01644, val loss: 0.01698\n",
      "Training epoch: 578, train loss: 0.01607, val loss: 0.01666\n",
      "Training epoch: 579, train loss: 0.01615, val loss: 0.01677\n",
      "Training epoch: 580, train loss: 0.01736, val loss: 0.01799\n",
      "Training epoch: 581, train loss: 0.01630, val loss: 0.01687\n",
      "Training epoch: 582, train loss: 0.01637, val loss: 0.01695\n",
      "Training epoch: 583, train loss: 0.01649, val loss: 0.01717\n",
      "Training epoch: 584, train loss: 0.01629, val loss: 0.01696\n",
      "Training epoch: 585, train loss: 0.01659, val loss: 0.01715\n",
      "Training epoch: 586, train loss: 0.01686, val loss: 0.01759\n",
      "Training epoch: 587, train loss: 0.01615, val loss: 0.01682\n",
      "Training epoch: 588, train loss: 0.01644, val loss: 0.01702\n",
      "Training epoch: 589, train loss: 0.01631, val loss: 0.01686\n",
      "Training epoch: 590, train loss: 0.01701, val loss: 0.01774\n",
      "Training epoch: 591, train loss: 0.01664, val loss: 0.01715\n",
      "Training epoch: 592, train loss: 0.01610, val loss: 0.01674\n",
      "Training epoch: 593, train loss: 0.01601, val loss: 0.01659\n",
      "Training epoch: 594, train loss: 0.01611, val loss: 0.01677\n",
      "Training epoch: 595, train loss: 0.01625, val loss: 0.01681\n",
      "Training epoch: 596, train loss: 0.01671, val loss: 0.01746\n",
      "Training epoch: 597, train loss: 0.01662, val loss: 0.01719\n",
      "Training epoch: 598, train loss: 0.01597, val loss: 0.01663\n",
      "Training epoch: 599, train loss: 0.01689, val loss: 0.01739\n",
      "Training epoch: 600, train loss: 0.01612, val loss: 0.01675\n",
      "Training epoch: 601, train loss: 0.01631, val loss: 0.01693\n",
      "Training epoch: 602, train loss: 0.01641, val loss: 0.01705\n",
      "Training epoch: 603, train loss: 0.01607, val loss: 0.01668\n",
      "Training epoch: 604, train loss: 0.01598, val loss: 0.01655\n",
      "Training epoch: 605, train loss: 0.01613, val loss: 0.01679\n",
      "Training epoch: 606, train loss: 0.01648, val loss: 0.01721\n",
      "Training epoch: 607, train loss: 0.01653, val loss: 0.01717\n",
      "Training epoch: 608, train loss: 0.01602, val loss: 0.01663\n",
      "Training epoch: 609, train loss: 0.01624, val loss: 0.01690\n",
      "Training epoch: 610, train loss: 0.01678, val loss: 0.01742\n",
      "Training epoch: 611, train loss: 0.01805, val loss: 0.01888\n",
      "Training epoch: 612, train loss: 0.01626, val loss: 0.01690\n",
      "Training epoch: 613, train loss: 0.01599, val loss: 0.01658\n",
      "Training epoch: 614, train loss: 0.01742, val loss: 0.01811\n",
      "Training epoch: 615, train loss: 0.01647, val loss: 0.01708\n",
      "Training epoch: 616, train loss: 0.01660, val loss: 0.01722\n",
      "Training epoch: 617, train loss: 0.01675, val loss: 0.01738\n",
      "Training epoch: 618, train loss: 0.01654, val loss: 0.01718\n",
      "Training epoch: 619, train loss: 0.01649, val loss: 0.01707\n",
      "Training epoch: 620, train loss: 0.01602, val loss: 0.01666\n",
      "Training epoch: 621, train loss: 0.01643, val loss: 0.01703\n",
      "Training epoch: 622, train loss: 0.01607, val loss: 0.01669\n",
      "Training epoch: 623, train loss: 0.01595, val loss: 0.01661\n",
      "Training epoch: 624, train loss: 0.01606, val loss: 0.01668\n",
      "Training epoch: 625, train loss: 0.01610, val loss: 0.01678\n",
      "Training epoch: 626, train loss: 0.01630, val loss: 0.01685\n",
      "Training epoch: 627, train loss: 0.01628, val loss: 0.01696\n",
      "Training epoch: 628, train loss: 0.01642, val loss: 0.01716\n",
      "Training epoch: 629, train loss: 0.01597, val loss: 0.01667\n",
      "Training epoch: 630, train loss: 0.01627, val loss: 0.01694\n",
      "Training epoch: 631, train loss: 0.01622, val loss: 0.01680\n",
      "Training epoch: 632, train loss: 0.01647, val loss: 0.01717\n",
      "Training epoch: 633, train loss: 0.01626, val loss: 0.01687\n",
      "Training epoch: 634, train loss: 0.01593, val loss: 0.01656\n",
      "Training epoch: 635, train loss: 0.01693, val loss: 0.01751\n",
      "Training epoch: 636, train loss: 0.01607, val loss: 0.01673\n",
      "Training epoch: 637, train loss: 0.01605, val loss: 0.01675\n",
      "Training epoch: 638, train loss: 0.01627, val loss: 0.01692\n",
      "Training epoch: 639, train loss: 0.01605, val loss: 0.01666\n",
      "Training epoch: 640, train loss: 0.01610, val loss: 0.01674\n",
      "Training epoch: 641, train loss: 0.01617, val loss: 0.01688\n",
      "Training epoch: 642, train loss: 0.01611, val loss: 0.01667\n",
      "Training epoch: 643, train loss: 0.01613, val loss: 0.01675\n",
      "Training epoch: 644, train loss: 0.01590, val loss: 0.01655\n",
      "Training epoch: 645, train loss: 0.01592, val loss: 0.01661\n",
      "Training epoch: 646, train loss: 0.01620, val loss: 0.01677\n",
      "Training epoch: 647, train loss: 0.01600, val loss: 0.01660\n",
      "Training epoch: 648, train loss: 0.01597, val loss: 0.01660\n",
      "Training epoch: 649, train loss: 0.01638, val loss: 0.01707\n",
      "Training epoch: 650, train loss: 0.01747, val loss: 0.01824\n",
      "Training epoch: 651, train loss: 0.01627, val loss: 0.01687\n",
      "Training epoch: 652, train loss: 0.01630, val loss: 0.01693\n",
      "Training epoch: 653, train loss: 0.01596, val loss: 0.01656\n",
      "Training epoch: 654, train loss: 0.01597, val loss: 0.01665\n",
      "Training epoch: 655, train loss: 0.01643, val loss: 0.01701\n",
      "Training epoch: 656, train loss: 0.01703, val loss: 0.01761\n",
      "Training epoch: 657, train loss: 0.01599, val loss: 0.01666\n",
      "Training epoch: 658, train loss: 0.01605, val loss: 0.01674\n",
      "Training epoch: 659, train loss: 0.01653, val loss: 0.01720\n",
      "Training epoch: 660, train loss: 0.01607, val loss: 0.01671\n",
      "Training epoch: 661, train loss: 0.01594, val loss: 0.01655\n",
      "Training epoch: 662, train loss: 0.01617, val loss: 0.01690\n",
      "Training epoch: 663, train loss: 0.01602, val loss: 0.01672\n",
      "Training epoch: 664, train loss: 0.01597, val loss: 0.01661\n",
      "Training epoch: 665, train loss: 0.01614, val loss: 0.01669\n",
      "Training epoch: 666, train loss: 0.01618, val loss: 0.01683\n",
      "Training epoch: 667, train loss: 0.01596, val loss: 0.01665\n",
      "Training epoch: 668, train loss: 0.01623, val loss: 0.01690\n",
      "Training epoch: 669, train loss: 0.01604, val loss: 0.01664\n",
      "Training epoch: 670, train loss: 0.01663, val loss: 0.01738\n",
      "Training epoch: 671, train loss: 0.01696, val loss: 0.01772\n",
      "Training epoch: 672, train loss: 0.01629, val loss: 0.01698\n",
      "Training epoch: 673, train loss: 0.01666, val loss: 0.01728\n",
      "Training epoch: 674, train loss: 0.01606, val loss: 0.01678\n",
      "Training epoch: 675, train loss: 0.01606, val loss: 0.01671\n",
      "Training epoch: 676, train loss: 0.01617, val loss: 0.01685\n",
      "Training epoch: 677, train loss: 0.01613, val loss: 0.01674\n",
      "Training epoch: 678, train loss: 0.01596, val loss: 0.01659\n",
      "Training epoch: 679, train loss: 0.01594, val loss: 0.01658\n",
      "Training epoch: 680, train loss: 0.01595, val loss: 0.01657\n",
      "Training epoch: 681, train loss: 0.01605, val loss: 0.01672\n",
      "Training epoch: 682, train loss: 0.01602, val loss: 0.01672\n",
      "Training epoch: 683, train loss: 0.01646, val loss: 0.01713\n",
      "Training epoch: 684, train loss: 0.01614, val loss: 0.01679\n",
      "Training epoch: 685, train loss: 0.01608, val loss: 0.01674\n",
      "Training epoch: 686, train loss: 0.01579, val loss: 0.01648\n",
      "Training epoch: 687, train loss: 0.01669, val loss: 0.01740\n",
      "Training epoch: 688, train loss: 0.01840, val loss: 0.01903\n",
      "Training epoch: 689, train loss: 0.01614, val loss: 0.01677\n",
      "Training epoch: 690, train loss: 0.01640, val loss: 0.01706\n",
      "Training epoch: 691, train loss: 0.01593, val loss: 0.01654\n",
      "Training epoch: 692, train loss: 0.01584, val loss: 0.01656\n",
      "Training epoch: 693, train loss: 0.01652, val loss: 0.01715\n",
      "Training epoch: 694, train loss: 0.01628, val loss: 0.01698\n",
      "Training epoch: 695, train loss: 0.01604, val loss: 0.01668\n",
      "Training epoch: 696, train loss: 0.01587, val loss: 0.01653\n",
      "Training epoch: 697, train loss: 0.01607, val loss: 0.01674\n",
      "Training epoch: 698, train loss: 0.01602, val loss: 0.01670\n",
      "Training epoch: 699, train loss: 0.01611, val loss: 0.01679\n",
      "Training epoch: 700, train loss: 0.01587, val loss: 0.01662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 701, train loss: 0.01594, val loss: 0.01661\n",
      "Training epoch: 702, train loss: 0.01657, val loss: 0.01719\n",
      "Training epoch: 703, train loss: 0.01659, val loss: 0.01727\n",
      "Training epoch: 704, train loss: 0.01616, val loss: 0.01681\n",
      "Training epoch: 705, train loss: 0.01602, val loss: 0.01670\n",
      "Training epoch: 706, train loss: 0.01604, val loss: 0.01663\n",
      "Training epoch: 707, train loss: 0.01624, val loss: 0.01684\n",
      "Training epoch: 708, train loss: 0.01604, val loss: 0.01670\n",
      "Training epoch: 709, train loss: 0.01618, val loss: 0.01689\n",
      "Training epoch: 710, train loss: 0.01597, val loss: 0.01668\n",
      "Training epoch: 711, train loss: 0.01624, val loss: 0.01693\n",
      "Training epoch: 712, train loss: 0.01668, val loss: 0.01741\n",
      "Training epoch: 713, train loss: 0.01683, val loss: 0.01751\n",
      "Training epoch: 714, train loss: 0.01627, val loss: 0.01691\n",
      "Training epoch: 715, train loss: 0.01641, val loss: 0.01708\n",
      "Training epoch: 716, train loss: 0.01596, val loss: 0.01660\n",
      "Training epoch: 717, train loss: 0.01622, val loss: 0.01690\n",
      "Training epoch: 718, train loss: 0.01620, val loss: 0.01694\n",
      "Training epoch: 719, train loss: 0.01630, val loss: 0.01700\n",
      "Training epoch: 720, train loss: 0.01602, val loss: 0.01670\n",
      "Training epoch: 721, train loss: 0.01624, val loss: 0.01692\n",
      "Training epoch: 722, train loss: 0.01582, val loss: 0.01647\n",
      "Training epoch: 723, train loss: 0.01580, val loss: 0.01646\n",
      "Training epoch: 724, train loss: 0.01629, val loss: 0.01698\n",
      "Training epoch: 725, train loss: 0.01591, val loss: 0.01660\n",
      "Training epoch: 726, train loss: 0.01601, val loss: 0.01665\n",
      "Training epoch: 727, train loss: 0.01717, val loss: 0.01775\n",
      "Training epoch: 728, train loss: 0.01613, val loss: 0.01678\n",
      "Training epoch: 729, train loss: 0.01579, val loss: 0.01651\n",
      "Training epoch: 730, train loss: 0.01588, val loss: 0.01660\n",
      "Training epoch: 731, train loss: 0.01635, val loss: 0.01704\n",
      "Training epoch: 732, train loss: 0.01593, val loss: 0.01657\n",
      "Training epoch: 733, train loss: 0.01584, val loss: 0.01651\n",
      "Training epoch: 734, train loss: 0.01583, val loss: 0.01650\n",
      "Training epoch: 735, train loss: 0.01634, val loss: 0.01707\n",
      "Training epoch: 736, train loss: 0.01598, val loss: 0.01665\n",
      "Training epoch: 737, train loss: 0.01579, val loss: 0.01643\n",
      "Training epoch: 738, train loss: 0.01590, val loss: 0.01655\n",
      "Training epoch: 739, train loss: 0.01668, val loss: 0.01744\n",
      "Training epoch: 740, train loss: 0.01670, val loss: 0.01733\n",
      "Training epoch: 741, train loss: 0.01578, val loss: 0.01645\n",
      "Training epoch: 742, train loss: 0.01588, val loss: 0.01654\n",
      "Training epoch: 743, train loss: 0.01599, val loss: 0.01663\n",
      "Training epoch: 744, train loss: 0.01578, val loss: 0.01643\n",
      "Training epoch: 745, train loss: 0.01664, val loss: 0.01736\n",
      "Training epoch: 746, train loss: 0.01625, val loss: 0.01691\n",
      "Training epoch: 747, train loss: 0.01643, val loss: 0.01703\n",
      "Training epoch: 748, train loss: 0.01605, val loss: 0.01676\n",
      "Training epoch: 749, train loss: 0.01615, val loss: 0.01681\n",
      "Training epoch: 750, train loss: 0.01574, val loss: 0.01640\n",
      "Training epoch: 751, train loss: 0.01609, val loss: 0.01674\n",
      "Training epoch: 752, train loss: 0.01658, val loss: 0.01723\n",
      "Training epoch: 753, train loss: 0.01576, val loss: 0.01643\n",
      "Training epoch: 754, train loss: 0.01589, val loss: 0.01655\n",
      "Training epoch: 755, train loss: 0.01637, val loss: 0.01705\n",
      "Training epoch: 756, train loss: 0.01585, val loss: 0.01650\n",
      "Training epoch: 757, train loss: 0.01591, val loss: 0.01659\n",
      "Training epoch: 758, train loss: 0.01580, val loss: 0.01650\n",
      "Training epoch: 759, train loss: 0.01594, val loss: 0.01657\n",
      "Training epoch: 760, train loss: 0.01597, val loss: 0.01664\n",
      "Training epoch: 761, train loss: 0.01641, val loss: 0.01712\n",
      "Training epoch: 762, train loss: 0.01739, val loss: 0.01823\n",
      "Training epoch: 763, train loss: 0.01596, val loss: 0.01655\n",
      "Training epoch: 764, train loss: 0.01614, val loss: 0.01680\n",
      "Training epoch: 765, train loss: 0.01672, val loss: 0.01739\n",
      "Training epoch: 766, train loss: 0.01584, val loss: 0.01654\n",
      "Training epoch: 767, train loss: 0.01607, val loss: 0.01674\n",
      "Training epoch: 768, train loss: 0.01599, val loss: 0.01667\n",
      "Training epoch: 769, train loss: 0.01579, val loss: 0.01642\n",
      "Training epoch: 770, train loss: 0.01612, val loss: 0.01683\n",
      "Training epoch: 771, train loss: 0.01631, val loss: 0.01695\n",
      "Training epoch: 772, train loss: 0.01589, val loss: 0.01658\n",
      "Training epoch: 773, train loss: 0.01596, val loss: 0.01660\n",
      "Training epoch: 774, train loss: 0.01603, val loss: 0.01674\n",
      "Training epoch: 775, train loss: 0.01567, val loss: 0.01635\n",
      "Training epoch: 776, train loss: 0.01621, val loss: 0.01689\n",
      "Training epoch: 777, train loss: 0.01631, val loss: 0.01695\n",
      "Training epoch: 778, train loss: 0.01637, val loss: 0.01706\n",
      "Training epoch: 779, train loss: 0.01582, val loss: 0.01653\n",
      "Training epoch: 780, train loss: 0.01610, val loss: 0.01681\n",
      "Training epoch: 781, train loss: 0.01599, val loss: 0.01669\n",
      "Training epoch: 782, train loss: 0.01567, val loss: 0.01631\n",
      "Training epoch: 783, train loss: 0.01577, val loss: 0.01643\n",
      "Training epoch: 784, train loss: 0.01567, val loss: 0.01633\n",
      "Training epoch: 785, train loss: 0.01574, val loss: 0.01643\n",
      "Training epoch: 786, train loss: 0.01588, val loss: 0.01656\n",
      "Training epoch: 787, train loss: 0.01581, val loss: 0.01650\n",
      "Training epoch: 788, train loss: 0.01633, val loss: 0.01692\n",
      "Training epoch: 789, train loss: 0.01604, val loss: 0.01668\n",
      "Training epoch: 790, train loss: 0.01584, val loss: 0.01652\n",
      "Training epoch: 791, train loss: 0.01576, val loss: 0.01642\n",
      "Training epoch: 792, train loss: 0.01583, val loss: 0.01650\n",
      "Training epoch: 793, train loss: 0.01611, val loss: 0.01677\n",
      "Training epoch: 794, train loss: 0.01580, val loss: 0.01648\n",
      "Training epoch: 795, train loss: 0.01563, val loss: 0.01630\n",
      "Training epoch: 796, train loss: 0.01573, val loss: 0.01640\n",
      "Training epoch: 797, train loss: 0.01585, val loss: 0.01650\n",
      "Training epoch: 798, train loss: 0.01678, val loss: 0.01749\n",
      "Training epoch: 799, train loss: 0.01567, val loss: 0.01637\n",
      "Training epoch: 800, train loss: 0.01621, val loss: 0.01684\n",
      "Training epoch: 801, train loss: 0.01575, val loss: 0.01642\n",
      "Training epoch: 802, train loss: 0.01641, val loss: 0.01704\n",
      "Training epoch: 803, train loss: 0.01574, val loss: 0.01639\n",
      "Training epoch: 804, train loss: 0.01582, val loss: 0.01647\n",
      "Training epoch: 805, train loss: 0.01649, val loss: 0.01717\n",
      "Training epoch: 806, train loss: 0.01647, val loss: 0.01713\n",
      "Training epoch: 807, train loss: 0.01616, val loss: 0.01686\n",
      "Training epoch: 808, train loss: 0.01593, val loss: 0.01656\n",
      "Training epoch: 809, train loss: 0.01633, val loss: 0.01703\n",
      "Training epoch: 810, train loss: 0.01597, val loss: 0.01662\n",
      "Training epoch: 811, train loss: 0.01564, val loss: 0.01631\n",
      "Training epoch: 812, train loss: 0.01565, val loss: 0.01636\n",
      "Training epoch: 813, train loss: 0.01611, val loss: 0.01675\n",
      "Training epoch: 814, train loss: 0.01580, val loss: 0.01645\n",
      "Training epoch: 815, train loss: 0.01581, val loss: 0.01649\n",
      "Training epoch: 816, train loss: 0.01569, val loss: 0.01635\n",
      "Training epoch: 817, train loss: 0.01614, val loss: 0.01678\n",
      "Training epoch: 818, train loss: 0.01633, val loss: 0.01702\n",
      "Training epoch: 819, train loss: 0.01592, val loss: 0.01658\n",
      "Training epoch: 820, train loss: 0.01634, val loss: 0.01695\n",
      "Training epoch: 821, train loss: 0.01603, val loss: 0.01674\n",
      "Training epoch: 822, train loss: 0.01605, val loss: 0.01671\n",
      "Training epoch: 823, train loss: 0.01644, val loss: 0.01715\n",
      "Training epoch: 824, train loss: 0.01573, val loss: 0.01642\n",
      "Training epoch: 825, train loss: 0.01628, val loss: 0.01691\n",
      "Training epoch: 826, train loss: 0.01659, val loss: 0.01729\n",
      "Training epoch: 827, train loss: 0.01670, val loss: 0.01741\n",
      "Training epoch: 828, train loss: 0.01587, val loss: 0.01651\n",
      "Training epoch: 829, train loss: 0.01607, val loss: 0.01673\n",
      "Training epoch: 830, train loss: 0.01580, val loss: 0.01649\n",
      "Training epoch: 831, train loss: 0.01567, val loss: 0.01634\n",
      "Training epoch: 832, train loss: 0.01572, val loss: 0.01637\n",
      "Training epoch: 833, train loss: 0.01566, val loss: 0.01636\n",
      "Training epoch: 834, train loss: 0.01561, val loss: 0.01624\n",
      "Training epoch: 835, train loss: 0.01567, val loss: 0.01634\n",
      "Training epoch: 836, train loss: 0.01577, val loss: 0.01647\n",
      "Training epoch: 837, train loss: 0.01588, val loss: 0.01647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 838, train loss: 0.01591, val loss: 0.01655\n",
      "Training epoch: 839, train loss: 0.01563, val loss: 0.01629\n",
      "Training epoch: 840, train loss: 0.01587, val loss: 0.01657\n",
      "Training epoch: 841, train loss: 0.01625, val loss: 0.01692\n",
      "Training epoch: 842, train loss: 0.01564, val loss: 0.01625\n",
      "Training epoch: 843, train loss: 0.01563, val loss: 0.01633\n",
      "Training epoch: 844, train loss: 0.01571, val loss: 0.01638\n",
      "Training epoch: 845, train loss: 0.01559, val loss: 0.01622\n",
      "Training epoch: 846, train loss: 0.01565, val loss: 0.01629\n",
      "Training epoch: 847, train loss: 0.01562, val loss: 0.01629\n",
      "Training epoch: 848, train loss: 0.01598, val loss: 0.01665\n",
      "Training epoch: 849, train loss: 0.01614, val loss: 0.01690\n",
      "Training epoch: 850, train loss: 0.01561, val loss: 0.01628\n",
      "Training epoch: 851, train loss: 0.01774, val loss: 0.01844\n",
      "Training epoch: 852, train loss: 0.01625, val loss: 0.01686\n",
      "Training epoch: 853, train loss: 0.01595, val loss: 0.01664\n",
      "Training epoch: 854, train loss: 0.01553, val loss: 0.01617\n",
      "Training epoch: 855, train loss: 0.01599, val loss: 0.01666\n",
      "Training epoch: 856, train loss: 0.01593, val loss: 0.01660\n",
      "Training epoch: 857, train loss: 0.01594, val loss: 0.01659\n",
      "Training epoch: 858, train loss: 0.01574, val loss: 0.01641\n",
      "Training epoch: 859, train loss: 0.01568, val loss: 0.01632\n",
      "Training epoch: 860, train loss: 0.01570, val loss: 0.01637\n",
      "Training epoch: 861, train loss: 0.01581, val loss: 0.01645\n",
      "Training epoch: 862, train loss: 0.01557, val loss: 0.01623\n",
      "Training epoch: 863, train loss: 0.01575, val loss: 0.01640\n",
      "Training epoch: 864, train loss: 0.01583, val loss: 0.01651\n",
      "Training epoch: 865, train loss: 0.01573, val loss: 0.01643\n",
      "Training epoch: 866, train loss: 0.01567, val loss: 0.01631\n",
      "Training epoch: 867, train loss: 0.01558, val loss: 0.01621\n",
      "Training epoch: 868, train loss: 0.01559, val loss: 0.01624\n",
      "Training epoch: 869, train loss: 0.01563, val loss: 0.01627\n",
      "Training epoch: 870, train loss: 0.01578, val loss: 0.01645\n",
      "Training epoch: 871, train loss: 0.01563, val loss: 0.01625\n",
      "Training epoch: 872, train loss: 0.01560, val loss: 0.01621\n",
      "Training epoch: 873, train loss: 0.01575, val loss: 0.01635\n",
      "Training epoch: 874, train loss: 0.01560, val loss: 0.01626\n",
      "Training epoch: 875, train loss: 0.01596, val loss: 0.01660\n",
      "Training epoch: 876, train loss: 0.01564, val loss: 0.01631\n",
      "Training epoch: 877, train loss: 0.01551, val loss: 0.01617\n",
      "Training epoch: 878, train loss: 0.01554, val loss: 0.01617\n",
      "Training epoch: 879, train loss: 0.01593, val loss: 0.01658\n",
      "Training epoch: 880, train loss: 0.01584, val loss: 0.01654\n",
      "Training epoch: 881, train loss: 0.01567, val loss: 0.01632\n",
      "Training epoch: 882, train loss: 0.01592, val loss: 0.01657\n",
      "Training epoch: 883, train loss: 0.01561, val loss: 0.01628\n",
      "Training epoch: 884, train loss: 0.01589, val loss: 0.01656\n",
      "Training epoch: 885, train loss: 0.01583, val loss: 0.01648\n",
      "Training epoch: 886, train loss: 0.01584, val loss: 0.01650\n",
      "Training epoch: 887, train loss: 0.01553, val loss: 0.01616\n",
      "Training epoch: 888, train loss: 0.01555, val loss: 0.01619\n",
      "Training epoch: 889, train loss: 0.01603, val loss: 0.01670\n",
      "Training epoch: 890, train loss: 0.01565, val loss: 0.01632\n",
      "Training epoch: 891, train loss: 0.01564, val loss: 0.01631\n",
      "Training epoch: 892, train loss: 0.01620, val loss: 0.01674\n",
      "Training epoch: 893, train loss: 0.01626, val loss: 0.01688\n",
      "Training epoch: 894, train loss: 0.01554, val loss: 0.01619\n",
      "Training epoch: 895, train loss: 0.01575, val loss: 0.01639\n",
      "Training epoch: 896, train loss: 0.01596, val loss: 0.01663\n",
      "Training epoch: 897, train loss: 0.01590, val loss: 0.01660\n",
      "Training epoch: 898, train loss: 0.01617, val loss: 0.01678\n",
      "Training epoch: 899, train loss: 0.01548, val loss: 0.01608\n",
      "Training epoch: 900, train loss: 0.01546, val loss: 0.01611\n",
      "Training epoch: 901, train loss: 0.01595, val loss: 0.01659\n",
      "Training epoch: 902, train loss: 0.01570, val loss: 0.01627\n",
      "Training epoch: 903, train loss: 0.01687, val loss: 0.01752\n",
      "Training epoch: 904, train loss: 0.01572, val loss: 0.01634\n",
      "Training epoch: 905, train loss: 0.01560, val loss: 0.01625\n",
      "Training epoch: 906, train loss: 0.01554, val loss: 0.01619\n",
      "Training epoch: 907, train loss: 0.01593, val loss: 0.01659\n",
      "Training epoch: 908, train loss: 0.01571, val loss: 0.01632\n",
      "Training epoch: 909, train loss: 0.01560, val loss: 0.01623\n",
      "Training epoch: 910, train loss: 0.01748, val loss: 0.01807\n",
      "Training epoch: 911, train loss: 0.01599, val loss: 0.01664\n",
      "Training epoch: 912, train loss: 0.01592, val loss: 0.01656\n",
      "Training epoch: 913, train loss: 0.01578, val loss: 0.01640\n",
      "Training epoch: 914, train loss: 0.01549, val loss: 0.01615\n",
      "Training epoch: 915, train loss: 0.01546, val loss: 0.01611\n",
      "Training epoch: 916, train loss: 0.01558, val loss: 0.01622\n",
      "Training epoch: 917, train loss: 0.01605, val loss: 0.01671\n",
      "Training epoch: 918, train loss: 0.01549, val loss: 0.01609\n",
      "Training epoch: 919, train loss: 0.01547, val loss: 0.01612\n",
      "Training epoch: 920, train loss: 0.01541, val loss: 0.01606\n",
      "Training epoch: 921, train loss: 0.01616, val loss: 0.01676\n",
      "Training epoch: 922, train loss: 0.01550, val loss: 0.01614\n",
      "Training epoch: 923, train loss: 0.01552, val loss: 0.01618\n",
      "Training epoch: 924, train loss: 0.01591, val loss: 0.01655\n",
      "Training epoch: 925, train loss: 0.01603, val loss: 0.01668\n",
      "Training epoch: 926, train loss: 0.01669, val loss: 0.01730\n",
      "Training epoch: 927, train loss: 0.01647, val loss: 0.01710\n",
      "Training epoch: 928, train loss: 0.01587, val loss: 0.01645\n",
      "Training epoch: 929, train loss: 0.01552, val loss: 0.01612\n",
      "Training epoch: 930, train loss: 0.01588, val loss: 0.01654\n",
      "Training epoch: 931, train loss: 0.01548, val loss: 0.01612\n",
      "Training epoch: 932, train loss: 0.01587, val loss: 0.01647\n",
      "Training epoch: 933, train loss: 0.01580, val loss: 0.01642\n",
      "Training epoch: 934, train loss: 0.01549, val loss: 0.01610\n",
      "Training epoch: 935, train loss: 0.01551, val loss: 0.01615\n",
      "Training epoch: 936, train loss: 0.01568, val loss: 0.01631\n",
      "Training epoch: 937, train loss: 0.01545, val loss: 0.01609\n",
      "Training epoch: 938, train loss: 0.01575, val loss: 0.01634\n",
      "Training epoch: 939, train loss: 0.01585, val loss: 0.01648\n",
      "Training epoch: 940, train loss: 0.01589, val loss: 0.01648\n",
      "Training epoch: 941, train loss: 0.01549, val loss: 0.01610\n",
      "Training epoch: 942, train loss: 0.01652, val loss: 0.01712\n",
      "Training epoch: 943, train loss: 0.01562, val loss: 0.01621\n",
      "Training epoch: 944, train loss: 0.01563, val loss: 0.01624\n",
      "Training epoch: 945, train loss: 0.01543, val loss: 0.01606\n",
      "Training epoch: 946, train loss: 0.01557, val loss: 0.01619\n",
      "Training epoch: 947, train loss: 0.01549, val loss: 0.01612\n",
      "Training epoch: 948, train loss: 0.01557, val loss: 0.01622\n",
      "Training epoch: 949, train loss: 0.01557, val loss: 0.01620\n",
      "Training epoch: 950, train loss: 0.01545, val loss: 0.01607\n",
      "Training epoch: 951, train loss: 0.01574, val loss: 0.01637\n",
      "Training epoch: 952, train loss: 0.01563, val loss: 0.01621\n",
      "Training epoch: 953, train loss: 0.01563, val loss: 0.01625\n",
      "Training epoch: 954, train loss: 0.01558, val loss: 0.01620\n",
      "Training epoch: 955, train loss: 0.01567, val loss: 0.01626\n",
      "Training epoch: 956, train loss: 0.01551, val loss: 0.01615\n",
      "Training epoch: 957, train loss: 0.01566, val loss: 0.01623\n",
      "Training epoch: 958, train loss: 0.01579, val loss: 0.01641\n",
      "Training epoch: 959, train loss: 0.01563, val loss: 0.01618\n",
      "Training epoch: 960, train loss: 0.01634, val loss: 0.01692\n",
      "Training epoch: 961, train loss: 0.01538, val loss: 0.01601\n",
      "Training epoch: 962, train loss: 0.01552, val loss: 0.01613\n",
      "Training epoch: 963, train loss: 0.01545, val loss: 0.01606\n",
      "Training epoch: 964, train loss: 0.01551, val loss: 0.01611\n",
      "Training epoch: 965, train loss: 0.01535, val loss: 0.01595\n",
      "Training epoch: 966, train loss: 0.01553, val loss: 0.01613\n",
      "Training epoch: 967, train loss: 0.01555, val loss: 0.01614\n",
      "Training epoch: 968, train loss: 0.01554, val loss: 0.01614\n",
      "Training epoch: 969, train loss: 0.01569, val loss: 0.01632\n",
      "Training epoch: 970, train loss: 0.01546, val loss: 0.01607\n",
      "Training epoch: 971, train loss: 0.01554, val loss: 0.01615\n",
      "Training epoch: 972, train loss: 0.01557, val loss: 0.01618\n",
      "Training epoch: 973, train loss: 0.01556, val loss: 0.01617\n",
      "Training epoch: 974, train loss: 0.01550, val loss: 0.01610\n",
      "Training epoch: 975, train loss: 0.01617, val loss: 0.01674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 976, train loss: 0.01589, val loss: 0.01648\n",
      "Training epoch: 977, train loss: 0.01592, val loss: 0.01653\n",
      "Training epoch: 978, train loss: 0.01581, val loss: 0.01646\n",
      "Training epoch: 979, train loss: 0.01537, val loss: 0.01599\n",
      "Training epoch: 980, train loss: 0.01560, val loss: 0.01623\n",
      "Training epoch: 981, train loss: 0.01664, val loss: 0.01729\n",
      "Training epoch: 982, train loss: 0.01558, val loss: 0.01615\n",
      "Training epoch: 983, train loss: 0.01572, val loss: 0.01630\n",
      "Training epoch: 984, train loss: 0.01583, val loss: 0.01640\n",
      "Training epoch: 985, train loss: 0.01574, val loss: 0.01635\n",
      "Training epoch: 986, train loss: 0.01544, val loss: 0.01608\n",
      "Training epoch: 987, train loss: 0.01576, val loss: 0.01637\n",
      "Training epoch: 988, train loss: 0.01547, val loss: 0.01606\n",
      "Training epoch: 989, train loss: 0.01538, val loss: 0.01600\n",
      "Training epoch: 990, train loss: 0.01536, val loss: 0.01600\n",
      "Training epoch: 991, train loss: 0.01543, val loss: 0.01602\n",
      "Training epoch: 992, train loss: 0.01561, val loss: 0.01617\n",
      "Training epoch: 993, train loss: 0.01548, val loss: 0.01610\n",
      "Training epoch: 994, train loss: 0.01544, val loss: 0.01603\n",
      "Training epoch: 995, train loss: 0.01544, val loss: 0.01607\n",
      "Training epoch: 996, train loss: 0.01565, val loss: 0.01623\n",
      "Training epoch: 997, train loss: 0.01571, val loss: 0.01628\n",
      "Training epoch: 998, train loss: 0.01550, val loss: 0.01612\n",
      "Training epoch: 999, train loss: 0.01537, val loss: 0.01595\n",
      "Training epoch: 1000, train loss: 0.01681, val loss: 0.01750\n",
      "Training epoch: 1001, train loss: 0.01569, val loss: 0.01630\n",
      "Training epoch: 1002, train loss: 0.01585, val loss: 0.01642\n",
      "Training epoch: 1003, train loss: 0.01692, val loss: 0.01748\n",
      "Training epoch: 1004, train loss: 0.01563, val loss: 0.01625\n",
      "Training epoch: 1005, train loss: 0.01552, val loss: 0.01613\n",
      "Training epoch: 1006, train loss: 0.01712, val loss: 0.01782\n",
      "Training epoch: 1007, train loss: 0.01599, val loss: 0.01662\n",
      "Training epoch: 1008, train loss: 0.01547, val loss: 0.01603\n",
      "Training epoch: 1009, train loss: 0.01539, val loss: 0.01601\n",
      "Training epoch: 1010, train loss: 0.01556, val loss: 0.01618\n",
      "Training epoch: 1011, train loss: 0.01541, val loss: 0.01602\n",
      "Training epoch: 1012, train loss: 0.01553, val loss: 0.01609\n",
      "Training epoch: 1013, train loss: 0.01584, val loss: 0.01643\n",
      "Training epoch: 1014, train loss: 0.01589, val loss: 0.01653\n",
      "Training epoch: 1015, train loss: 0.01598, val loss: 0.01662\n",
      "Training epoch: 1016, train loss: 0.01551, val loss: 0.01607\n",
      "Training epoch: 1017, train loss: 0.01574, val loss: 0.01631\n",
      "Training epoch: 1018, train loss: 0.01538, val loss: 0.01599\n",
      "Training epoch: 1019, train loss: 0.01546, val loss: 0.01607\n",
      "Training epoch: 1020, train loss: 0.01540, val loss: 0.01602\n",
      "Training epoch: 1021, train loss: 0.01552, val loss: 0.01612\n",
      "Training epoch: 1022, train loss: 0.01568, val loss: 0.01626\n",
      "Training epoch: 1023, train loss: 0.01535, val loss: 0.01594\n",
      "Training epoch: 1024, train loss: 0.01553, val loss: 0.01614\n",
      "Training epoch: 1025, train loss: 0.01571, val loss: 0.01633\n",
      "Training epoch: 1026, train loss: 0.01547, val loss: 0.01607\n",
      "Training epoch: 1027, train loss: 0.01541, val loss: 0.01596\n",
      "Training epoch: 1028, train loss: 0.01541, val loss: 0.01603\n",
      "Training epoch: 1029, train loss: 0.01579, val loss: 0.01641\n",
      "Training epoch: 1030, train loss: 0.01566, val loss: 0.01625\n",
      "Training epoch: 1031, train loss: 0.01545, val loss: 0.01602\n",
      "Training epoch: 1032, train loss: 0.01565, val loss: 0.01623\n",
      "Training epoch: 1033, train loss: 0.01542, val loss: 0.01600\n",
      "Training epoch: 1034, train loss: 0.01540, val loss: 0.01596\n",
      "Training epoch: 1035, train loss: 0.01582, val loss: 0.01635\n",
      "Training epoch: 1036, train loss: 0.01591, val loss: 0.01656\n",
      "Training epoch: 1037, train loss: 0.01601, val loss: 0.01660\n",
      "Training epoch: 1038, train loss: 0.01562, val loss: 0.01619\n",
      "Training epoch: 1039, train loss: 0.01541, val loss: 0.01604\n",
      "Training epoch: 1040, train loss: 0.01562, val loss: 0.01619\n",
      "Training epoch: 1041, train loss: 0.01565, val loss: 0.01623\n",
      "Training epoch: 1042, train loss: 0.01636, val loss: 0.01694\n",
      "Training epoch: 1043, train loss: 0.01540, val loss: 0.01596\n",
      "Training epoch: 1044, train loss: 0.01552, val loss: 0.01611\n",
      "Training epoch: 1045, train loss: 0.01540, val loss: 0.01596\n",
      "Training epoch: 1046, train loss: 0.01536, val loss: 0.01597\n",
      "Training epoch: 1047, train loss: 0.01539, val loss: 0.01602\n",
      "Training epoch: 1048, train loss: 0.01546, val loss: 0.01605\n",
      "Training epoch: 1049, train loss: 0.01574, val loss: 0.01633\n",
      "Training epoch: 1050, train loss: 0.01588, val loss: 0.01649\n",
      "Training epoch: 1051, train loss: 0.01614, val loss: 0.01673\n",
      "Training epoch: 1052, train loss: 0.01558, val loss: 0.01614\n",
      "Training epoch: 1053, train loss: 0.01549, val loss: 0.01605\n",
      "Training epoch: 1054, train loss: 0.01577, val loss: 0.01639\n",
      "Training epoch: 1055, train loss: 0.01548, val loss: 0.01606\n",
      "Training epoch: 1056, train loss: 0.01580, val loss: 0.01640\n",
      "Training epoch: 1057, train loss: 0.01586, val loss: 0.01647\n",
      "Training epoch: 1058, train loss: 0.01540, val loss: 0.01599\n",
      "Training epoch: 1059, train loss: 0.01540, val loss: 0.01596\n",
      "Training epoch: 1060, train loss: 0.01550, val loss: 0.01611\n",
      "Training epoch: 1061, train loss: 0.01541, val loss: 0.01602\n",
      "Training epoch: 1062, train loss: 0.01545, val loss: 0.01602\n",
      "Training epoch: 1063, train loss: 0.01537, val loss: 0.01596\n",
      "Training epoch: 1064, train loss: 0.01550, val loss: 0.01610\n",
      "Training epoch: 1065, train loss: 0.01584, val loss: 0.01642\n",
      "Training epoch: 1066, train loss: 0.01567, val loss: 0.01626\n",
      "Training epoch: 1067, train loss: 0.01568, val loss: 0.01626\n",
      "Training epoch: 1068, train loss: 0.01602, val loss: 0.01660\n",
      "Training epoch: 1069, train loss: 0.01547, val loss: 0.01604\n",
      "Training epoch: 1070, train loss: 0.01545, val loss: 0.01600\n",
      "Training epoch: 1071, train loss: 0.01552, val loss: 0.01608\n",
      "Training epoch: 1072, train loss: 0.01597, val loss: 0.01654\n",
      "Training epoch: 1073, train loss: 0.01561, val loss: 0.01622\n",
      "Training epoch: 1074, train loss: 0.01555, val loss: 0.01611\n",
      "Training epoch: 1075, train loss: 0.01590, val loss: 0.01648\n",
      "Training epoch: 1076, train loss: 0.01619, val loss: 0.01677\n",
      "Training epoch: 1077, train loss: 0.01558, val loss: 0.01616\n",
      "Training epoch: 1078, train loss: 0.01535, val loss: 0.01596\n",
      "Training epoch: 1079, train loss: 0.01556, val loss: 0.01613\n",
      "Training epoch: 1080, train loss: 0.01534, val loss: 0.01593\n",
      "Training epoch: 1081, train loss: 0.01533, val loss: 0.01587\n",
      "Training epoch: 1082, train loss: 0.01531, val loss: 0.01586\n",
      "Training epoch: 1083, train loss: 0.01574, val loss: 0.01631\n",
      "Training epoch: 1084, train loss: 0.01555, val loss: 0.01609\n",
      "Training epoch: 1085, train loss: 0.01537, val loss: 0.01598\n",
      "Training epoch: 1086, train loss: 0.01544, val loss: 0.01599\n",
      "Training epoch: 1087, train loss: 0.01531, val loss: 0.01588\n",
      "Training epoch: 1088, train loss: 0.01539, val loss: 0.01599\n",
      "Training epoch: 1089, train loss: 0.01533, val loss: 0.01590\n",
      "Training epoch: 1090, train loss: 0.01558, val loss: 0.01615\n",
      "Training epoch: 1091, train loss: 0.01532, val loss: 0.01586\n",
      "Training epoch: 1092, train loss: 0.01542, val loss: 0.01602\n",
      "Training epoch: 1093, train loss: 0.01588, val loss: 0.01648\n",
      "Training epoch: 1094, train loss: 0.01592, val loss: 0.01649\n",
      "Training epoch: 1095, train loss: 0.01557, val loss: 0.01608\n",
      "Training epoch: 1096, train loss: 0.01625, val loss: 0.01676\n",
      "Training epoch: 1097, train loss: 0.01574, val loss: 0.01631\n",
      "Training epoch: 1098, train loss: 0.01617, val loss: 0.01674\n",
      "Training epoch: 1099, train loss: 0.01551, val loss: 0.01610\n",
      "Training epoch: 1100, train loss: 0.01537, val loss: 0.01592\n",
      "Training epoch: 1101, train loss: 0.01552, val loss: 0.01609\n",
      "Training epoch: 1102, train loss: 0.01609, val loss: 0.01669\n",
      "Training epoch: 1103, train loss: 0.01587, val loss: 0.01642\n",
      "Training epoch: 1104, train loss: 0.01640, val loss: 0.01701\n",
      "Training epoch: 1105, train loss: 0.01573, val loss: 0.01631\n",
      "Training epoch: 1106, train loss: 0.01546, val loss: 0.01599\n",
      "Training epoch: 1107, train loss: 0.01575, val loss: 0.01634\n",
      "Training epoch: 1108, train loss: 0.01550, val loss: 0.01608\n",
      "Training epoch: 1109, train loss: 0.01575, val loss: 0.01630\n",
      "Training epoch: 1110, train loss: 0.01558, val loss: 0.01616\n",
      "Training epoch: 1111, train loss: 0.01532, val loss: 0.01589\n",
      "Training epoch: 1112, train loss: 0.01539, val loss: 0.01596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1113, train loss: 0.01568, val loss: 0.01627\n",
      "Training epoch: 1114, train loss: 0.01537, val loss: 0.01590\n",
      "Training epoch: 1115, train loss: 0.01558, val loss: 0.01615\n",
      "Training epoch: 1116, train loss: 0.01547, val loss: 0.01605\n",
      "Training epoch: 1117, train loss: 0.01552, val loss: 0.01605\n",
      "Training epoch: 1118, train loss: 0.01544, val loss: 0.01600\n",
      "Training epoch: 1119, train loss: 0.01552, val loss: 0.01610\n",
      "Training epoch: 1120, train loss: 0.01534, val loss: 0.01591\n",
      "Training epoch: 1121, train loss: 0.01533, val loss: 0.01588\n",
      "Training epoch: 1122, train loss: 0.01547, val loss: 0.01602\n",
      "Training epoch: 1123, train loss: 0.01526, val loss: 0.01582\n",
      "Training epoch: 1124, train loss: 0.01549, val loss: 0.01604\n",
      "Training epoch: 1125, train loss: 0.01581, val loss: 0.01635\n",
      "Training epoch: 1126, train loss: 0.01554, val loss: 0.01607\n",
      "Training epoch: 1127, train loss: 0.01585, val loss: 0.01641\n",
      "Training epoch: 1128, train loss: 0.01553, val loss: 0.01606\n",
      "Training epoch: 1129, train loss: 0.01573, val loss: 0.01632\n",
      "Training epoch: 1130, train loss: 0.01633, val loss: 0.01688\n",
      "Training epoch: 1131, train loss: 0.01612, val loss: 0.01668\n",
      "Training epoch: 1132, train loss: 0.01542, val loss: 0.01596\n",
      "Training epoch: 1133, train loss: 0.01551, val loss: 0.01602\n",
      "Training epoch: 1134, train loss: 0.01550, val loss: 0.01603\n",
      "Training epoch: 1135, train loss: 0.01552, val loss: 0.01606\n",
      "Training epoch: 1136, train loss: 0.01539, val loss: 0.01593\n",
      "Training epoch: 1137, train loss: 0.01531, val loss: 0.01587\n",
      "Training epoch: 1138, train loss: 0.01553, val loss: 0.01611\n",
      "Training epoch: 1139, train loss: 0.01535, val loss: 0.01589\n",
      "Training epoch: 1140, train loss: 0.01546, val loss: 0.01604\n",
      "Training epoch: 1141, train loss: 0.01545, val loss: 0.01602\n",
      "Training epoch: 1142, train loss: 0.01563, val loss: 0.01614\n",
      "Training epoch: 1143, train loss: 0.01537, val loss: 0.01587\n",
      "Training epoch: 1144, train loss: 0.01650, val loss: 0.01706\n",
      "Training epoch: 1145, train loss: 0.01551, val loss: 0.01606\n",
      "Training epoch: 1146, train loss: 0.01541, val loss: 0.01597\n",
      "Training epoch: 1147, train loss: 0.01538, val loss: 0.01593\n",
      "Training epoch: 1148, train loss: 0.01581, val loss: 0.01635\n",
      "Training epoch: 1149, train loss: 0.01566, val loss: 0.01620\n",
      "Training epoch: 1150, train loss: 0.01559, val loss: 0.01618\n",
      "Training epoch: 1151, train loss: 0.01529, val loss: 0.01579\n",
      "Training epoch: 1152, train loss: 0.01536, val loss: 0.01591\n",
      "Training epoch: 1153, train loss: 0.01530, val loss: 0.01585\n",
      "Training epoch: 1154, train loss: 0.01532, val loss: 0.01587\n",
      "Training epoch: 1155, train loss: 0.01555, val loss: 0.01608\n",
      "Training epoch: 1156, train loss: 0.01531, val loss: 0.01586\n",
      "Training epoch: 1157, train loss: 0.01563, val loss: 0.01617\n",
      "Training epoch: 1158, train loss: 0.01530, val loss: 0.01584\n",
      "Training epoch: 1159, train loss: 0.01631, val loss: 0.01690\n",
      "Training epoch: 1160, train loss: 0.01561, val loss: 0.01618\n",
      "Training epoch: 1161, train loss: 0.01555, val loss: 0.01608\n",
      "Training epoch: 1162, train loss: 0.01555, val loss: 0.01610\n",
      "Training epoch: 1163, train loss: 0.01657, val loss: 0.01714\n",
      "Training epoch: 1164, train loss: 0.01549, val loss: 0.01602\n",
      "Training epoch: 1165, train loss: 0.01606, val loss: 0.01659\n",
      "Training epoch: 1166, train loss: 0.01592, val loss: 0.01637\n",
      "Training epoch: 1167, train loss: 0.01565, val loss: 0.01617\n",
      "Training epoch: 1168, train loss: 0.01579, val loss: 0.01635\n",
      "Training epoch: 1169, train loss: 0.01778, val loss: 0.01833\n",
      "Training epoch: 1170, train loss: 0.01605, val loss: 0.01665\n",
      "Training epoch: 1171, train loss: 0.01557, val loss: 0.01605\n",
      "Training epoch: 1172, train loss: 0.01561, val loss: 0.01614\n",
      "Training epoch: 1173, train loss: 0.01561, val loss: 0.01610\n",
      "Training epoch: 1174, train loss: 0.01541, val loss: 0.01595\n",
      "Training epoch: 1175, train loss: 0.01543, val loss: 0.01594\n",
      "Training epoch: 1176, train loss: 0.01539, val loss: 0.01593\n",
      "Training epoch: 1177, train loss: 0.01531, val loss: 0.01582\n",
      "Training epoch: 1178, train loss: 0.01541, val loss: 0.01595\n",
      "Training epoch: 1179, train loss: 0.01579, val loss: 0.01630\n",
      "Training epoch: 1180, train loss: 0.01530, val loss: 0.01582\n",
      "Training epoch: 1181, train loss: 0.01546, val loss: 0.01601\n",
      "Training epoch: 1182, train loss: 0.01619, val loss: 0.01675\n",
      "Training epoch: 1183, train loss: 0.01526, val loss: 0.01580\n",
      "Training epoch: 1184, train loss: 0.01532, val loss: 0.01586\n",
      "Training epoch: 1185, train loss: 0.01557, val loss: 0.01614\n",
      "Training epoch: 1186, train loss: 0.01532, val loss: 0.01589\n",
      "Training epoch: 1187, train loss: 0.01530, val loss: 0.01581\n",
      "Training epoch: 1188, train loss: 0.01532, val loss: 0.01585\n",
      "Training epoch: 1189, train loss: 0.01535, val loss: 0.01587\n",
      "Training epoch: 1190, train loss: 0.01532, val loss: 0.01583\n",
      "Training epoch: 1191, train loss: 0.01560, val loss: 0.01615\n",
      "Training epoch: 1192, train loss: 0.01533, val loss: 0.01585\n",
      "Training epoch: 1193, train loss: 0.01558, val loss: 0.01606\n",
      "Training epoch: 1194, train loss: 0.01635, val loss: 0.01688\n",
      "Training epoch: 1195, train loss: 0.01556, val loss: 0.01603\n",
      "Training epoch: 1196, train loss: 0.01530, val loss: 0.01582\n",
      "Training epoch: 1197, train loss: 0.01560, val loss: 0.01612\n",
      "Training epoch: 1198, train loss: 0.01546, val loss: 0.01601\n",
      "Training epoch: 1199, train loss: 0.01628, val loss: 0.01683\n",
      "Training epoch: 1200, train loss: 0.01533, val loss: 0.01584\n",
      "Training epoch: 1201, train loss: 0.01531, val loss: 0.01582\n",
      "Training epoch: 1202, train loss: 0.01535, val loss: 0.01586\n",
      "Training epoch: 1203, train loss: 0.01558, val loss: 0.01612\n",
      "Training epoch: 1204, train loss: 0.01619, val loss: 0.01670\n",
      "Training epoch: 1205, train loss: 0.01621, val loss: 0.01669\n",
      "Training epoch: 1206, train loss: 0.01531, val loss: 0.01583\n",
      "Training epoch: 1207, train loss: 0.01535, val loss: 0.01586\n",
      "Training epoch: 1208, train loss: 0.01588, val loss: 0.01645\n",
      "Training epoch: 1209, train loss: 0.01560, val loss: 0.01609\n",
      "Training epoch: 1210, train loss: 0.01538, val loss: 0.01591\n",
      "Training epoch: 1211, train loss: 0.01555, val loss: 0.01602\n",
      "Training epoch: 1212, train loss: 0.01529, val loss: 0.01584\n",
      "Training epoch: 1213, train loss: 0.01542, val loss: 0.01593\n",
      "Training epoch: 1214, train loss: 0.01532, val loss: 0.01583\n",
      "Training epoch: 1215, train loss: 0.01555, val loss: 0.01604\n",
      "Training epoch: 1216, train loss: 0.01528, val loss: 0.01582\n",
      "Training epoch: 1217, train loss: 0.01553, val loss: 0.01604\n",
      "Training epoch: 1218, train loss: 0.01587, val loss: 0.01641\n",
      "Training epoch: 1219, train loss: 0.01560, val loss: 0.01609\n",
      "Training epoch: 1220, train loss: 0.01563, val loss: 0.01610\n",
      "Training epoch: 1221, train loss: 0.01590, val loss: 0.01639\n",
      "Training epoch: 1222, train loss: 0.01542, val loss: 0.01595\n",
      "Training epoch: 1223, train loss: 0.01559, val loss: 0.01609\n",
      "Training epoch: 1224, train loss: 0.01540, val loss: 0.01594\n",
      "Training epoch: 1225, train loss: 0.01548, val loss: 0.01600\n",
      "Training epoch: 1226, train loss: 0.01578, val loss: 0.01632\n",
      "Training epoch: 1227, train loss: 0.01528, val loss: 0.01581\n",
      "Training epoch: 1228, train loss: 0.01532, val loss: 0.01585\n",
      "Training epoch: 1229, train loss: 0.01585, val loss: 0.01637\n",
      "Training epoch: 1230, train loss: 0.01530, val loss: 0.01584\n",
      "Training epoch: 1231, train loss: 0.01543, val loss: 0.01596\n",
      "Training epoch: 1232, train loss: 0.01574, val loss: 0.01625\n",
      "Training epoch: 1233, train loss: 0.01559, val loss: 0.01610\n",
      "Training epoch: 1234, train loss: 0.01569, val loss: 0.01625\n",
      "Training epoch: 1235, train loss: 0.01570, val loss: 0.01616\n",
      "Training epoch: 1236, train loss: 0.01557, val loss: 0.01607\n",
      "Training epoch: 1237, train loss: 0.01570, val loss: 0.01617\n",
      "Training epoch: 1238, train loss: 0.01583, val loss: 0.01634\n",
      "Training epoch: 1239, train loss: 0.01537, val loss: 0.01590\n",
      "Training epoch: 1240, train loss: 0.01619, val loss: 0.01671\n",
      "Training epoch: 1241, train loss: 0.01607, val loss: 0.01654\n",
      "Training epoch: 1242, train loss: 0.01584, val loss: 0.01630\n",
      "Training epoch: 1243, train loss: 0.01532, val loss: 0.01581\n",
      "Training epoch: 1244, train loss: 0.01543, val loss: 0.01600\n",
      "Training epoch: 1245, train loss: 0.01559, val loss: 0.01613\n",
      "Training epoch: 1246, train loss: 0.01559, val loss: 0.01609\n",
      "Training epoch: 1247, train loss: 0.01618, val loss: 0.01665\n",
      "Training epoch: 1248, train loss: 0.01541, val loss: 0.01593\n",
      "Training epoch: 1249, train loss: 0.01550, val loss: 0.01608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1250, train loss: 0.01539, val loss: 0.01590\n",
      "Training epoch: 1251, train loss: 0.01533, val loss: 0.01585\n",
      "Training epoch: 1252, train loss: 0.01562, val loss: 0.01614\n",
      "Training epoch: 1253, train loss: 0.01524, val loss: 0.01574\n",
      "Training epoch: 1254, train loss: 0.01553, val loss: 0.01601\n",
      "Training epoch: 1255, train loss: 0.01529, val loss: 0.01579\n",
      "Training epoch: 1256, train loss: 0.01534, val loss: 0.01588\n",
      "Training epoch: 1257, train loss: 0.01532, val loss: 0.01581\n",
      "Training epoch: 1258, train loss: 0.01528, val loss: 0.01578\n",
      "Training epoch: 1259, train loss: 0.01640, val loss: 0.01694\n",
      "Training epoch: 1260, train loss: 0.01532, val loss: 0.01582\n",
      "Training epoch: 1261, train loss: 0.01548, val loss: 0.01595\n",
      "Training epoch: 1262, train loss: 0.01532, val loss: 0.01584\n",
      "Training epoch: 1263, train loss: 0.01582, val loss: 0.01637\n",
      "Training epoch: 1264, train loss: 0.01577, val loss: 0.01628\n",
      "Training epoch: 1265, train loss: 0.01554, val loss: 0.01608\n",
      "Training epoch: 1266, train loss: 0.01542, val loss: 0.01595\n",
      "Training epoch: 1267, train loss: 0.01536, val loss: 0.01588\n",
      "Training epoch: 1268, train loss: 0.01549, val loss: 0.01601\n",
      "Training epoch: 1269, train loss: 0.01532, val loss: 0.01588\n",
      "Training epoch: 1270, train loss: 0.01564, val loss: 0.01612\n",
      "Training epoch: 1271, train loss: 0.01569, val loss: 0.01621\n",
      "Training epoch: 1272, train loss: 0.01550, val loss: 0.01596\n",
      "Training epoch: 1273, train loss: 0.01521, val loss: 0.01569\n",
      "Training epoch: 1274, train loss: 0.01537, val loss: 0.01588\n",
      "Training epoch: 1275, train loss: 0.01554, val loss: 0.01604\n",
      "Training epoch: 1276, train loss: 0.01530, val loss: 0.01577\n",
      "Training epoch: 1277, train loss: 0.01549, val loss: 0.01600\n",
      "Training epoch: 1278, train loss: 0.01532, val loss: 0.01583\n",
      "Training epoch: 1279, train loss: 0.01535, val loss: 0.01590\n",
      "Training epoch: 1280, train loss: 0.01580, val loss: 0.01627\n",
      "Training epoch: 1281, train loss: 0.01562, val loss: 0.01609\n",
      "Training epoch: 1282, train loss: 0.01555, val loss: 0.01607\n",
      "Training epoch: 1283, train loss: 0.01527, val loss: 0.01576\n",
      "Training epoch: 1284, train loss: 0.01587, val loss: 0.01637\n",
      "Training epoch: 1285, train loss: 0.01545, val loss: 0.01599\n",
      "Training epoch: 1286, train loss: 0.01536, val loss: 0.01589\n",
      "Training epoch: 1287, train loss: 0.01528, val loss: 0.01576\n",
      "Training epoch: 1288, train loss: 0.01526, val loss: 0.01576\n",
      "Training epoch: 1289, train loss: 0.01522, val loss: 0.01574\n",
      "Training epoch: 1290, train loss: 0.01576, val loss: 0.01628\n",
      "Training epoch: 1291, train loss: 0.01556, val loss: 0.01602\n",
      "Training epoch: 1292, train loss: 0.01552, val loss: 0.01601\n",
      "Training epoch: 1293, train loss: 0.01566, val loss: 0.01619\n",
      "Training epoch: 1294, train loss: 0.01536, val loss: 0.01586\n",
      "Training epoch: 1295, train loss: 0.01560, val loss: 0.01608\n",
      "Training epoch: 1296, train loss: 0.01536, val loss: 0.01591\n",
      "Training epoch: 1297, train loss: 0.01576, val loss: 0.01619\n",
      "Training epoch: 1298, train loss: 0.01543, val loss: 0.01594\n",
      "Training epoch: 1299, train loss: 0.01545, val loss: 0.01593\n",
      "Training epoch: 1300, train loss: 0.01553, val loss: 0.01601\n",
      "Training epoch: 1301, train loss: 0.01569, val loss: 0.01622\n",
      "Training epoch: 1302, train loss: 0.01525, val loss: 0.01575\n",
      "Training epoch: 1303, train loss: 0.01540, val loss: 0.01592\n",
      "Training epoch: 1304, train loss: 0.01545, val loss: 0.01598\n",
      "Training epoch: 1305, train loss: 0.01538, val loss: 0.01590\n",
      "Training epoch: 1306, train loss: 0.01528, val loss: 0.01577\n",
      "Training epoch: 1307, train loss: 0.01546, val loss: 0.01595\n",
      "Training epoch: 1308, train loss: 0.01540, val loss: 0.01587\n",
      "Training epoch: 1309, train loss: 0.01526, val loss: 0.01575\n",
      "Training epoch: 1310, train loss: 0.01534, val loss: 0.01586\n",
      "Training epoch: 1311, train loss: 0.01538, val loss: 0.01587\n",
      "Training epoch: 1312, train loss: 0.01543, val loss: 0.01593\n",
      "Training epoch: 1313, train loss: 0.01596, val loss: 0.01649\n",
      "Training epoch: 1314, train loss: 0.01556, val loss: 0.01610\n",
      "Training epoch: 1315, train loss: 0.01533, val loss: 0.01583\n",
      "Training epoch: 1316, train loss: 0.01524, val loss: 0.01574\n",
      "Training epoch: 1317, train loss: 0.01538, val loss: 0.01589\n",
      "Training epoch: 1318, train loss: 0.01532, val loss: 0.01584\n",
      "Training epoch: 1319, train loss: 0.01535, val loss: 0.01586\n",
      "Training epoch: 1320, train loss: 0.01529, val loss: 0.01576\n",
      "Training epoch: 1321, train loss: 0.01548, val loss: 0.01597\n",
      "Training epoch: 1322, train loss: 0.01535, val loss: 0.01586\n",
      "Training epoch: 1323, train loss: 0.01578, val loss: 0.01620\n",
      "Training epoch: 1324, train loss: 0.01529, val loss: 0.01578\n",
      "Training epoch: 1325, train loss: 0.01563, val loss: 0.01616\n",
      "Training epoch: 1326, train loss: 0.01523, val loss: 0.01574\n",
      "Training epoch: 1327, train loss: 0.01556, val loss: 0.01607\n",
      "Training epoch: 1328, train loss: 0.01570, val loss: 0.01620\n",
      "Training epoch: 1329, train loss: 0.01576, val loss: 0.01622\n",
      "Training epoch: 1330, train loss: 0.01536, val loss: 0.01588\n",
      "Training epoch: 1331, train loss: 0.01568, val loss: 0.01614\n",
      "Training epoch: 1332, train loss: 0.01571, val loss: 0.01618\n",
      "Training epoch: 1333, train loss: 0.01550, val loss: 0.01603\n",
      "Training epoch: 1334, train loss: 0.01538, val loss: 0.01589\n",
      "Training epoch: 1335, train loss: 0.01555, val loss: 0.01604\n",
      "Training epoch: 1336, train loss: 0.01540, val loss: 0.01587\n",
      "Training epoch: 1337, train loss: 0.01527, val loss: 0.01578\n",
      "Training epoch: 1338, train loss: 0.01536, val loss: 0.01585\n",
      "Training epoch: 1339, train loss: 0.01564, val loss: 0.01613\n",
      "Training epoch: 1340, train loss: 0.01541, val loss: 0.01592\n",
      "Training epoch: 1341, train loss: 0.01552, val loss: 0.01598\n",
      "Training epoch: 1342, train loss: 0.01545, val loss: 0.01592\n",
      "Training epoch: 1343, train loss: 0.01534, val loss: 0.01585\n",
      "Training epoch: 1344, train loss: 0.01527, val loss: 0.01576\n",
      "Training epoch: 1345, train loss: 0.01556, val loss: 0.01608\n",
      "Training epoch: 1346, train loss: 0.01541, val loss: 0.01593\n",
      "Training epoch: 1347, train loss: 0.01527, val loss: 0.01575\n",
      "Training epoch: 1348, train loss: 0.01536, val loss: 0.01586\n",
      "Training epoch: 1349, train loss: 0.01550, val loss: 0.01598\n",
      "Training epoch: 1350, train loss: 0.01534, val loss: 0.01582\n",
      "Training epoch: 1351, train loss: 0.01563, val loss: 0.01619\n",
      "Training epoch: 1352, train loss: 0.01533, val loss: 0.01583\n",
      "Training epoch: 1353, train loss: 0.01609, val loss: 0.01660\n",
      "Training epoch: 1354, train loss: 0.01570, val loss: 0.01619\n",
      "Training epoch: 1355, train loss: 0.01539, val loss: 0.01587\n",
      "Training epoch: 1356, train loss: 0.01557, val loss: 0.01609\n",
      "Training epoch: 1357, train loss: 0.01567, val loss: 0.01615\n",
      "Training epoch: 1358, train loss: 0.01556, val loss: 0.01607\n",
      "Training epoch: 1359, train loss: 0.01549, val loss: 0.01596\n",
      "Training epoch: 1360, train loss: 0.01533, val loss: 0.01583\n",
      "Training epoch: 1361, train loss: 0.01557, val loss: 0.01607\n",
      "Training epoch: 1362, train loss: 0.01548, val loss: 0.01599\n",
      "Training epoch: 1363, train loss: 0.01537, val loss: 0.01583\n",
      "Training epoch: 1364, train loss: 0.01586, val loss: 0.01637\n",
      "Training epoch: 1365, train loss: 0.01529, val loss: 0.01582\n",
      "Training epoch: 1366, train loss: 0.01541, val loss: 0.01589\n",
      "Training epoch: 1367, train loss: 0.01549, val loss: 0.01598\n",
      "Training epoch: 1368, train loss: 0.01545, val loss: 0.01593\n",
      "Training epoch: 1369, train loss: 0.01541, val loss: 0.01589\n",
      "Training epoch: 1370, train loss: 0.01527, val loss: 0.01575\n",
      "Training epoch: 1371, train loss: 0.01568, val loss: 0.01620\n",
      "Training epoch: 1372, train loss: 0.01563, val loss: 0.01609\n",
      "Training epoch: 1373, train loss: 0.01545, val loss: 0.01591\n",
      "Training epoch: 1374, train loss: 0.01559, val loss: 0.01606\n",
      "Training epoch: 1375, train loss: 0.01531, val loss: 0.01581\n",
      "Training epoch: 1376, train loss: 0.01535, val loss: 0.01585\n",
      "Training epoch: 1377, train loss: 0.01522, val loss: 0.01567\n",
      "Training epoch: 1378, train loss: 0.01573, val loss: 0.01625\n",
      "Training epoch: 1379, train loss: 0.01559, val loss: 0.01610\n",
      "Training epoch: 1380, train loss: 0.01547, val loss: 0.01596\n",
      "Training epoch: 1381, train loss: 0.01526, val loss: 0.01574\n",
      "Training epoch: 1382, train loss: 0.01528, val loss: 0.01578\n",
      "Training epoch: 1383, train loss: 0.01556, val loss: 0.01605\n",
      "Training epoch: 1384, train loss: 0.01543, val loss: 0.01592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1385, train loss: 0.01563, val loss: 0.01614\n",
      "Training epoch: 1386, train loss: 0.01543, val loss: 0.01592\n",
      "Training epoch: 1387, train loss: 0.01533, val loss: 0.01580\n",
      "Training epoch: 1388, train loss: 0.01534, val loss: 0.01583\n",
      "Training epoch: 1389, train loss: 0.01525, val loss: 0.01575\n",
      "Training epoch: 1390, train loss: 0.01562, val loss: 0.01612\n",
      "Training epoch: 1391, train loss: 0.01537, val loss: 0.01586\n",
      "Training epoch: 1392, train loss: 0.01547, val loss: 0.01599\n",
      "Training epoch: 1393, train loss: 0.01569, val loss: 0.01618\n",
      "Training epoch: 1394, train loss: 0.01536, val loss: 0.01585\n",
      "Training epoch: 1395, train loss: 0.01540, val loss: 0.01591\n",
      "Training epoch: 1396, train loss: 0.01554, val loss: 0.01607\n",
      "Training epoch: 1397, train loss: 0.01552, val loss: 0.01600\n",
      "Training epoch: 1398, train loss: 0.01535, val loss: 0.01580\n",
      "Training epoch: 1399, train loss: 0.01591, val loss: 0.01645\n",
      "Training epoch: 1400, train loss: 0.01532, val loss: 0.01580\n",
      "Training epoch: 1401, train loss: 0.01532, val loss: 0.01579\n",
      "Training epoch: 1402, train loss: 0.01533, val loss: 0.01580\n",
      "Training epoch: 1403, train loss: 0.01540, val loss: 0.01592\n",
      "Training epoch: 1404, train loss: 0.01524, val loss: 0.01572\n",
      "Training epoch: 1405, train loss: 0.01538, val loss: 0.01584\n",
      "Training epoch: 1406, train loss: 0.01533, val loss: 0.01583\n",
      "Training epoch: 1407, train loss: 0.01532, val loss: 0.01579\n",
      "Training epoch: 1408, train loss: 0.01578, val loss: 0.01627\n",
      "Training epoch: 1409, train loss: 0.01598, val loss: 0.01645\n",
      "Training epoch: 1410, train loss: 0.01547, val loss: 0.01597\n",
      "Training epoch: 1411, train loss: 0.01550, val loss: 0.01596\n",
      "Training epoch: 1412, train loss: 0.01523, val loss: 0.01574\n",
      "Training epoch: 1413, train loss: 0.01565, val loss: 0.01614\n",
      "Training epoch: 1414, train loss: 0.01558, val loss: 0.01605\n",
      "Training epoch: 1415, train loss: 0.01595, val loss: 0.01644\n",
      "Training epoch: 1416, train loss: 0.01588, val loss: 0.01638\n",
      "Training epoch: 1417, train loss: 0.01550, val loss: 0.01602\n",
      "Training epoch: 1418, train loss: 0.01627, val loss: 0.01680\n",
      "Training epoch: 1419, train loss: 0.01550, val loss: 0.01600\n",
      "Training epoch: 1420, train loss: 0.01546, val loss: 0.01595\n",
      "Training epoch: 1421, train loss: 0.01544, val loss: 0.01589\n",
      "Training epoch: 1422, train loss: 0.01526, val loss: 0.01575\n",
      "Training epoch: 1423, train loss: 0.01538, val loss: 0.01589\n",
      "Training epoch: 1424, train loss: 0.01540, val loss: 0.01590\n",
      "Training epoch: 1425, train loss: 0.01538, val loss: 0.01587\n",
      "Training epoch: 1426, train loss: 0.01598, val loss: 0.01647\n",
      "Training epoch: 1427, train loss: 0.01632, val loss: 0.01683\n",
      "Training epoch: 1428, train loss: 0.01570, val loss: 0.01615\n",
      "Training epoch: 1429, train loss: 0.01547, val loss: 0.01599\n",
      "Training epoch: 1430, train loss: 0.01565, val loss: 0.01621\n",
      "Training epoch: 1431, train loss: 0.01575, val loss: 0.01626\n",
      "Training epoch: 1432, train loss: 0.01522, val loss: 0.01571\n",
      "Training epoch: 1433, train loss: 0.01552, val loss: 0.01604\n",
      "Training epoch: 1434, train loss: 0.01538, val loss: 0.01586\n",
      "Training epoch: 1435, train loss: 0.01563, val loss: 0.01612\n",
      "Training epoch: 1436, train loss: 0.01580, val loss: 0.01628\n",
      "Training epoch: 1437, train loss: 0.01550, val loss: 0.01600\n",
      "Training epoch: 1438, train loss: 0.01550, val loss: 0.01596\n",
      "Training epoch: 1439, train loss: 0.01532, val loss: 0.01581\n",
      "Training epoch: 1440, train loss: 0.01532, val loss: 0.01583\n",
      "Training epoch: 1441, train loss: 0.01537, val loss: 0.01586\n",
      "Training epoch: 1442, train loss: 0.01546, val loss: 0.01591\n",
      "Training epoch: 1443, train loss: 0.01547, val loss: 0.01597\n",
      "Training epoch: 1444, train loss: 0.01567, val loss: 0.01616\n",
      "Training epoch: 1445, train loss: 0.01539, val loss: 0.01585\n",
      "Training epoch: 1446, train loss: 0.01585, val loss: 0.01636\n",
      "Training epoch: 1447, train loss: 0.01555, val loss: 0.01596\n",
      "Training epoch: 1448, train loss: 0.01614, val loss: 0.01663\n",
      "Training epoch: 1449, train loss: 0.01535, val loss: 0.01584\n",
      "Training epoch: 1450, train loss: 0.01697, val loss: 0.01746\n",
      "Training epoch: 1451, train loss: 0.01609, val loss: 0.01659\n",
      "Training epoch: 1452, train loss: 0.01544, val loss: 0.01590\n",
      "Training epoch: 1453, train loss: 0.01535, val loss: 0.01582\n",
      "Training epoch: 1454, train loss: 0.01571, val loss: 0.01622\n",
      "Training epoch: 1455, train loss: 0.01570, val loss: 0.01618\n",
      "Training epoch: 1456, train loss: 0.01528, val loss: 0.01575\n",
      "Training epoch: 1457, train loss: 0.01534, val loss: 0.01578\n",
      "Training epoch: 1458, train loss: 0.01541, val loss: 0.01590\n",
      "Training epoch: 1459, train loss: 0.01614, val loss: 0.01667\n",
      "Training epoch: 1460, train loss: 0.01590, val loss: 0.01641\n",
      "Training epoch: 1461, train loss: 0.01547, val loss: 0.01595\n",
      "Training epoch: 1462, train loss: 0.01546, val loss: 0.01595\n",
      "Training epoch: 1463, train loss: 0.01538, val loss: 0.01588\n",
      "Training epoch: 1464, train loss: 0.01621, val loss: 0.01670\n",
      "Training epoch: 1465, train loss: 0.01559, val loss: 0.01608\n",
      "Training epoch: 1466, train loss: 0.01595, val loss: 0.01645\n",
      "Training epoch: 1467, train loss: 0.01533, val loss: 0.01581\n",
      "Training epoch: 1468, train loss: 0.01530, val loss: 0.01577\n",
      "Training epoch: 1469, train loss: 0.01558, val loss: 0.01603\n",
      "Training epoch: 1470, train loss: 0.01541, val loss: 0.01588\n",
      "Training epoch: 1471, train loss: 0.01524, val loss: 0.01571\n",
      "Training epoch: 1472, train loss: 0.01544, val loss: 0.01593\n",
      "Training epoch: 1473, train loss: 0.01529, val loss: 0.01579\n",
      "Training epoch: 1474, train loss: 0.01603, val loss: 0.01652\n",
      "Training epoch: 1475, train loss: 0.01575, val loss: 0.01626\n",
      "Training epoch: 1476, train loss: 0.01539, val loss: 0.01585\n",
      "Training epoch: 1477, train loss: 0.01531, val loss: 0.01583\n",
      "Training epoch: 1478, train loss: 0.01532, val loss: 0.01576\n",
      "Training epoch: 1479, train loss: 0.01568, val loss: 0.01614\n",
      "Training epoch: 1480, train loss: 0.01545, val loss: 0.01591\n",
      "Training epoch: 1481, train loss: 0.01610, val loss: 0.01661\n",
      "Training epoch: 1482, train loss: 0.01535, val loss: 0.01582\n",
      "Training epoch: 1483, train loss: 0.01529, val loss: 0.01575\n",
      "Training epoch: 1484, train loss: 0.01565, val loss: 0.01613\n",
      "Training epoch: 1485, train loss: 0.01535, val loss: 0.01581\n",
      "Training epoch: 1486, train loss: 0.01586, val loss: 0.01639\n",
      "Training epoch: 1487, train loss: 0.01544, val loss: 0.01593\n",
      "Training epoch: 1488, train loss: 0.01555, val loss: 0.01604\n",
      "Training epoch: 1489, train loss: 0.01595, val loss: 0.01645\n",
      "Training epoch: 1490, train loss: 0.01559, val loss: 0.01603\n",
      "Training epoch: 1491, train loss: 0.01561, val loss: 0.01605\n",
      "Training epoch: 1492, train loss: 0.01524, val loss: 0.01573\n",
      "Training epoch: 1493, train loss: 0.01547, val loss: 0.01592\n",
      "Training epoch: 1494, train loss: 0.01533, val loss: 0.01580\n",
      "Training epoch: 1495, train loss: 0.01571, val loss: 0.01614\n",
      "Training epoch: 1496, train loss: 0.01541, val loss: 0.01591\n",
      "Training epoch: 1497, train loss: 0.01549, val loss: 0.01595\n",
      "Training epoch: 1498, train loss: 0.01592, val loss: 0.01642\n",
      "Training epoch: 1499, train loss: 0.01556, val loss: 0.01608\n",
      "Training epoch: 1500, train loss: 0.01564, val loss: 0.01612\n",
      "Training epoch: 1501, train loss: 0.01529, val loss: 0.01576\n",
      "Training epoch: 1502, train loss: 0.01552, val loss: 0.01599\n",
      "Training epoch: 1503, train loss: 0.01536, val loss: 0.01585\n",
      "Training epoch: 1504, train loss: 0.01547, val loss: 0.01597\n",
      "Training epoch: 1505, train loss: 0.01546, val loss: 0.01593\n",
      "Training epoch: 1506, train loss: 0.01537, val loss: 0.01584\n",
      "Training epoch: 1507, train loss: 0.01560, val loss: 0.01612\n",
      "Training epoch: 1508, train loss: 0.01541, val loss: 0.01592\n",
      "Training epoch: 1509, train loss: 0.01532, val loss: 0.01577\n",
      "Training epoch: 1510, train loss: 0.01531, val loss: 0.01576\n",
      "Training epoch: 1511, train loss: 0.01529, val loss: 0.01578\n",
      "Training epoch: 1512, train loss: 0.01579, val loss: 0.01629\n",
      "Training epoch: 1513, train loss: 0.01551, val loss: 0.01600\n",
      "Training epoch: 1514, train loss: 0.01538, val loss: 0.01583\n",
      "Training epoch: 1515, train loss: 0.01573, val loss: 0.01619\n",
      "Training epoch: 1516, train loss: 0.01534, val loss: 0.01583\n",
      "Training epoch: 1517, train loss: 0.01527, val loss: 0.01573\n",
      "Training epoch: 1518, train loss: 0.01552, val loss: 0.01602\n",
      "Training epoch: 1519, train loss: 0.01537, val loss: 0.01586\n",
      "Training epoch: 1520, train loss: 0.01564, val loss: 0.01611\n",
      "Training epoch: 1521, train loss: 0.01537, val loss: 0.01585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1522, train loss: 0.01523, val loss: 0.01571\n",
      "Training epoch: 1523, train loss: 0.01559, val loss: 0.01602\n",
      "Training epoch: 1524, train loss: 0.01528, val loss: 0.01574\n",
      "Training epoch: 1525, train loss: 0.01594, val loss: 0.01644\n",
      "Training epoch: 1526, train loss: 0.01524, val loss: 0.01570\n",
      "Training epoch: 1527, train loss: 0.01593, val loss: 0.01634\n",
      "Training epoch: 1528, train loss: 0.01543, val loss: 0.01592\n",
      "Training epoch: 1529, train loss: 0.01553, val loss: 0.01600\n",
      "Training epoch: 1530, train loss: 0.01527, val loss: 0.01574\n",
      "Training epoch: 1531, train loss: 0.01539, val loss: 0.01587\n",
      "Training epoch: 1532, train loss: 0.01577, val loss: 0.01631\n",
      "Training epoch: 1533, train loss: 0.01553, val loss: 0.01602\n",
      "Training epoch: 1534, train loss: 0.01578, val loss: 0.01627\n",
      "Training epoch: 1535, train loss: 0.01556, val loss: 0.01597\n",
      "Training epoch: 1536, train loss: 0.01540, val loss: 0.01586\n",
      "Training epoch: 1537, train loss: 0.01540, val loss: 0.01582\n",
      "Training epoch: 1538, train loss: 0.01550, val loss: 0.01597\n",
      "Training epoch: 1539, train loss: 0.01612, val loss: 0.01659\n",
      "Training epoch: 1540, train loss: 0.01535, val loss: 0.01582\n",
      "Training epoch: 1541, train loss: 0.01596, val loss: 0.01645\n",
      "Training epoch: 1542, train loss: 0.01526, val loss: 0.01571\n",
      "Training epoch: 1543, train loss: 0.01525, val loss: 0.01570\n",
      "Training epoch: 1544, train loss: 0.01561, val loss: 0.01609\n",
      "Training epoch: 1545, train loss: 0.01564, val loss: 0.01615\n",
      "Training epoch: 1546, train loss: 0.01722, val loss: 0.01771\n",
      "Training epoch: 1547, train loss: 0.01538, val loss: 0.01585\n",
      "Training epoch: 1548, train loss: 0.01535, val loss: 0.01579\n",
      "Training epoch: 1549, train loss: 0.01544, val loss: 0.01593\n",
      "Training epoch: 1550, train loss: 0.01544, val loss: 0.01592\n",
      "Training epoch: 1551, train loss: 0.01543, val loss: 0.01589\n",
      "Training epoch: 1552, train loss: 0.01561, val loss: 0.01606\n",
      "Training epoch: 1553, train loss: 0.01566, val loss: 0.01609\n",
      "Training epoch: 1554, train loss: 0.01536, val loss: 0.01585\n",
      "Training epoch: 1555, train loss: 0.01564, val loss: 0.01611\n",
      "Training epoch: 1556, train loss: 0.01561, val loss: 0.01608\n",
      "Training epoch: 1557, train loss: 0.01554, val loss: 0.01595\n",
      "Training epoch: 1558, train loss: 0.01577, val loss: 0.01618\n",
      "Training epoch: 1559, train loss: 0.01539, val loss: 0.01587\n",
      "Training epoch: 1560, train loss: 0.01535, val loss: 0.01583\n",
      "Training epoch: 1561, train loss: 0.01569, val loss: 0.01616\n",
      "Training epoch: 1562, train loss: 0.01554, val loss: 0.01604\n",
      "Training epoch: 1563, train loss: 0.01645, val loss: 0.01694\n",
      "Training epoch: 1564, train loss: 0.01560, val loss: 0.01606\n",
      "Training epoch: 1565, train loss: 0.01526, val loss: 0.01574\n",
      "Training epoch: 1566, train loss: 0.01532, val loss: 0.01579\n",
      "Training epoch: 1567, train loss: 0.01536, val loss: 0.01584\n",
      "Training epoch: 1568, train loss: 0.01573, val loss: 0.01620\n",
      "Training epoch: 1569, train loss: 0.01550, val loss: 0.01596\n",
      "Training epoch: 1570, train loss: 0.01553, val loss: 0.01600\n",
      "Training epoch: 1571, train loss: 0.01544, val loss: 0.01590\n",
      "Training epoch: 1572, train loss: 0.01548, val loss: 0.01595\n",
      "Training epoch: 1573, train loss: 0.01528, val loss: 0.01577\n",
      "Training epoch: 1574, train loss: 0.01521, val loss: 0.01568\n",
      "Training epoch: 1575, train loss: 0.01563, val loss: 0.01611\n",
      "Training epoch: 1576, train loss: 0.01611, val loss: 0.01660\n",
      "Training epoch: 1577, train loss: 0.01562, val loss: 0.01609\n",
      "Training epoch: 1578, train loss: 0.01523, val loss: 0.01571\n",
      "Early stop at epoch 1578, With Testing Error: 0.01571\n",
      "Subnetwork pruning.\n",
      "Fine tuning.\n",
      "Tuning epoch: 1, train loss: 0.01547, val loss: 0.01602\n",
      "Tuning epoch: 2, train loss: 0.01563, val loss: 0.01624\n",
      "Tuning epoch: 3, train loss: 0.01584, val loss: 0.01643\n",
      "Tuning epoch: 4, train loss: 0.01574, val loss: 0.01629\n",
      "Tuning epoch: 5, train loss: 0.01535, val loss: 0.01589\n",
      "Tuning epoch: 6, train loss: 0.01617, val loss: 0.01681\n",
      "Tuning epoch: 7, train loss: 0.01565, val loss: 0.01621\n",
      "Tuning epoch: 8, train loss: 0.01564, val loss: 0.01621\n",
      "Tuning epoch: 9, train loss: 0.01548, val loss: 0.01606\n",
      "Tuning epoch: 10, train loss: 0.01559, val loss: 0.01615\n",
      "Tuning epoch: 11, train loss: 0.01536, val loss: 0.01588\n",
      "Tuning epoch: 12, train loss: 0.01537, val loss: 0.01591\n",
      "Tuning epoch: 13, train loss: 0.01616, val loss: 0.01674\n",
      "Tuning epoch: 14, train loss: 0.01544, val loss: 0.01599\n",
      "Tuning epoch: 15, train loss: 0.01563, val loss: 0.01613\n",
      "Tuning epoch: 16, train loss: 0.01633, val loss: 0.01687\n",
      "Tuning epoch: 17, train loss: 0.01638, val loss: 0.01694\n",
      "Tuning epoch: 18, train loss: 0.01625, val loss: 0.01684\n",
      "Tuning epoch: 19, train loss: 0.01546, val loss: 0.01599\n",
      "Tuning epoch: 20, train loss: 0.01537, val loss: 0.01593\n",
      "Tuning epoch: 21, train loss: 0.01555, val loss: 0.01603\n",
      "Tuning epoch: 22, train loss: 0.01578, val loss: 0.01634\n",
      "Tuning epoch: 23, train loss: 0.01542, val loss: 0.01600\n",
      "Tuning epoch: 24, train loss: 0.01575, val loss: 0.01633\n",
      "Tuning epoch: 25, train loss: 0.01540, val loss: 0.01595\n",
      "Tuning epoch: 26, train loss: 0.01584, val loss: 0.01638\n",
      "Tuning epoch: 27, train loss: 0.01576, val loss: 0.01636\n",
      "Tuning epoch: 28, train loss: 0.01552, val loss: 0.01605\n",
      "Tuning epoch: 29, train loss: 0.01552, val loss: 0.01603\n",
      "Tuning epoch: 30, train loss: 0.01586, val loss: 0.01645\n",
      "Tuning epoch: 31, train loss: 0.01569, val loss: 0.01627\n",
      "Tuning epoch: 32, train loss: 0.01562, val loss: 0.01617\n",
      "Tuning epoch: 33, train loss: 0.01539, val loss: 0.01593\n",
      "Tuning epoch: 34, train loss: 0.01541, val loss: 0.01593\n",
      "Tuning epoch: 35, train loss: 0.01554, val loss: 0.01609\n",
      "Tuning epoch: 36, train loss: 0.01535, val loss: 0.01590\n",
      "Tuning epoch: 37, train loss: 0.01539, val loss: 0.01593\n",
      "Tuning epoch: 38, train loss: 0.01592, val loss: 0.01648\n",
      "Tuning epoch: 39, train loss: 0.01567, val loss: 0.01620\n",
      "Tuning epoch: 40, train loss: 0.01564, val loss: 0.01617\n",
      "Tuning epoch: 41, train loss: 0.01577, val loss: 0.01627\n",
      "Tuning epoch: 42, train loss: 0.01555, val loss: 0.01609\n",
      "Tuning epoch: 43, train loss: 0.01550, val loss: 0.01601\n",
      "Tuning epoch: 44, train loss: 0.01602, val loss: 0.01657\n",
      "Tuning epoch: 45, train loss: 0.01567, val loss: 0.01624\n",
      "Tuning epoch: 46, train loss: 0.01533, val loss: 0.01589\n",
      "Tuning epoch: 47, train loss: 0.01543, val loss: 0.01593\n",
      "Tuning epoch: 48, train loss: 0.01561, val loss: 0.01614\n",
      "Tuning epoch: 49, train loss: 0.01560, val loss: 0.01617\n",
      "Tuning epoch: 50, train loss: 0.01535, val loss: 0.01588\n",
      "Tuning epoch: 51, train loss: 0.01535, val loss: 0.01587\n",
      "Tuning epoch: 52, train loss: 0.01574, val loss: 0.01631\n",
      "Tuning epoch: 53, train loss: 0.01553, val loss: 0.01607\n",
      "Tuning epoch: 54, train loss: 0.01583, val loss: 0.01640\n",
      "Tuning epoch: 55, train loss: 0.01534, val loss: 0.01590\n",
      "Tuning epoch: 56, train loss: 0.01595, val loss: 0.01653\n",
      "Tuning epoch: 57, train loss: 0.01567, val loss: 0.01621\n",
      "Tuning epoch: 58, train loss: 0.01548, val loss: 0.01603\n",
      "Tuning epoch: 59, train loss: 0.01573, val loss: 0.01630\n",
      "Tuning epoch: 60, train loss: 0.01553, val loss: 0.01606\n",
      "Tuning epoch: 61, train loss: 0.01542, val loss: 0.01598\n",
      "Tuning epoch: 62, train loss: 0.01541, val loss: 0.01597\n",
      "Tuning epoch: 63, train loss: 0.01541, val loss: 0.01594\n",
      "Tuning epoch: 64, train loss: 0.01575, val loss: 0.01624\n",
      "Tuning epoch: 65, train loss: 0.01550, val loss: 0.01603\n",
      "Tuning epoch: 66, train loss: 0.01559, val loss: 0.01616\n",
      "Tuning epoch: 67, train loss: 0.01655, val loss: 0.01712\n",
      "Tuning epoch: 68, train loss: 0.01582, val loss: 0.01639\n",
      "Tuning epoch: 69, train loss: 0.01582, val loss: 0.01634\n",
      "Tuning epoch: 70, train loss: 0.01555, val loss: 0.01607\n",
      "Tuning epoch: 71, train loss: 0.01539, val loss: 0.01596\n",
      "Tuning epoch: 72, train loss: 0.01614, val loss: 0.01673\n",
      "Tuning epoch: 73, train loss: 0.01584, val loss: 0.01641\n",
      "Tuning epoch: 74, train loss: 0.01559, val loss: 0.01615\n",
      "Tuning epoch: 75, train loss: 0.01638, val loss: 0.01683\n",
      "Tuning epoch: 76, train loss: 0.01571, val loss: 0.01626\n",
      "Tuning epoch: 77, train loss: 0.01538, val loss: 0.01594\n",
      "Tuning epoch: 78, train loss: 0.01563, val loss: 0.01619\n",
      "Tuning epoch: 79, train loss: 0.01544, val loss: 0.01604\n",
      "Tuning epoch: 80, train loss: 0.01550, val loss: 0.01601\n",
      "Tuning epoch: 81, train loss: 0.01546, val loss: 0.01601\n",
      "Tuning epoch: 82, train loss: 0.01536, val loss: 0.01591\n",
      "Tuning epoch: 83, train loss: 0.01541, val loss: 0.01596\n",
      "Tuning epoch: 84, train loss: 0.01543, val loss: 0.01595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning epoch: 85, train loss: 0.01542, val loss: 0.01597\n",
      "Tuning epoch: 86, train loss: 0.01547, val loss: 0.01601\n",
      "Tuning epoch: 87, train loss: 0.01552, val loss: 0.01609\n",
      "Tuning epoch: 88, train loss: 0.01583, val loss: 0.01637\n",
      "Tuning epoch: 89, train loss: 0.01546, val loss: 0.01597\n",
      "Tuning epoch: 90, train loss: 0.01615, val loss: 0.01674\n",
      "Tuning epoch: 91, train loss: 0.01579, val loss: 0.01635\n",
      "Tuning epoch: 92, train loss: 0.01570, val loss: 0.01621\n",
      "Tuning epoch: 93, train loss: 0.01569, val loss: 0.01624\n",
      "Tuning epoch: 94, train loss: 0.01559, val loss: 0.01616\n",
      "Tuning epoch: 95, train loss: 0.01543, val loss: 0.01597\n",
      "Tuning epoch: 96, train loss: 0.01538, val loss: 0.01592\n",
      "Tuning epoch: 97, train loss: 0.01608, val loss: 0.01663\n",
      "Tuning epoch: 98, train loss: 0.01538, val loss: 0.01591\n",
      "Tuning epoch: 99, train loss: 0.01546, val loss: 0.01604\n",
      "Tuning epoch: 100, train loss: 0.01555, val loss: 0.01610\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from exnn import ExNN\n",
    "\n",
    "def data_generator1(datanum, testnum=10000, noise_sigma=1, rand_seed=0):\n",
    "    \n",
    "    corr = 0.5\n",
    "    np.random.seed(rand_seed)\n",
    "    proj_matrix = np.zeros((10, 4))\n",
    "    proj_matrix[:7, 0] = np.array([1,0,0,0,0,0,0])\n",
    "    proj_matrix[:7, 1] = np.array([0,1,0,0,0,0,0])\n",
    "    proj_matrix[:7, 2] = np.array([0,0,0.5,0.5,0,0,0])\n",
    "    proj_matrix[:7, 3] = np.array([0,0,0,0,0.2,0.3,0.5])\n",
    "    u = np.random.uniform(-1, 1, [datanum + testnum, 1])\n",
    "    t = np.sqrt(corr / (1 - corr))\n",
    "    x = np.zeros((datanum + testnum, 10))\n",
    "    for i in range(10):\n",
    "        x[:, i:i + 1] = (np.random.uniform(-1, 1, [datanum + testnum, 1]) + t * u) / (1 + t)\n",
    "\n",
    "    y = np.reshape(2 * np.dot(x, proj_matrix[:, 0]) + 0.2 * np.exp(-4 * np.dot(x, proj_matrix[:, 1])) + \\\n",
    "                   3 * (np.dot(x, proj_matrix[:, 2]))**2 + 2.5 * np.sin(np.pi * np.dot(x, proj_matrix[:, 3])), [-1, 1]) + \\\n",
    "              noise_sigma * np.random.normal(0, 1, [datanum + testnum, 1])\n",
    "    \n",
    "    task_type = \"Regression\"\n",
    "    meta_info = {\"X1\":{\"type\":\"continuous\"},\n",
    "             \"X2\":{\"type\":\"continuous\"},\n",
    "             \"X3\":{\"type\":\"continuous\"},\n",
    "             \"X4\":{\"type\":\"continuous\"},\n",
    "             \"X5\":{\"type\":\"continuous\"},\n",
    "             \"X6\":{\"type\":\"continuous\"},\n",
    "             \"X7\":{\"type\":\"continuous\"},\n",
    "             \"X8\":{\"type\":\"continuous\"},\n",
    "             \"X9\":{\"type\":\"continuous\"},\n",
    "             \"X10\":{\"type\":\"continuous\"},\n",
    "             \"Y\":{\"type\":\"target\"}}\n",
    "    for i, (key, item) in enumerate(meta_info.items()):\n",
    "        if item['type'] == \"target\":\n",
    "            sy = MinMaxScaler((-1, 1))\n",
    "            y = sy.fit_transform(y)\n",
    "            meta_info[key][\"scaler\"] = sy\n",
    "        elif item['type'] == \"categorical\":\n",
    "            enc = OrdinalEncoder()\n",
    "            enc.fit(x[:,[i]])\n",
    "            ordinal_feature = enc.transform(x[:,[i]])\n",
    "            x[:,[i]] = ordinal_feature\n",
    "            meta_info[key][\"values\"] = enc.categories_[0].tolist()\n",
    "        else:\n",
    "            sx = MinMaxScaler((-1, 1))\n",
    "            x[:,[i]] = sx.fit_transform(x[:,[i]])\n",
    "            meta_info[key][\"scaler\"] = sx\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=testnum, random_state=rand_seed)\n",
    "    return train_x, test_x, train_y, test_y, task_type, meta_info\n",
    "\n",
    "train_x, test_x, train_y, test_y, task_type, meta_info = data_generator1(datanum=10000, testnum=10000, noise_sigma=1, rand_seed=0)\n",
    "model = ExNN(meta_info=meta_info,\n",
    "               subnet_num=10,\n",
    "               subnet_arch=[10, 6],\n",
    "               task_type=task_type,\n",
    "               activation_func=tf.tanh,\n",
    "               batch_size=min(1000, int(train_x.shape[0] * 0.2)),\n",
    "               training_epochs=5000,\n",
    "               lr_bp=0.001,\n",
    "               lr_cl=0.1,\n",
    "               beta_threshold=0.05,\n",
    "               tuning_epochs=100,\n",
    "               l1_proj=0.0001,\n",
    "               l1_subnet=0.00316,\n",
    "               l2_smooth=10**(-6),\n",
    "               verbose=True,\n",
    "               val_ratio=0.2,\n",
    "               early_stop_thres=200)\n",
    "\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T06:15:34.591483Z",
     "start_time": "2020-07-21T06:15:33.205436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x1296 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.visualize(folder=\"./\", name=\"exnn_demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T06:15:34.875137Z",
     "start_time": "2020-07-21T06:15:34.593311Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'active_subnets_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-84bbf4d21978>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols_per_row\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubnet_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_subnet_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"exnn_demo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2_local/envs/tf2/lib/python3.6/site-packages/exnn/base.py\u001b[0m in \u001b[0;36mvisualize_new\u001b[0;34m(self, cols_per_row, subnet_num, dummy_subnet_num, folder, name, save_png, save_eps)\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mactive_subnets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_subnets_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubnet_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0mactive_dummy_subnets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dummy_subnets_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_subnet_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m         \u001b[0mmax_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive_subnets_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive_dummy_subnets_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcols_per_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.6\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_ids\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcols_per_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mouter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgridspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGridSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_ids\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcols_per_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_per_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'active_subnets_' is not defined"
     ]
    }
   ],
   "source": [
    "model.visualize_new(cols_per_row=3, subnet_num=3, dummy_subnet_num=0, folder=\"./\", name=\"exnn_demo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf2)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
