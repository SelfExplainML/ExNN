{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from xnn import GAMNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator1(datanum, testnum=10000, noise_sigma=1, rand_seed=0):\n",
    "    \n",
    "    corr = 0.5\n",
    "    np.random.seed(rand_seed)\n",
    "    proj_matrix = np.zeros((10, 4))\n",
    "    proj_matrix[:7, 0] = np.array([1,0,0,0,0,0,0])\n",
    "    proj_matrix[:7, 1] = np.array([0,1,0,0,0,0,0])\n",
    "    proj_matrix[:7, 2] = np.array([0,0,0.5,0.5,0,0,0])\n",
    "    proj_matrix[:7, 3] = np.array([0,0,0,0,0.2,0.3,0.5])\n",
    "    u = np.random.uniform(-1, 1, [datanum + testnum, 1])\n",
    "    t = np.sqrt(corr / (1 - corr))\n",
    "    x = np.zeros((datanum + testnum, 10))\n",
    "    for i in range(10):\n",
    "        x[:, i:i + 1] = (np.random.uniform(-1, 1, [datanum + testnum, 1]) + t * u) / (1 + t)\n",
    "\n",
    "    y = np.reshape(2 * np.dot(x, proj_matrix[:, 0]) + 0.2 * np.exp(-4 * np.dot(x, proj_matrix[:, 1])) + \\\n",
    "                   3 * (np.dot(x, proj_matrix[:, 2]))**2 + 2.5 * np.sin(np.pi * np.dot(x, proj_matrix[:, 3])), [-1, 1]) + \\\n",
    "              noise_sigma * np.random.normal(0, 1, [datanum + testnum, 1])\n",
    "    \n",
    "    task_type = \"Regression\"\n",
    "    meta_info = {\"X1\":{\"type\":\"continuous\"},\n",
    "             \"X2\":{\"type\":\"continuous\"},\n",
    "             \"X3\":{\"type\":\"continuous\"},\n",
    "             \"X4\":{\"type\":\"continuous\"},\n",
    "             \"X5\":{\"type\":\"continuous\"},\n",
    "             \"X6\":{\"type\":\"continuous\"},\n",
    "             \"X7\":{\"type\":\"continuous\"},\n",
    "             \"X8\":{\"type\":\"continuous\"},\n",
    "             \"X9\":{\"type\":\"continuous\"},\n",
    "             \"X10\":{\"type\":\"continuous\"},\n",
    "             \"Y\":{\"type\":\"target\"}}\n",
    "    for i, (key, item) in enumerate(meta_info.items()):\n",
    "        if item['type'] == \"target\":\n",
    "            sy = MinMaxScaler((-1, 1))\n",
    "            y = sy.fit_transform(y)\n",
    "            meta_info[key][\"scaler\"] = sy\n",
    "        elif item['type'] == \"categorical\":\n",
    "            enc = OrdinalEncoder()\n",
    "            enc.fit(x[:,[i]])\n",
    "            ordinal_feature = enc.transform(x[:,[i]])\n",
    "            x[:,[i]] = ordinal_feature\n",
    "            meta_info[key][\"values\"] = enc.categories_[0].tolist()\n",
    "        else:\n",
    "            sx = MinMaxScaler((-1, 1))\n",
    "            x[:,[i]] = sx.fit_transform(x[:,[i]])\n",
    "            meta_info[key][\"scaler\"] = sx\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=testnum, random_state=rand_seed)\n",
    "    return train_x, test_x, train_y, test_y, task_type, meta_info\n",
    "\n",
    "train_x, test_x, train_y, test_y, task_type, meta_info = data_generator1(datanum=10000, testnum=10000, noise_sigma=1, rand_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0824 23:51:20.502281 140414761764672 deprecation.py:323] From /home/r7user1/anaconda2_local/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1220: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1, train loss: 2.64600, val loss: 2.55468\n",
      "Training epoch: 2, train loss: 1.56202, val loss: 1.51955\n",
      "Training epoch: 3, train loss: 0.90726, val loss: 0.89689\n",
      "Training epoch: 4, train loss: 0.52213, val loss: 0.51681\n",
      "Training epoch: 5, train loss: 0.50752, val loss: 0.50266\n",
      "Training epoch: 6, train loss: 0.49964, val loss: 0.49563\n",
      "Training epoch: 7, train loss: 0.49207, val loss: 0.48888\n",
      "Training epoch: 8, train loss: 0.48383, val loss: 0.48039\n",
      "Training epoch: 9, train loss: 0.47556, val loss: 0.47327\n",
      "Training epoch: 10, train loss: 0.46734, val loss: 0.46487\n",
      "Training epoch: 11, train loss: 0.45869, val loss: 0.45635\n",
      "Training epoch: 12, train loss: 0.45070, val loss: 0.44833\n",
      "Training epoch: 13, train loss: 0.44287, val loss: 0.44098\n",
      "Training epoch: 14, train loss: 0.43490, val loss: 0.43333\n",
      "Training epoch: 15, train loss: 0.42679, val loss: 0.42516\n",
      "Training epoch: 16, train loss: 0.41891, val loss: 0.41811\n",
      "Training epoch: 17, train loss: 0.41078, val loss: 0.40979\n",
      "Training epoch: 18, train loss: 0.40399, val loss: 0.40437\n",
      "Training epoch: 19, train loss: 0.39785, val loss: 0.39787\n",
      "Training epoch: 20, train loss: 0.39035, val loss: 0.39118\n",
      "Training epoch: 21, train loss: 0.38266, val loss: 0.38398\n",
      "Training epoch: 22, train loss: 0.37452, val loss: 0.37515\n",
      "Training epoch: 23, train loss: 0.36647, val loss: 0.36827\n",
      "Training epoch: 24, train loss: 0.35740, val loss: 0.35810\n",
      "Training epoch: 25, train loss: 0.34896, val loss: 0.34981\n",
      "Training epoch: 26, train loss: 0.34053, val loss: 0.34217\n",
      "Training epoch: 27, train loss: 0.33276, val loss: 0.33439\n",
      "Training epoch: 28, train loss: 0.32566, val loss: 0.32749\n",
      "Training epoch: 29, train loss: 0.31787, val loss: 0.31907\n",
      "Training epoch: 30, train loss: 0.31103, val loss: 0.31314\n",
      "Training epoch: 31, train loss: 0.30371, val loss: 0.30563\n",
      "Training epoch: 32, train loss: 0.29667, val loss: 0.29896\n",
      "Training epoch: 33, train loss: 0.29006, val loss: 0.29292\n",
      "Training epoch: 34, train loss: 0.28283, val loss: 0.28477\n",
      "Training epoch: 35, train loss: 0.27497, val loss: 0.27616\n",
      "Training epoch: 36, train loss: 0.26876, val loss: 0.27116\n",
      "Training epoch: 37, train loss: 0.26224, val loss: 0.26467\n",
      "Training epoch: 38, train loss: 0.25517, val loss: 0.25756\n",
      "Training epoch: 39, train loss: 0.24885, val loss: 0.25192\n",
      "Training epoch: 40, train loss: 0.24176, val loss: 0.24338\n",
      "Training epoch: 41, train loss: 0.23555, val loss: 0.23354\n",
      "Training epoch: 42, train loss: 0.22856, val loss: 0.22776\n",
      "Training epoch: 43, train loss: 0.22177, val loss: 0.22015\n",
      "Training epoch: 44, train loss: 0.21521, val loss: 0.21380\n",
      "Training epoch: 45, train loss: 0.20936, val loss: 0.20859\n",
      "Training epoch: 46, train loss: 0.20325, val loss: 0.20256\n",
      "Training epoch: 47, train loss: 0.19744, val loss: 0.19737\n",
      "Training epoch: 48, train loss: 0.19171, val loss: 0.19120\n",
      "Training epoch: 49, train loss: 0.18609, val loss: 0.18643\n",
      "Training epoch: 50, train loss: 0.18151, val loss: 0.18263\n",
      "Training epoch: 51, train loss: 0.17550, val loss: 0.17565\n",
      "Training epoch: 52, train loss: 0.17145, val loss: 0.17270\n",
      "Training epoch: 53, train loss: 0.16551, val loss: 0.16576\n",
      "Training epoch: 54, train loss: 0.16214, val loss: 0.16451\n",
      "Training epoch: 55, train loss: 0.15619, val loss: 0.15603\n",
      "Training epoch: 56, train loss: 0.15103, val loss: 0.15070\n",
      "Training epoch: 57, train loss: 0.14622, val loss: 0.14540\n",
      "Training epoch: 58, train loss: 0.13976, val loss: 0.13776\n",
      "Training epoch: 59, train loss: 0.09395, val loss: 0.09599\n",
      "Training epoch: 60, train loss: 0.09107, val loss: 0.09209\n",
      "Training epoch: 61, train loss: 0.08845, val loss: 0.09100\n",
      "Training epoch: 62, train loss: 0.08545, val loss: 0.08707\n",
      "Training epoch: 63, train loss: 0.08283, val loss: 0.08472\n",
      "Training epoch: 64, train loss: 0.08030, val loss: 0.08209\n",
      "Training epoch: 65, train loss: 0.07793, val loss: 0.07998\n",
      "Training epoch: 66, train loss: 0.07567, val loss: 0.07769\n",
      "Training epoch: 67, train loss: 0.07353, val loss: 0.07539\n",
      "Training epoch: 68, train loss: 0.07142, val loss: 0.07342\n",
      "Training epoch: 69, train loss: 0.06943, val loss: 0.07150\n",
      "Training epoch: 70, train loss: 0.06749, val loss: 0.06943\n",
      "Training epoch: 71, train loss: 0.06561, val loss: 0.06761\n",
      "Training epoch: 72, train loss: 0.06381, val loss: 0.06584\n",
      "Training epoch: 73, train loss: 0.06216, val loss: 0.06381\n",
      "Training epoch: 74, train loss: 0.06046, val loss: 0.06246\n",
      "Training epoch: 75, train loss: 0.05868, val loss: 0.06044\n",
      "Training epoch: 76, train loss: 0.05710, val loss: 0.05886\n",
      "Training epoch: 77, train loss: 0.05556, val loss: 0.05733\n",
      "Training epoch: 78, train loss: 0.05404, val loss: 0.05583\n",
      "Training epoch: 79, train loss: 0.05263, val loss: 0.05433\n",
      "Training epoch: 80, train loss: 0.05124, val loss: 0.05283\n",
      "Training epoch: 81, train loss: 0.04987, val loss: 0.05133\n",
      "Training epoch: 82, train loss: 0.04863, val loss: 0.05033\n",
      "Training epoch: 83, train loss: 0.04728, val loss: 0.04872\n",
      "Training epoch: 84, train loss: 0.04613, val loss: 0.04751\n",
      "Training epoch: 85, train loss: 0.04486, val loss: 0.04624\n",
      "Training epoch: 86, train loss: 0.04372, val loss: 0.04517\n",
      "Training epoch: 87, train loss: 0.04259, val loss: 0.04390\n",
      "Training epoch: 88, train loss: 0.04152, val loss: 0.04278\n",
      "Training epoch: 89, train loss: 0.04051, val loss: 0.04184\n",
      "Training epoch: 90, train loss: 0.03949, val loss: 0.04064\n",
      "Training epoch: 91, train loss: 0.03853, val loss: 0.03983\n",
      "Training epoch: 92, train loss: 0.03760, val loss: 0.03871\n",
      "Training epoch: 93, train loss: 0.03669, val loss: 0.03776\n",
      "Training epoch: 94, train loss: 0.03585, val loss: 0.03690\n",
      "Training epoch: 95, train loss: 0.03507, val loss: 0.03626\n",
      "Training epoch: 96, train loss: 0.03425, val loss: 0.03513\n",
      "Training epoch: 97, train loss: 0.03338, val loss: 0.03428\n",
      "Training epoch: 98, train loss: 0.03302, val loss: 0.03410\n",
      "Training epoch: 99, train loss: 0.03204, val loss: 0.03281\n",
      "Training epoch: 100, train loss: 0.03122, val loss: 0.03218\n",
      "Training epoch: 101, train loss: 0.03059, val loss: 0.03151\n",
      "Training epoch: 102, train loss: 0.02990, val loss: 0.03073\n",
      "Training epoch: 103, train loss: 0.02929, val loss: 0.03011\n",
      "Training epoch: 104, train loss: 0.02869, val loss: 0.02958\n",
      "Training epoch: 105, train loss: 0.02811, val loss: 0.02896\n",
      "Training epoch: 106, train loss: 0.02758, val loss: 0.02845\n",
      "Training epoch: 107, train loss: 0.02707, val loss: 0.02790\n",
      "Training epoch: 108, train loss: 0.02659, val loss: 0.02739\n",
      "Training epoch: 109, train loss: 0.02611, val loss: 0.02692\n",
      "Training epoch: 110, train loss: 0.02578, val loss: 0.02649\n",
      "Training epoch: 111, train loss: 0.02536, val loss: 0.02626\n",
      "Training epoch: 112, train loss: 0.02485, val loss: 0.02563\n",
      "Training epoch: 113, train loss: 0.02444, val loss: 0.02522\n",
      "Training epoch: 114, train loss: 0.02411, val loss: 0.02494\n",
      "Training epoch: 115, train loss: 0.02383, val loss: 0.02469\n",
      "Training epoch: 116, train loss: 0.02338, val loss: 0.02416\n",
      "Training epoch: 117, train loss: 0.02339, val loss: 0.02396\n",
      "Training epoch: 118, train loss: 0.02282, val loss: 0.02357\n",
      "Training epoch: 119, train loss: 0.02306, val loss: 0.02398\n",
      "Training epoch: 120, train loss: 0.02237, val loss: 0.02307\n",
      "Training epoch: 121, train loss: 0.02197, val loss: 0.02267\n",
      "Training epoch: 122, train loss: 0.02174, val loss: 0.02249\n",
      "Training epoch: 123, train loss: 0.02149, val loss: 0.02225\n",
      "Training epoch: 124, train loss: 0.02131, val loss: 0.02207\n",
      "Training epoch: 125, train loss: 0.02105, val loss: 0.02176\n",
      "Training epoch: 126, train loss: 0.02085, val loss: 0.02163\n",
      "Training epoch: 127, train loss: 0.02069, val loss: 0.02144\n",
      "Training epoch: 128, train loss: 0.02053, val loss: 0.02129\n",
      "Training epoch: 129, train loss: 0.02038, val loss: 0.02106\n",
      "Training epoch: 130, train loss: 0.02017, val loss: 0.02087\n",
      "Training epoch: 131, train loss: 0.02001, val loss: 0.02078\n",
      "Training epoch: 132, train loss: 0.01994, val loss: 0.02075\n",
      "Training epoch: 133, train loss: 0.01975, val loss: 0.02047\n",
      "Training epoch: 134, train loss: 0.01963, val loss: 0.02039\n",
      "Training epoch: 135, train loss: 0.01952, val loss: 0.02025\n",
      "Training epoch: 136, train loss: 0.01942, val loss: 0.02017\n",
      "Training epoch: 137, train loss: 0.01932, val loss: 0.02006\n",
      "Training epoch: 138, train loss: 0.01921, val loss: 0.01998\n",
      "Training epoch: 139, train loss: 0.01910, val loss: 0.01987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 140, train loss: 0.01901, val loss: 0.01976\n",
      "Training epoch: 141, train loss: 0.01893, val loss: 0.01966\n",
      "Training epoch: 142, train loss: 0.01899, val loss: 0.01970\n",
      "Training epoch: 143, train loss: 0.01880, val loss: 0.01954\n",
      "Training epoch: 144, train loss: 0.01874, val loss: 0.01948\n",
      "Training epoch: 145, train loss: 0.01865, val loss: 0.01941\n",
      "Training epoch: 146, train loss: 0.01876, val loss: 0.01947\n",
      "Training epoch: 147, train loss: 0.01856, val loss: 0.01932\n",
      "Training epoch: 148, train loss: 0.01849, val loss: 0.01924\n",
      "Training epoch: 149, train loss: 0.01842, val loss: 0.01917\n",
      "Training epoch: 150, train loss: 0.01842, val loss: 0.01919\n",
      "Training epoch: 151, train loss: 0.01835, val loss: 0.01915\n",
      "Training epoch: 152, train loss: 0.01830, val loss: 0.01904\n",
      "Training epoch: 153, train loss: 0.01826, val loss: 0.01901\n",
      "Training epoch: 154, train loss: 0.01823, val loss: 0.01902\n",
      "Training epoch: 155, train loss: 0.01835, val loss: 0.01916\n",
      "Training epoch: 156, train loss: 0.01818, val loss: 0.01895\n",
      "Training epoch: 157, train loss: 0.01813, val loss: 0.01888\n",
      "Training epoch: 158, train loss: 0.01822, val loss: 0.01903\n",
      "Training epoch: 159, train loss: 0.01815, val loss: 0.01894\n",
      "Training epoch: 160, train loss: 0.01803, val loss: 0.01880\n",
      "Training epoch: 161, train loss: 0.01803, val loss: 0.01878\n",
      "Training epoch: 162, train loss: 0.01814, val loss: 0.01895\n",
      "Training epoch: 163, train loss: 0.01796, val loss: 0.01873\n",
      "Training epoch: 164, train loss: 0.01819, val loss: 0.01893\n",
      "Training epoch: 165, train loss: 0.01799, val loss: 0.01874\n",
      "Training epoch: 166, train loss: 0.01798, val loss: 0.01875\n",
      "Training epoch: 167, train loss: 0.01791, val loss: 0.01868\n",
      "Training epoch: 168, train loss: 0.01788, val loss: 0.01866\n",
      "Training epoch: 169, train loss: 0.01790, val loss: 0.01866\n",
      "Training epoch: 170, train loss: 0.01790, val loss: 0.01866\n",
      "Training epoch: 171, train loss: 0.01784, val loss: 0.01860\n",
      "Training epoch: 172, train loss: 0.01785, val loss: 0.01860\n",
      "Training epoch: 173, train loss: 0.01781, val loss: 0.01856\n",
      "Training epoch: 174, train loss: 0.01786, val loss: 0.01864\n",
      "Training epoch: 175, train loss: 0.01778, val loss: 0.01856\n",
      "Training epoch: 176, train loss: 0.01785, val loss: 0.01860\n",
      "Training epoch: 177, train loss: 0.01778, val loss: 0.01852\n",
      "Training epoch: 178, train loss: 0.01780, val loss: 0.01856\n",
      "Training epoch: 179, train loss: 0.01774, val loss: 0.01853\n",
      "Training epoch: 180, train loss: 0.01778, val loss: 0.01855\n",
      "Training epoch: 181, train loss: 0.01772, val loss: 0.01847\n",
      "Training epoch: 182, train loss: 0.01779, val loss: 0.01854\n",
      "Training epoch: 183, train loss: 0.01783, val loss: 0.01862\n",
      "Training epoch: 184, train loss: 0.01770, val loss: 0.01847\n",
      "Training epoch: 185, train loss: 0.01771, val loss: 0.01847\n",
      "Training epoch: 186, train loss: 0.01768, val loss: 0.01842\n",
      "Training epoch: 187, train loss: 0.01771, val loss: 0.01844\n",
      "Training epoch: 188, train loss: 0.01770, val loss: 0.01846\n",
      "Training epoch: 189, train loss: 0.01773, val loss: 0.01849\n",
      "Training epoch: 190, train loss: 0.01766, val loss: 0.01842\n",
      "Training epoch: 191, train loss: 0.01771, val loss: 0.01847\n",
      "Training epoch: 192, train loss: 0.01765, val loss: 0.01840\n",
      "Training epoch: 193, train loss: 0.01765, val loss: 0.01840\n",
      "Training epoch: 194, train loss: 0.01764, val loss: 0.01840\n",
      "Training epoch: 195, train loss: 0.01764, val loss: 0.01839\n",
      "Training epoch: 196, train loss: 0.01764, val loss: 0.01840\n",
      "Training epoch: 197, train loss: 0.01764, val loss: 0.01839\n",
      "Training epoch: 198, train loss: 0.01766, val loss: 0.01840\n",
      "Training epoch: 199, train loss: 0.01767, val loss: 0.01842\n",
      "Training epoch: 200, train loss: 0.01764, val loss: 0.01838\n",
      "Training epoch: 201, train loss: 0.01763, val loss: 0.01838\n",
      "Training epoch: 202, train loss: 0.01762, val loss: 0.01838\n",
      "Training epoch: 203, train loss: 0.01770, val loss: 0.01845\n",
      "Training epoch: 204, train loss: 0.01761, val loss: 0.01836\n",
      "Training epoch: 205, train loss: 0.01768, val loss: 0.01844\n",
      "Training epoch: 206, train loss: 0.01765, val loss: 0.01841\n",
      "Training epoch: 207, train loss: 0.01760, val loss: 0.01835\n",
      "Training epoch: 208, train loss: 0.01771, val loss: 0.01846\n",
      "Training epoch: 209, train loss: 0.01761, val loss: 0.01836\n",
      "Training epoch: 210, train loss: 0.01760, val loss: 0.01834\n",
      "Training epoch: 211, train loss: 0.01762, val loss: 0.01836\n",
      "Training epoch: 212, train loss: 0.01763, val loss: 0.01837\n",
      "Training epoch: 213, train loss: 0.01764, val loss: 0.01839\n",
      "Training epoch: 214, train loss: 0.01759, val loss: 0.01833\n",
      "Training epoch: 215, train loss: 0.01765, val loss: 0.01838\n",
      "Training epoch: 216, train loss: 0.01769, val loss: 0.01844\n",
      "Training epoch: 217, train loss: 0.01760, val loss: 0.01835\n",
      "Training epoch: 218, train loss: 0.01761, val loss: 0.01836\n",
      "Training epoch: 219, train loss: 0.01760, val loss: 0.01833\n",
      "Training epoch: 220, train loss: 0.01761, val loss: 0.01836\n",
      "Training epoch: 221, train loss: 0.01765, val loss: 0.01841\n",
      "Training epoch: 222, train loss: 0.01762, val loss: 0.01835\n",
      "Training epoch: 223, train loss: 0.01764, val loss: 0.01838\n",
      "Training epoch: 224, train loss: 0.01772, val loss: 0.01846\n",
      "Training epoch: 225, train loss: 0.01758, val loss: 0.01832\n",
      "Training epoch: 226, train loss: 0.01765, val loss: 0.01839\n",
      "Training epoch: 227, train loss: 0.01760, val loss: 0.01836\n",
      "Training epoch: 228, train loss: 0.01757, val loss: 0.01833\n",
      "Training epoch: 229, train loss: 0.01763, val loss: 0.01836\n",
      "Training epoch: 230, train loss: 0.01766, val loss: 0.01839\n",
      "Training epoch: 231, train loss: 0.01757, val loss: 0.01831\n",
      "Training epoch: 232, train loss: 0.01757, val loss: 0.01833\n",
      "Training epoch: 233, train loss: 0.01759, val loss: 0.01833\n",
      "Training epoch: 234, train loss: 0.01759, val loss: 0.01831\n",
      "Training epoch: 235, train loss: 0.01761, val loss: 0.01834\n",
      "Training epoch: 236, train loss: 0.01757, val loss: 0.01831\n",
      "Training epoch: 237, train loss: 0.01765, val loss: 0.01840\n",
      "Training epoch: 238, train loss: 0.01761, val loss: 0.01833\n",
      "Training epoch: 239, train loss: 0.01760, val loss: 0.01832\n",
      "Training epoch: 240, train loss: 0.01760, val loss: 0.01834\n",
      "Training epoch: 241, train loss: 0.01756, val loss: 0.01830\n",
      "Training epoch: 242, train loss: 0.01757, val loss: 0.01830\n",
      "Training epoch: 243, train loss: 0.01756, val loss: 0.01831\n",
      "Training epoch: 244, train loss: 0.01756, val loss: 0.01829\n",
      "Training epoch: 245, train loss: 0.01760, val loss: 0.01833\n",
      "Training epoch: 246, train loss: 0.01755, val loss: 0.01829\n",
      "Training epoch: 247, train loss: 0.01760, val loss: 0.01834\n",
      "Training epoch: 248, train loss: 0.01756, val loss: 0.01832\n",
      "Training epoch: 249, train loss: 0.01755, val loss: 0.01828\n",
      "Training epoch: 250, train loss: 0.01764, val loss: 0.01836\n",
      "Training epoch: 251, train loss: 0.01755, val loss: 0.01829\n",
      "Training epoch: 252, train loss: 0.01768, val loss: 0.01841\n",
      "Training epoch: 253, train loss: 0.01756, val loss: 0.01829\n",
      "Training epoch: 254, train loss: 0.01762, val loss: 0.01836\n",
      "Training epoch: 255, train loss: 0.01757, val loss: 0.01828\n",
      "Training epoch: 256, train loss: 0.01755, val loss: 0.01828\n",
      "Training epoch: 257, train loss: 0.01760, val loss: 0.01835\n",
      "Training epoch: 258, train loss: 0.01754, val loss: 0.01828\n",
      "Training epoch: 259, train loss: 0.01757, val loss: 0.01829\n",
      "Training epoch: 260, train loss: 0.01754, val loss: 0.01826\n",
      "Training epoch: 261, train loss: 0.01756, val loss: 0.01829\n",
      "Training epoch: 262, train loss: 0.01754, val loss: 0.01826\n",
      "Training epoch: 263, train loss: 0.01762, val loss: 0.01836\n",
      "Training epoch: 264, train loss: 0.01753, val loss: 0.01825\n",
      "Training epoch: 265, train loss: 0.01761, val loss: 0.01834\n",
      "Training epoch: 266, train loss: 0.01754, val loss: 0.01829\n",
      "Training epoch: 267, train loss: 0.01759, val loss: 0.01834\n",
      "Training epoch: 268, train loss: 0.01768, val loss: 0.01842\n",
      "Training epoch: 269, train loss: 0.01755, val loss: 0.01828\n",
      "Training epoch: 270, train loss: 0.01755, val loss: 0.01827\n",
      "Training epoch: 271, train loss: 0.01753, val loss: 0.01827\n",
      "Training epoch: 272, train loss: 0.01755, val loss: 0.01828\n",
      "Training epoch: 273, train loss: 0.01763, val loss: 0.01837\n",
      "Training epoch: 274, train loss: 0.01753, val loss: 0.01827\n",
      "Training epoch: 275, train loss: 0.01755, val loss: 0.01829\n",
      "Training epoch: 276, train loss: 0.01758, val loss: 0.01833\n",
      "Training epoch: 277, train loss: 0.01769, val loss: 0.01842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 278, train loss: 0.01762, val loss: 0.01835\n",
      "Training epoch: 279, train loss: 0.01754, val loss: 0.01828\n",
      "Training epoch: 280, train loss: 0.01790, val loss: 0.01865\n",
      "Training epoch: 281, train loss: 0.01754, val loss: 0.01828\n",
      "Training epoch: 282, train loss: 0.01763, val loss: 0.01835\n",
      "Training epoch: 283, train loss: 0.01753, val loss: 0.01828\n",
      "Training epoch: 284, train loss: 0.01764, val loss: 0.01837\n",
      "Training epoch: 285, train loss: 0.01752, val loss: 0.01827\n",
      "Training epoch: 286, train loss: 0.01752, val loss: 0.01824\n",
      "Training epoch: 287, train loss: 0.01755, val loss: 0.01829\n",
      "Training epoch: 288, train loss: 0.01754, val loss: 0.01826\n",
      "Training epoch: 289, train loss: 0.01757, val loss: 0.01831\n",
      "Training epoch: 290, train loss: 0.01756, val loss: 0.01831\n",
      "Training epoch: 291, train loss: 0.01754, val loss: 0.01826\n",
      "Training epoch: 292, train loss: 0.01763, val loss: 0.01836\n",
      "Training epoch: 293, train loss: 0.01751, val loss: 0.01825\n",
      "Training epoch: 294, train loss: 0.01755, val loss: 0.01828\n",
      "Training epoch: 295, train loss: 0.01751, val loss: 0.01824\n",
      "Training epoch: 296, train loss: 0.01754, val loss: 0.01826\n",
      "Training epoch: 297, train loss: 0.01752, val loss: 0.01826\n",
      "Training epoch: 298, train loss: 0.01756, val loss: 0.01830\n",
      "Training epoch: 299, train loss: 0.01752, val loss: 0.01825\n",
      "Training epoch: 300, train loss: 0.01751, val loss: 0.01823\n",
      "Training epoch: 301, train loss: 0.01754, val loss: 0.01827\n",
      "Training epoch: 302, train loss: 0.01754, val loss: 0.01827\n",
      "Training epoch: 303, train loss: 0.01756, val loss: 0.01828\n",
      "Training epoch: 304, train loss: 0.01773, val loss: 0.01846\n",
      "Training epoch: 305, train loss: 0.01750, val loss: 0.01826\n",
      "Training epoch: 306, train loss: 0.01751, val loss: 0.01824\n",
      "Training epoch: 307, train loss: 0.01752, val loss: 0.01824\n",
      "Training epoch: 308, train loss: 0.01750, val loss: 0.01823\n",
      "Training epoch: 309, train loss: 0.01750, val loss: 0.01821\n",
      "Training epoch: 310, train loss: 0.01752, val loss: 0.01825\n",
      "Training epoch: 311, train loss: 0.01752, val loss: 0.01825\n",
      "Training epoch: 312, train loss: 0.01750, val loss: 0.01824\n",
      "Training epoch: 313, train loss: 0.01752, val loss: 0.01826\n",
      "Training epoch: 314, train loss: 0.01750, val loss: 0.01824\n",
      "Training epoch: 315, train loss: 0.01750, val loss: 0.01822\n",
      "Training epoch: 316, train loss: 0.01756, val loss: 0.01830\n",
      "Training epoch: 317, train loss: 0.01761, val loss: 0.01834\n",
      "Training epoch: 318, train loss: 0.01751, val loss: 0.01824\n",
      "Training epoch: 319, train loss: 0.01749, val loss: 0.01822\n",
      "Training epoch: 320, train loss: 0.01751, val loss: 0.01824\n",
      "Training epoch: 321, train loss: 0.01750, val loss: 0.01823\n",
      "Training epoch: 322, train loss: 0.01752, val loss: 0.01826\n",
      "Training epoch: 323, train loss: 0.01750, val loss: 0.01821\n",
      "Training epoch: 324, train loss: 0.01754, val loss: 0.01826\n",
      "Training epoch: 325, train loss: 0.01750, val loss: 0.01823\n",
      "Training epoch: 326, train loss: 0.01753, val loss: 0.01826\n",
      "Training epoch: 327, train loss: 0.01766, val loss: 0.01841\n",
      "Training epoch: 328, train loss: 0.01750, val loss: 0.01825\n",
      "Training epoch: 329, train loss: 0.01750, val loss: 0.01821\n",
      "Training epoch: 330, train loss: 0.01749, val loss: 0.01821\n",
      "Training epoch: 331, train loss: 0.01749, val loss: 0.01822\n",
      "Training epoch: 332, train loss: 0.01752, val loss: 0.01824\n",
      "Training epoch: 333, train loss: 0.01753, val loss: 0.01825\n",
      "Training epoch: 334, train loss: 0.01752, val loss: 0.01823\n",
      "Training epoch: 335, train loss: 0.01750, val loss: 0.01823\n",
      "Training epoch: 336, train loss: 0.01748, val loss: 0.01821\n",
      "Training epoch: 337, train loss: 0.01749, val loss: 0.01821\n",
      "Training epoch: 338, train loss: 0.01749, val loss: 0.01821\n",
      "Training epoch: 339, train loss: 0.01748, val loss: 0.01821\n",
      "Training epoch: 340, train loss: 0.01752, val loss: 0.01825\n",
      "Training epoch: 341, train loss: 0.01748, val loss: 0.01820\n",
      "Training epoch: 342, train loss: 0.01752, val loss: 0.01823\n",
      "Training epoch: 343, train loss: 0.01748, val loss: 0.01819\n",
      "Training epoch: 344, train loss: 0.01750, val loss: 0.01823\n",
      "Training epoch: 345, train loss: 0.01748, val loss: 0.01822\n",
      "Training epoch: 346, train loss: 0.01749, val loss: 0.01821\n",
      "Training epoch: 347, train loss: 0.01757, val loss: 0.01828\n",
      "Training epoch: 348, train loss: 0.01749, val loss: 0.01819\n",
      "Training epoch: 349, train loss: 0.01748, val loss: 0.01822\n",
      "Training epoch: 350, train loss: 0.01750, val loss: 0.01824\n",
      "Training epoch: 351, train loss: 0.01749, val loss: 0.01820\n",
      "Training epoch: 352, train loss: 0.01747, val loss: 0.01819\n",
      "Training epoch: 353, train loss: 0.01749, val loss: 0.01823\n",
      "Training epoch: 354, train loss: 0.01748, val loss: 0.01820\n",
      "Training epoch: 355, train loss: 0.01747, val loss: 0.01819\n",
      "Training epoch: 356, train loss: 0.01758, val loss: 0.01832\n",
      "Training epoch: 357, train loss: 0.01751, val loss: 0.01823\n",
      "Training epoch: 358, train loss: 0.01748, val loss: 0.01820\n",
      "Training epoch: 359, train loss: 0.01749, val loss: 0.01823\n",
      "Training epoch: 360, train loss: 0.01749, val loss: 0.01820\n",
      "Training epoch: 361, train loss: 0.01747, val loss: 0.01819\n",
      "Training epoch: 362, train loss: 0.01748, val loss: 0.01821\n",
      "Training epoch: 363, train loss: 0.01747, val loss: 0.01820\n",
      "Training epoch: 364, train loss: 0.01746, val loss: 0.01820\n",
      "Training epoch: 365, train loss: 0.01759, val loss: 0.01831\n",
      "Training epoch: 366, train loss: 0.01746, val loss: 0.01820\n",
      "Training epoch: 367, train loss: 0.01770, val loss: 0.01843\n",
      "Training epoch: 368, train loss: 0.01750, val loss: 0.01824\n",
      "Training epoch: 369, train loss: 0.01766, val loss: 0.01840\n",
      "Training epoch: 370, train loss: 0.01747, val loss: 0.01816\n",
      "Training epoch: 371, train loss: 0.01747, val loss: 0.01820\n",
      "Training epoch: 372, train loss: 0.01759, val loss: 0.01832\n",
      "Training epoch: 373, train loss: 0.01749, val loss: 0.01823\n",
      "Training epoch: 374, train loss: 0.01748, val loss: 0.01818\n",
      "Training epoch: 375, train loss: 0.01746, val loss: 0.01817\n",
      "Training epoch: 376, train loss: 0.01767, val loss: 0.01843\n",
      "Training epoch: 377, train loss: 0.01751, val loss: 0.01825\n",
      "Training epoch: 378, train loss: 0.01746, val loss: 0.01818\n",
      "Training epoch: 379, train loss: 0.01756, val loss: 0.01829\n",
      "Training epoch: 380, train loss: 0.01748, val loss: 0.01821\n",
      "Training epoch: 381, train loss: 0.01748, val loss: 0.01820\n",
      "Training epoch: 382, train loss: 0.01747, val loss: 0.01820\n",
      "Training epoch: 383, train loss: 0.01748, val loss: 0.01820\n",
      "Training epoch: 384, train loss: 0.01747, val loss: 0.01820\n",
      "Training epoch: 385, train loss: 0.01748, val loss: 0.01820\n",
      "Training epoch: 386, train loss: 0.01747, val loss: 0.01818\n",
      "Training epoch: 387, train loss: 0.01754, val loss: 0.01828\n",
      "Training epoch: 388, train loss: 0.01746, val loss: 0.01820\n",
      "Training epoch: 389, train loss: 0.01746, val loss: 0.01818\n",
      "Training epoch: 390, train loss: 0.01745, val loss: 0.01817\n",
      "Training epoch: 391, train loss: 0.01744, val loss: 0.01817\n",
      "Training epoch: 392, train loss: 0.01745, val loss: 0.01817\n",
      "Training epoch: 393, train loss: 0.01744, val loss: 0.01818\n",
      "Training epoch: 394, train loss: 0.01745, val loss: 0.01815\n",
      "Training epoch: 395, train loss: 0.01747, val loss: 0.01816\n",
      "Training epoch: 396, train loss: 0.01745, val loss: 0.01819\n",
      "Training epoch: 397, train loss: 0.01744, val loss: 0.01817\n",
      "Training epoch: 398, train loss: 0.01746, val loss: 0.01820\n",
      "Training epoch: 399, train loss: 0.01745, val loss: 0.01818\n",
      "Training epoch: 400, train loss: 0.01745, val loss: 0.01817\n",
      "Training epoch: 401, train loss: 0.01751, val loss: 0.01824\n",
      "Training epoch: 402, train loss: 0.01744, val loss: 0.01817\n",
      "Training epoch: 403, train loss: 0.01744, val loss: 0.01815\n",
      "Training epoch: 404, train loss: 0.01750, val loss: 0.01824\n",
      "Training epoch: 405, train loss: 0.01747, val loss: 0.01819\n",
      "Training epoch: 406, train loss: 0.01749, val loss: 0.01821\n",
      "Training epoch: 407, train loss: 0.01744, val loss: 0.01816\n",
      "Training epoch: 408, train loss: 0.01744, val loss: 0.01818\n",
      "Training epoch: 409, train loss: 0.01756, val loss: 0.01829\n",
      "Training epoch: 410, train loss: 0.01759, val loss: 0.01830\n",
      "Training epoch: 411, train loss: 0.01745, val loss: 0.01815\n",
      "Training epoch: 412, train loss: 0.01744, val loss: 0.01817\n",
      "Training epoch: 413, train loss: 0.01745, val loss: 0.01820\n",
      "Training epoch: 414, train loss: 0.01755, val loss: 0.01826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 415, train loss: 0.01744, val loss: 0.01813\n",
      "Training epoch: 416, train loss: 0.01749, val loss: 0.01821\n",
      "Training epoch: 417, train loss: 0.01752, val loss: 0.01826\n",
      "Training epoch: 418, train loss: 0.01749, val loss: 0.01821\n",
      "Training epoch: 419, train loss: 0.01750, val loss: 0.01821\n",
      "Training epoch: 420, train loss: 0.01747, val loss: 0.01819\n",
      "Training epoch: 421, train loss: 0.01744, val loss: 0.01819\n",
      "Training epoch: 422, train loss: 0.01762, val loss: 0.01833\n",
      "Training epoch: 423, train loss: 0.01752, val loss: 0.01823\n",
      "Training epoch: 424, train loss: 0.01744, val loss: 0.01817\n",
      "Training epoch: 425, train loss: 0.01743, val loss: 0.01817\n",
      "Training epoch: 426, train loss: 0.01749, val loss: 0.01820\n",
      "Training epoch: 427, train loss: 0.01744, val loss: 0.01814\n",
      "Training epoch: 428, train loss: 0.01743, val loss: 0.01817\n",
      "Training epoch: 429, train loss: 0.01743, val loss: 0.01816\n",
      "Training epoch: 430, train loss: 0.01745, val loss: 0.01815\n",
      "Training epoch: 431, train loss: 0.01747, val loss: 0.01816\n",
      "Training epoch: 432, train loss: 0.01744, val loss: 0.01819\n",
      "Training epoch: 433, train loss: 0.01742, val loss: 0.01813\n",
      "Training epoch: 434, train loss: 0.01754, val loss: 0.01828\n",
      "Training epoch: 435, train loss: 0.01741, val loss: 0.01812\n",
      "Training epoch: 436, train loss: 0.01755, val loss: 0.01829\n",
      "Training epoch: 437, train loss: 0.01746, val loss: 0.01816\n",
      "Training epoch: 438, train loss: 0.01749, val loss: 0.01823\n",
      "Training epoch: 439, train loss: 0.01742, val loss: 0.01815\n",
      "Training epoch: 440, train loss: 0.01745, val loss: 0.01815\n",
      "Training epoch: 441, train loss: 0.01748, val loss: 0.01820\n",
      "Training epoch: 442, train loss: 0.01742, val loss: 0.01815\n",
      "Training epoch: 443, train loss: 0.01743, val loss: 0.01816\n",
      "Training epoch: 444, train loss: 0.01742, val loss: 0.01814\n",
      "Training epoch: 445, train loss: 0.01741, val loss: 0.01813\n",
      "Training epoch: 446, train loss: 0.01745, val loss: 0.01817\n",
      "Training epoch: 447, train loss: 0.01741, val loss: 0.01814\n",
      "Training epoch: 448, train loss: 0.01742, val loss: 0.01815\n",
      "Training epoch: 449, train loss: 0.01741, val loss: 0.01812\n",
      "Training epoch: 450, train loss: 0.01742, val loss: 0.01813\n",
      "Training epoch: 451, train loss: 0.01740, val loss: 0.01811\n",
      "Training epoch: 452, train loss: 0.01741, val loss: 0.01814\n",
      "Training epoch: 453, train loss: 0.01740, val loss: 0.01811\n",
      "Training epoch: 454, train loss: 0.01741, val loss: 0.01812\n",
      "Training epoch: 455, train loss: 0.01741, val loss: 0.01814\n",
      "Training epoch: 456, train loss: 0.01740, val loss: 0.01814\n",
      "Training epoch: 457, train loss: 0.01742, val loss: 0.01813\n",
      "Training epoch: 458, train loss: 0.01744, val loss: 0.01815\n",
      "Training epoch: 459, train loss: 0.01740, val loss: 0.01813\n",
      "Training epoch: 460, train loss: 0.01740, val loss: 0.01812\n",
      "Training epoch: 461, train loss: 0.01744, val loss: 0.01813\n",
      "Training epoch: 462, train loss: 0.01742, val loss: 0.01816\n",
      "Training epoch: 463, train loss: 0.01742, val loss: 0.01814\n",
      "Training epoch: 464, train loss: 0.01740, val loss: 0.01811\n",
      "Training epoch: 465, train loss: 0.01740, val loss: 0.01811\n",
      "Training epoch: 466, train loss: 0.01747, val loss: 0.01818\n",
      "Training epoch: 467, train loss: 0.01745, val loss: 0.01817\n",
      "Training epoch: 468, train loss: 0.01740, val loss: 0.01813\n",
      "Training epoch: 469, train loss: 0.01745, val loss: 0.01812\n",
      "Training epoch: 470, train loss: 0.01752, val loss: 0.01824\n",
      "Training epoch: 471, train loss: 0.01744, val loss: 0.01820\n",
      "Training epoch: 472, train loss: 0.01744, val loss: 0.01815\n",
      "Training epoch: 473, train loss: 0.01739, val loss: 0.01810\n",
      "Training epoch: 474, train loss: 0.01742, val loss: 0.01815\n",
      "Training epoch: 475, train loss: 0.01740, val loss: 0.01811\n",
      "Training epoch: 476, train loss: 0.01741, val loss: 0.01812\n",
      "Training epoch: 477, train loss: 0.01754, val loss: 0.01828\n",
      "Training epoch: 478, train loss: 0.01739, val loss: 0.01813\n",
      "Training epoch: 479, train loss: 0.01740, val loss: 0.01810\n",
      "Training epoch: 480, train loss: 0.01741, val loss: 0.01812\n",
      "Training epoch: 481, train loss: 0.01739, val loss: 0.01812\n",
      "Training epoch: 482, train loss: 0.01741, val loss: 0.01812\n",
      "Training epoch: 483, train loss: 0.01747, val loss: 0.01818\n",
      "Training epoch: 484, train loss: 0.01742, val loss: 0.01815\n",
      "Training epoch: 485, train loss: 0.01743, val loss: 0.01812\n",
      "Training epoch: 486, train loss: 0.01742, val loss: 0.01815\n",
      "Training epoch: 487, train loss: 0.01741, val loss: 0.01813\n",
      "Training epoch: 488, train loss: 0.01738, val loss: 0.01810\n",
      "Training epoch: 489, train loss: 0.01741, val loss: 0.01814\n",
      "Training epoch: 490, train loss: 0.01739, val loss: 0.01811\n",
      "Training epoch: 491, train loss: 0.01739, val loss: 0.01811\n",
      "Training epoch: 492, train loss: 0.01746, val loss: 0.01816\n",
      "Training epoch: 493, train loss: 0.01740, val loss: 0.01813\n",
      "Training epoch: 494, train loss: 0.01740, val loss: 0.01809\n",
      "Training epoch: 495, train loss: 0.01761, val loss: 0.01830\n",
      "Training epoch: 496, train loss: 0.01740, val loss: 0.01814\n",
      "Training epoch: 497, train loss: 0.01737, val loss: 0.01808\n",
      "Training epoch: 498, train loss: 0.01738, val loss: 0.01808\n",
      "Training epoch: 499, train loss: 0.01737, val loss: 0.01810\n",
      "Training epoch: 500, train loss: 0.01740, val loss: 0.01810\n",
      "Training epoch: 501, train loss: 0.01747, val loss: 0.01821\n",
      "Training epoch: 502, train loss: 0.01738, val loss: 0.01810\n",
      "Training epoch: 503, train loss: 0.01740, val loss: 0.01809\n",
      "Training epoch: 504, train loss: 0.01740, val loss: 0.01814\n",
      "Training epoch: 505, train loss: 0.01737, val loss: 0.01810\n",
      "Training epoch: 506, train loss: 0.01740, val loss: 0.01812\n",
      "Training epoch: 507, train loss: 0.01738, val loss: 0.01807\n",
      "Training epoch: 508, train loss: 0.01736, val loss: 0.01808\n",
      "Training epoch: 509, train loss: 0.01737, val loss: 0.01809\n",
      "Training epoch: 510, train loss: 0.01741, val loss: 0.01811\n",
      "Training epoch: 511, train loss: 0.01738, val loss: 0.01809\n",
      "Training epoch: 512, train loss: 0.01738, val loss: 0.01811\n",
      "Training epoch: 513, train loss: 0.01741, val loss: 0.01811\n",
      "Training epoch: 514, train loss: 0.01737, val loss: 0.01811\n",
      "Training epoch: 515, train loss: 0.01746, val loss: 0.01816\n",
      "Training epoch: 516, train loss: 0.01738, val loss: 0.01808\n",
      "Training epoch: 517, train loss: 0.01736, val loss: 0.01807\n",
      "Training epoch: 518, train loss: 0.01740, val loss: 0.01812\n",
      "Training epoch: 519, train loss: 0.01739, val loss: 0.01812\n",
      "Training epoch: 520, train loss: 0.01737, val loss: 0.01808\n",
      "Training epoch: 521, train loss: 0.01735, val loss: 0.01806\n",
      "Training epoch: 522, train loss: 0.01741, val loss: 0.01810\n",
      "Training epoch: 523, train loss: 0.01739, val loss: 0.01808\n",
      "Training epoch: 524, train loss: 0.01737, val loss: 0.01810\n",
      "Training epoch: 525, train loss: 0.01740, val loss: 0.01812\n",
      "Training epoch: 526, train loss: 0.01739, val loss: 0.01809\n",
      "Training epoch: 527, train loss: 0.01738, val loss: 0.01811\n",
      "Training epoch: 528, train loss: 0.01756, val loss: 0.01831\n",
      "Training epoch: 529, train loss: 0.01741, val loss: 0.01810\n",
      "Training epoch: 530, train loss: 0.01739, val loss: 0.01808\n",
      "Training epoch: 531, train loss: 0.01742, val loss: 0.01813\n",
      "Training epoch: 532, train loss: 0.01740, val loss: 0.01809\n",
      "Training epoch: 533, train loss: 0.01737, val loss: 0.01811\n",
      "Training epoch: 534, train loss: 0.01746, val loss: 0.01812\n",
      "Training epoch: 535, train loss: 0.01736, val loss: 0.01807\n",
      "Training epoch: 536, train loss: 0.01741, val loss: 0.01816\n",
      "Training epoch: 537, train loss: 0.01742, val loss: 0.01811\n",
      "Training epoch: 538, train loss: 0.01736, val loss: 0.01808\n",
      "Training epoch: 539, train loss: 0.01743, val loss: 0.01814\n",
      "Training epoch: 540, train loss: 0.01735, val loss: 0.01809\n",
      "Training epoch: 541, train loss: 0.01735, val loss: 0.01806\n",
      "Training epoch: 542, train loss: 0.01738, val loss: 0.01808\n",
      "Training epoch: 543, train loss: 0.01739, val loss: 0.01810\n",
      "Training epoch: 544, train loss: 0.01734, val loss: 0.01806\n",
      "Training epoch: 545, train loss: 0.01735, val loss: 0.01805\n",
      "Training epoch: 546, train loss: 0.01739, val loss: 0.01809\n",
      "Training epoch: 547, train loss: 0.01735, val loss: 0.01805\n",
      "Training epoch: 548, train loss: 0.01736, val loss: 0.01809\n",
      "Training epoch: 549, train loss: 0.01737, val loss: 0.01809\n",
      "Training epoch: 550, train loss: 0.01740, val loss: 0.01809\n",
      "Training epoch: 551, train loss: 0.01734, val loss: 0.01805\n",
      "Training epoch: 552, train loss: 0.01734, val loss: 0.01807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 553, train loss: 0.01733, val loss: 0.01804\n",
      "Training epoch: 554, train loss: 0.01734, val loss: 0.01804\n",
      "Training epoch: 555, train loss: 0.01737, val loss: 0.01810\n",
      "Training epoch: 556, train loss: 0.01734, val loss: 0.01803\n",
      "Training epoch: 557, train loss: 0.01737, val loss: 0.01806\n",
      "Training epoch: 558, train loss: 0.01733, val loss: 0.01806\n",
      "Training epoch: 559, train loss: 0.01733, val loss: 0.01801\n",
      "Training epoch: 560, train loss: 0.01734, val loss: 0.01804\n",
      "Training epoch: 561, train loss: 0.01737, val loss: 0.01807\n",
      "Training epoch: 562, train loss: 0.01735, val loss: 0.01804\n",
      "Training epoch: 563, train loss: 0.01734, val loss: 0.01805\n",
      "Training epoch: 564, train loss: 0.01733, val loss: 0.01804\n",
      "Training epoch: 565, train loss: 0.01732, val loss: 0.01802\n",
      "Training epoch: 566, train loss: 0.01738, val loss: 0.01808\n",
      "Training epoch: 567, train loss: 0.01747, val loss: 0.01819\n",
      "Training epoch: 568, train loss: 0.01735, val loss: 0.01803\n",
      "Training epoch: 569, train loss: 0.01742, val loss: 0.01812\n",
      "Training epoch: 570, train loss: 0.01734, val loss: 0.01807\n",
      "Training epoch: 571, train loss: 0.01732, val loss: 0.01802\n",
      "Training epoch: 572, train loss: 0.01732, val loss: 0.01802\n",
      "Training epoch: 573, train loss: 0.01744, val loss: 0.01816\n",
      "Training epoch: 574, train loss: 0.01733, val loss: 0.01803\n",
      "Training epoch: 575, train loss: 0.01736, val loss: 0.01808\n",
      "Training epoch: 576, train loss: 0.01733, val loss: 0.01802\n",
      "Training epoch: 577, train loss: 0.01731, val loss: 0.01802\n",
      "Training epoch: 578, train loss: 0.01731, val loss: 0.01802\n",
      "Training epoch: 579, train loss: 0.01734, val loss: 0.01808\n",
      "Training epoch: 580, train loss: 0.01734, val loss: 0.01805\n",
      "Training epoch: 581, train loss: 0.01737, val loss: 0.01807\n",
      "Training epoch: 582, train loss: 0.01734, val loss: 0.01802\n",
      "Training epoch: 583, train loss: 0.01734, val loss: 0.01806\n",
      "Training epoch: 584, train loss: 0.01735, val loss: 0.01804\n",
      "Training epoch: 585, train loss: 0.01737, val loss: 0.01809\n",
      "Training epoch: 586, train loss: 0.01731, val loss: 0.01800\n",
      "Training epoch: 587, train loss: 0.01739, val loss: 0.01810\n",
      "Training epoch: 588, train loss: 0.01732, val loss: 0.01805\n",
      "Training epoch: 589, train loss: 0.01732, val loss: 0.01803\n",
      "Training epoch: 590, train loss: 0.01742, val loss: 0.01813\n",
      "Training epoch: 591, train loss: 0.01734, val loss: 0.01805\n",
      "Training epoch: 592, train loss: 0.01732, val loss: 0.01799\n",
      "Training epoch: 593, train loss: 0.01734, val loss: 0.01806\n",
      "Training epoch: 594, train loss: 0.01732, val loss: 0.01802\n",
      "Training epoch: 595, train loss: 0.01732, val loss: 0.01803\n",
      "Training epoch: 596, train loss: 0.01731, val loss: 0.01802\n",
      "Training epoch: 597, train loss: 0.01734, val loss: 0.01804\n",
      "Training epoch: 598, train loss: 0.01736, val loss: 0.01806\n",
      "Training epoch: 599, train loss: 0.01733, val loss: 0.01804\n",
      "Training epoch: 600, train loss: 0.01731, val loss: 0.01801\n",
      "Training epoch: 601, train loss: 0.01732, val loss: 0.01801\n",
      "Training epoch: 602, train loss: 0.01737, val loss: 0.01808\n",
      "Training epoch: 603, train loss: 0.01737, val loss: 0.01809\n",
      "Training epoch: 604, train loss: 0.01733, val loss: 0.01801\n",
      "Training epoch: 605, train loss: 0.01772, val loss: 0.01845\n",
      "Training epoch: 606, train loss: 0.01740, val loss: 0.01809\n",
      "Training epoch: 607, train loss: 0.01744, val loss: 0.01815\n",
      "Training epoch: 608, train loss: 0.01747, val loss: 0.01819\n",
      "Training epoch: 609, train loss: 0.01730, val loss: 0.01798\n",
      "Training epoch: 610, train loss: 0.01770, val loss: 0.01837\n",
      "Training epoch: 611, train loss: 0.01735, val loss: 0.01810\n",
      "Training epoch: 612, train loss: 0.01731, val loss: 0.01797\n",
      "Training epoch: 613, train loss: 0.01732, val loss: 0.01800\n",
      "Training epoch: 614, train loss: 0.01733, val loss: 0.01805\n",
      "Training epoch: 615, train loss: 0.01737, val loss: 0.01806\n",
      "Training epoch: 616, train loss: 0.01731, val loss: 0.01800\n",
      "Training epoch: 617, train loss: 0.01737, val loss: 0.01808\n",
      "Training epoch: 618, train loss: 0.01729, val loss: 0.01800\n",
      "Training epoch: 619, train loss: 0.01729, val loss: 0.01798\n",
      "Training epoch: 620, train loss: 0.01730, val loss: 0.01802\n",
      "Training epoch: 621, train loss: 0.01729, val loss: 0.01799\n",
      "Training epoch: 622, train loss: 0.01732, val loss: 0.01802\n",
      "Training epoch: 623, train loss: 0.01728, val loss: 0.01800\n",
      "Training epoch: 624, train loss: 0.01730, val loss: 0.01797\n",
      "Training epoch: 625, train loss: 0.01730, val loss: 0.01799\n",
      "Training epoch: 626, train loss: 0.01729, val loss: 0.01799\n",
      "Training epoch: 627, train loss: 0.01728, val loss: 0.01798\n",
      "Training epoch: 628, train loss: 0.01730, val loss: 0.01798\n",
      "Training epoch: 629, train loss: 0.01729, val loss: 0.01798\n",
      "Training epoch: 630, train loss: 0.01731, val loss: 0.01801\n",
      "Training epoch: 631, train loss: 0.01730, val loss: 0.01800\n",
      "Training epoch: 632, train loss: 0.01731, val loss: 0.01802\n",
      "Training epoch: 633, train loss: 0.01732, val loss: 0.01801\n",
      "Training epoch: 634, train loss: 0.01734, val loss: 0.01803\n",
      "Training epoch: 635, train loss: 0.01727, val loss: 0.01796\n",
      "Training epoch: 636, train loss: 0.01727, val loss: 0.01795\n",
      "Training epoch: 637, train loss: 0.01745, val loss: 0.01818\n",
      "Training epoch: 638, train loss: 0.01738, val loss: 0.01809\n",
      "Training epoch: 639, train loss: 0.01728, val loss: 0.01799\n",
      "Training epoch: 640, train loss: 0.01733, val loss: 0.01801\n",
      "Training epoch: 641, train loss: 0.01726, val loss: 0.01797\n",
      "Training epoch: 642, train loss: 0.01730, val loss: 0.01799\n",
      "Training epoch: 643, train loss: 0.01727, val loss: 0.01800\n",
      "Training epoch: 644, train loss: 0.01725, val loss: 0.01796\n",
      "Training epoch: 645, train loss: 0.01727, val loss: 0.01795\n",
      "Training epoch: 646, train loss: 0.01731, val loss: 0.01799\n",
      "Training epoch: 647, train loss: 0.01726, val loss: 0.01797\n",
      "Training epoch: 648, train loss: 0.01727, val loss: 0.01795\n",
      "Training epoch: 649, train loss: 0.01726, val loss: 0.01795\n",
      "Training epoch: 650, train loss: 0.01726, val loss: 0.01796\n",
      "Training epoch: 651, train loss: 0.01725, val loss: 0.01796\n",
      "Training epoch: 652, train loss: 0.01732, val loss: 0.01802\n",
      "Training epoch: 653, train loss: 0.01725, val loss: 0.01797\n",
      "Training epoch: 654, train loss: 0.01724, val loss: 0.01793\n",
      "Training epoch: 655, train loss: 0.01729, val loss: 0.01797\n",
      "Training epoch: 656, train loss: 0.01726, val loss: 0.01796\n",
      "Training epoch: 657, train loss: 0.01729, val loss: 0.01800\n",
      "Training epoch: 658, train loss: 0.01727, val loss: 0.01797\n",
      "Training epoch: 659, train loss: 0.01726, val loss: 0.01793\n",
      "Training epoch: 660, train loss: 0.01725, val loss: 0.01795\n",
      "Training epoch: 661, train loss: 0.01731, val loss: 0.01799\n",
      "Training epoch: 662, train loss: 0.01724, val loss: 0.01792\n",
      "Training epoch: 663, train loss: 0.01724, val loss: 0.01793\n",
      "Training epoch: 664, train loss: 0.01730, val loss: 0.01798\n",
      "Training epoch: 665, train loss: 0.01728, val loss: 0.01797\n",
      "Training epoch: 666, train loss: 0.01725, val loss: 0.01795\n",
      "Training epoch: 667, train loss: 0.01730, val loss: 0.01800\n",
      "Training epoch: 668, train loss: 0.01724, val loss: 0.01794\n",
      "Training epoch: 669, train loss: 0.01723, val loss: 0.01793\n",
      "Training epoch: 670, train loss: 0.01732, val loss: 0.01797\n",
      "Training epoch: 671, train loss: 0.01727, val loss: 0.01799\n",
      "Training epoch: 672, train loss: 0.01729, val loss: 0.01795\n",
      "Training epoch: 673, train loss: 0.01723, val loss: 0.01790\n",
      "Training epoch: 674, train loss: 0.01728, val loss: 0.01797\n",
      "Training epoch: 675, train loss: 0.01726, val loss: 0.01795\n",
      "Training epoch: 676, train loss: 0.01728, val loss: 0.01797\n",
      "Training epoch: 677, train loss: 0.01723, val loss: 0.01794\n",
      "Training epoch: 678, train loss: 0.01732, val loss: 0.01801\n",
      "Training epoch: 679, train loss: 0.01724, val loss: 0.01789\n",
      "Training epoch: 680, train loss: 0.01727, val loss: 0.01796\n",
      "Training epoch: 681, train loss: 0.01744, val loss: 0.01815\n",
      "Training epoch: 682, train loss: 0.01722, val loss: 0.01792\n",
      "Training epoch: 683, train loss: 0.01723, val loss: 0.01792\n",
      "Training epoch: 684, train loss: 0.01728, val loss: 0.01794\n",
      "Training epoch: 685, train loss: 0.01730, val loss: 0.01802\n",
      "Training epoch: 686, train loss: 0.01720, val loss: 0.01788\n",
      "Training epoch: 687, train loss: 0.01724, val loss: 0.01791\n",
      "Training epoch: 688, train loss: 0.01728, val loss: 0.01795\n",
      "Training epoch: 689, train loss: 0.01727, val loss: 0.01796\n",
      "Training epoch: 690, train loss: 0.01729, val loss: 0.01799\n",
      "Training epoch: 691, train loss: 0.01723, val loss: 0.01793\n",
      "Training epoch: 692, train loss: 0.01722, val loss: 0.01788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 693, train loss: 0.01720, val loss: 0.01789\n",
      "Training epoch: 694, train loss: 0.01721, val loss: 0.01787\n",
      "Training epoch: 695, train loss: 0.01721, val loss: 0.01791\n",
      "Training epoch: 696, train loss: 0.01720, val loss: 0.01790\n",
      "Training epoch: 697, train loss: 0.01721, val loss: 0.01784\n",
      "Training epoch: 698, train loss: 0.01720, val loss: 0.01789\n",
      "Training epoch: 699, train loss: 0.01720, val loss: 0.01789\n",
      "Training epoch: 700, train loss: 0.01718, val loss: 0.01788\n",
      "Training epoch: 701, train loss: 0.01720, val loss: 0.01787\n",
      "Training epoch: 702, train loss: 0.01720, val loss: 0.01787\n",
      "Training epoch: 703, train loss: 0.01732, val loss: 0.01798\n",
      "Training epoch: 704, train loss: 0.01721, val loss: 0.01787\n",
      "Training epoch: 705, train loss: 0.01728, val loss: 0.01794\n",
      "Training epoch: 706, train loss: 0.01723, val loss: 0.01794\n",
      "Training epoch: 707, train loss: 0.01720, val loss: 0.01786\n",
      "Training epoch: 708, train loss: 0.01722, val loss: 0.01789\n",
      "Training epoch: 709, train loss: 0.01717, val loss: 0.01783\n",
      "Training epoch: 710, train loss: 0.01717, val loss: 0.01785\n",
      "Training epoch: 711, train loss: 0.01725, val loss: 0.01791\n",
      "Training epoch: 712, train loss: 0.01721, val loss: 0.01790\n",
      "Training epoch: 713, train loss: 0.01716, val loss: 0.01785\n",
      "Training epoch: 714, train loss: 0.01717, val loss: 0.01782\n",
      "Training epoch: 715, train loss: 0.01723, val loss: 0.01790\n",
      "Training epoch: 716, train loss: 0.01716, val loss: 0.01785\n",
      "Training epoch: 717, train loss: 0.01722, val loss: 0.01788\n",
      "Training epoch: 718, train loss: 0.01718, val loss: 0.01783\n",
      "Training epoch: 719, train loss: 0.01717, val loss: 0.01783\n",
      "Training epoch: 720, train loss: 0.01739, val loss: 0.01808\n",
      "Training epoch: 721, train loss: 0.01726, val loss: 0.01789\n",
      "Training epoch: 722, train loss: 0.01733, val loss: 0.01801\n",
      "Training epoch: 723, train loss: 0.01715, val loss: 0.01781\n",
      "Training epoch: 724, train loss: 0.01714, val loss: 0.01781\n",
      "Training epoch: 725, train loss: 0.01715, val loss: 0.01780\n",
      "Training epoch: 726, train loss: 0.01713, val loss: 0.01778\n",
      "Training epoch: 727, train loss: 0.01717, val loss: 0.01788\n",
      "Training epoch: 728, train loss: 0.01716, val loss: 0.01778\n",
      "Training epoch: 729, train loss: 0.01718, val loss: 0.01780\n",
      "Training epoch: 730, train loss: 0.01714, val loss: 0.01782\n",
      "Training epoch: 731, train loss: 0.01724, val loss: 0.01787\n",
      "Training epoch: 732, train loss: 0.01717, val loss: 0.01783\n",
      "Training epoch: 733, train loss: 0.01725, val loss: 0.01791\n",
      "Training epoch: 734, train loss: 0.01718, val loss: 0.01783\n",
      "Training epoch: 735, train loss: 0.01711, val loss: 0.01775\n",
      "Training epoch: 736, train loss: 0.01712, val loss: 0.01777\n",
      "Training epoch: 737, train loss: 0.01714, val loss: 0.01778\n",
      "Training epoch: 738, train loss: 0.01712, val loss: 0.01774\n",
      "Training epoch: 739, train loss: 0.01711, val loss: 0.01779\n",
      "Training epoch: 740, train loss: 0.01711, val loss: 0.01775\n",
      "Training epoch: 741, train loss: 0.01715, val loss: 0.01780\n",
      "Training epoch: 742, train loss: 0.01713, val loss: 0.01778\n",
      "Training epoch: 743, train loss: 0.01718, val loss: 0.01781\n",
      "Training epoch: 744, train loss: 0.01710, val loss: 0.01774\n",
      "Training epoch: 745, train loss: 0.01709, val loss: 0.01770\n",
      "Training epoch: 746, train loss: 0.01714, val loss: 0.01778\n",
      "Training epoch: 747, train loss: 0.01709, val loss: 0.01772\n",
      "Training epoch: 748, train loss: 0.01715, val loss: 0.01777\n",
      "Training epoch: 749, train loss: 0.01714, val loss: 0.01774\n",
      "Training epoch: 750, train loss: 0.01710, val loss: 0.01771\n",
      "Training epoch: 751, train loss: 0.01709, val loss: 0.01771\n",
      "Training epoch: 752, train loss: 0.01710, val loss: 0.01771\n",
      "Training epoch: 753, train loss: 0.01710, val loss: 0.01772\n",
      "Training epoch: 754, train loss: 0.01713, val loss: 0.01770\n",
      "Training epoch: 755, train loss: 0.01710, val loss: 0.01775\n",
      "Training epoch: 756, train loss: 0.01713, val loss: 0.01774\n",
      "Training epoch: 757, train loss: 0.01711, val loss: 0.01773\n",
      "Training epoch: 758, train loss: 0.01709, val loss: 0.01770\n",
      "Training epoch: 759, train loss: 0.01709, val loss: 0.01769\n",
      "Training epoch: 760, train loss: 0.01716, val loss: 0.01776\n",
      "Training epoch: 761, train loss: 0.01709, val loss: 0.01770\n",
      "Training epoch: 762, train loss: 0.01721, val loss: 0.01778\n",
      "Training epoch: 763, train loss: 0.01720, val loss: 0.01786\n",
      "Training epoch: 764, train loss: 0.01708, val loss: 0.01769\n",
      "Training epoch: 765, train loss: 0.01716, val loss: 0.01774\n",
      "Training epoch: 766, train loss: 0.01711, val loss: 0.01774\n",
      "Training epoch: 767, train loss: 0.01715, val loss: 0.01776\n",
      "Training epoch: 768, train loss: 0.01716, val loss: 0.01777\n",
      "Training epoch: 769, train loss: 0.01708, val loss: 0.01768\n",
      "Training epoch: 770, train loss: 0.01710, val loss: 0.01769\n",
      "Training epoch: 771, train loss: 0.01711, val loss: 0.01774\n",
      "Training epoch: 772, train loss: 0.01710, val loss: 0.01770\n",
      "Training epoch: 773, train loss: 0.01710, val loss: 0.01771\n",
      "Training epoch: 774, train loss: 0.01711, val loss: 0.01772\n",
      "Training epoch: 775, train loss: 0.01714, val loss: 0.01772\n",
      "Training epoch: 776, train loss: 0.01710, val loss: 0.01775\n",
      "Training epoch: 777, train loss: 0.01727, val loss: 0.01786\n",
      "Training epoch: 778, train loss: 0.01721, val loss: 0.01776\n",
      "Training epoch: 779, train loss: 0.01711, val loss: 0.01771\n",
      "Training epoch: 780, train loss: 0.01711, val loss: 0.01773\n",
      "Training epoch: 781, train loss: 0.01717, val loss: 0.01773\n",
      "Training epoch: 782, train loss: 0.01710, val loss: 0.01770\n",
      "Training epoch: 783, train loss: 0.01714, val loss: 0.01776\n",
      "Training epoch: 784, train loss: 0.01711, val loss: 0.01768\n",
      "Training epoch: 785, train loss: 0.01708, val loss: 0.01771\n",
      "Training epoch: 786, train loss: 0.01710, val loss: 0.01770\n",
      "Training epoch: 787, train loss: 0.01709, val loss: 0.01773\n",
      "Training epoch: 788, train loss: 0.01708, val loss: 0.01766\n",
      "Training epoch: 789, train loss: 0.01709, val loss: 0.01769\n",
      "Training epoch: 790, train loss: 0.01708, val loss: 0.01769\n",
      "Training epoch: 791, train loss: 0.01713, val loss: 0.01773\n",
      "Training epoch: 792, train loss: 0.01708, val loss: 0.01767\n",
      "Training epoch: 793, train loss: 0.01708, val loss: 0.01769\n",
      "Training epoch: 794, train loss: 0.01709, val loss: 0.01770\n",
      "Training epoch: 795, train loss: 0.01710, val loss: 0.01768\n",
      "Training epoch: 796, train loss: 0.01709, val loss: 0.01772\n",
      "Training epoch: 797, train loss: 0.01708, val loss: 0.01768\n",
      "Training epoch: 798, train loss: 0.01711, val loss: 0.01773\n",
      "Training epoch: 799, train loss: 0.01715, val loss: 0.01775\n",
      "Training epoch: 800, train loss: 0.01716, val loss: 0.01773\n",
      "Training epoch: 801, train loss: 0.01712, val loss: 0.01774\n",
      "Training epoch: 802, train loss: 0.01709, val loss: 0.01767\n",
      "Training epoch: 803, train loss: 0.01715, val loss: 0.01774\n",
      "Training epoch: 804, train loss: 0.01709, val loss: 0.01771\n",
      "Training epoch: 805, train loss: 0.01710, val loss: 0.01773\n",
      "Training epoch: 806, train loss: 0.01709, val loss: 0.01771\n",
      "Training epoch: 807, train loss: 0.01711, val loss: 0.01768\n",
      "Training epoch: 808, train loss: 0.01708, val loss: 0.01770\n",
      "Training epoch: 809, train loss: 0.01710, val loss: 0.01770\n",
      "Training epoch: 810, train loss: 0.01708, val loss: 0.01767\n",
      "Training epoch: 811, train loss: 0.01709, val loss: 0.01770\n",
      "Training epoch: 812, train loss: 0.01714, val loss: 0.01777\n",
      "Training epoch: 813, train loss: 0.01709, val loss: 0.01770\n",
      "Training epoch: 814, train loss: 0.01708, val loss: 0.01769\n",
      "Training epoch: 815, train loss: 0.01709, val loss: 0.01771\n",
      "Training epoch: 816, train loss: 0.01709, val loss: 0.01768\n",
      "Training epoch: 817, train loss: 0.01707, val loss: 0.01769\n",
      "Training epoch: 818, train loss: 0.01709, val loss: 0.01770\n",
      "Training epoch: 819, train loss: 0.01708, val loss: 0.01767\n",
      "Training epoch: 820, train loss: 0.01708, val loss: 0.01766\n",
      "Training epoch: 821, train loss: 0.01709, val loss: 0.01767\n",
      "Training epoch: 822, train loss: 0.01714, val loss: 0.01776\n",
      "Training epoch: 823, train loss: 0.01710, val loss: 0.01770\n",
      "Training epoch: 824, train loss: 0.01710, val loss: 0.01773\n",
      "Training epoch: 825, train loss: 0.01708, val loss: 0.01768\n",
      "Training epoch: 826, train loss: 0.01723, val loss: 0.01783\n",
      "Training epoch: 827, train loss: 0.01708, val loss: 0.01768\n",
      "Training epoch: 828, train loss: 0.01712, val loss: 0.01772\n",
      "Training epoch: 829, train loss: 0.01708, val loss: 0.01766\n",
      "Training epoch: 830, train loss: 0.01714, val loss: 0.01773\n",
      "Training epoch: 831, train loss: 0.01709, val loss: 0.01768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 832, train loss: 0.01710, val loss: 0.01769\n",
      "Training epoch: 833, train loss: 0.01707, val loss: 0.01769\n",
      "Training epoch: 834, train loss: 0.01709, val loss: 0.01769\n",
      "Training epoch: 835, train loss: 0.01707, val loss: 0.01768\n",
      "Training epoch: 836, train loss: 0.01709, val loss: 0.01768\n",
      "Training epoch: 837, train loss: 0.01714, val loss: 0.01772\n",
      "Training epoch: 838, train loss: 0.01709, val loss: 0.01770\n",
      "Training epoch: 839, train loss: 0.01709, val loss: 0.01770\n",
      "Training epoch: 840, train loss: 0.01707, val loss: 0.01766\n",
      "Training epoch: 841, train loss: 0.01718, val loss: 0.01779\n",
      "Training epoch: 842, train loss: 0.01716, val loss: 0.01777\n",
      "Training epoch: 843, train loss: 0.01709, val loss: 0.01769\n",
      "Training epoch: 844, train loss: 0.01712, val loss: 0.01770\n",
      "Training epoch: 845, train loss: 0.01727, val loss: 0.01792\n",
      "Training epoch: 846, train loss: 0.01710, val loss: 0.01770\n",
      "Training epoch: 847, train loss: 0.01724, val loss: 0.01783\n",
      "Training epoch: 848, train loss: 0.01710, val loss: 0.01772\n",
      "Training epoch: 849, train loss: 0.01721, val loss: 0.01782\n",
      "Training epoch: 850, train loss: 0.01713, val loss: 0.01774\n",
      "Training epoch: 851, train loss: 0.01713, val loss: 0.01776\n",
      "Training epoch: 852, train loss: 0.01715, val loss: 0.01777\n",
      "Training epoch: 853, train loss: 0.01709, val loss: 0.01767\n",
      "Training epoch: 854, train loss: 0.01708, val loss: 0.01772\n",
      "Training epoch: 855, train loss: 0.01710, val loss: 0.01769\n",
      "Training epoch: 856, train loss: 0.01708, val loss: 0.01772\n",
      "Training epoch: 857, train loss: 0.01707, val loss: 0.01769\n",
      "Training epoch: 858, train loss: 0.01708, val loss: 0.01766\n",
      "Training epoch: 859, train loss: 0.01720, val loss: 0.01778\n",
      "Training epoch: 860, train loss: 0.01724, val loss: 0.01790\n",
      "Training epoch: 861, train loss: 0.01708, val loss: 0.01769\n",
      "Training epoch: 862, train loss: 0.01730, val loss: 0.01785\n",
      "Training epoch: 863, train loss: 0.01717, val loss: 0.01781\n",
      "Training epoch: 864, train loss: 0.01714, val loss: 0.01773\n",
      "Training epoch: 865, train loss: 0.01708, val loss: 0.01771\n",
      "Training epoch: 866, train loss: 0.01709, val loss: 0.01771\n",
      "Training epoch: 867, train loss: 0.01709, val loss: 0.01770\n",
      "Training epoch: 868, train loss: 0.01708, val loss: 0.01770\n",
      "Training epoch: 869, train loss: 0.01708, val loss: 0.01770\n",
      "Training epoch: 870, train loss: 0.01707, val loss: 0.01768\n",
      "Training epoch: 871, train loss: 0.01707, val loss: 0.01770\n",
      "Training epoch: 872, train loss: 0.01706, val loss: 0.01768\n",
      "Training epoch: 873, train loss: 0.01707, val loss: 0.01766\n",
      "Training epoch: 874, train loss: 0.01707, val loss: 0.01767\n",
      "Training epoch: 875, train loss: 0.01708, val loss: 0.01771\n",
      "Training epoch: 876, train loss: 0.01707, val loss: 0.01766\n",
      "Training epoch: 877, train loss: 0.01708, val loss: 0.01768\n",
      "Training epoch: 878, train loss: 0.01711, val loss: 0.01774\n",
      "Training epoch: 879, train loss: 0.01709, val loss: 0.01769\n",
      "Training epoch: 880, train loss: 0.01711, val loss: 0.01772\n",
      "Training epoch: 881, train loss: 0.01709, val loss: 0.01772\n",
      "Training epoch: 882, train loss: 0.01711, val loss: 0.01767\n",
      "Training epoch: 883, train loss: 0.01709, val loss: 0.01771\n",
      "Training epoch: 884, train loss: 0.01708, val loss: 0.01770\n",
      "Training epoch: 885, train loss: 0.01711, val loss: 0.01772\n",
      "Training epoch: 886, train loss: 0.01708, val loss: 0.01770\n",
      "Training epoch: 887, train loss: 0.01713, val loss: 0.01775\n",
      "Training epoch: 888, train loss: 0.01714, val loss: 0.01773\n",
      "Training epoch: 889, train loss: 0.01707, val loss: 0.01770\n",
      "Training epoch: 890, train loss: 0.01719, val loss: 0.01783\n",
      "Training epoch: 891, train loss: 0.01708, val loss: 0.01767\n",
      "Training epoch: 892, train loss: 0.01707, val loss: 0.01768\n",
      "Training epoch: 893, train loss: 0.01713, val loss: 0.01774\n",
      "Training epoch: 894, train loss: 0.01721, val loss: 0.01779\n",
      "Training epoch: 895, train loss: 0.01710, val loss: 0.01768\n",
      "Training epoch: 896, train loss: 0.01709, val loss: 0.01772\n",
      "Training epoch: 897, train loss: 0.01709, val loss: 0.01771\n",
      "Training epoch: 898, train loss: 0.01707, val loss: 0.01766\n",
      "Training epoch: 899, train loss: 0.01708, val loss: 0.01770\n",
      "Training epoch: 900, train loss: 0.01707, val loss: 0.01769\n",
      "Training epoch: 901, train loss: 0.01707, val loss: 0.01770\n",
      "Training epoch: 902, train loss: 0.01708, val loss: 0.01766\n",
      "Training epoch: 903, train loss: 0.01706, val loss: 0.01765\n",
      "Training epoch: 904, train loss: 0.01721, val loss: 0.01787\n",
      "Training epoch: 905, train loss: 0.01709, val loss: 0.01771\n",
      "Training epoch: 906, train loss: 0.01706, val loss: 0.01765\n",
      "Training epoch: 907, train loss: 0.01714, val loss: 0.01777\n",
      "Training epoch: 908, train loss: 0.01709, val loss: 0.01768\n",
      "Training epoch: 909, train loss: 0.01707, val loss: 0.01770\n",
      "Training epoch: 910, train loss: 0.01708, val loss: 0.01766\n",
      "Training epoch: 911, train loss: 0.01707, val loss: 0.01768\n",
      "Training epoch: 912, train loss: 0.01706, val loss: 0.01770\n",
      "Training epoch: 913, train loss: 0.01714, val loss: 0.01774\n",
      "Training epoch: 914, train loss: 0.01708, val loss: 0.01769\n",
      "Training epoch: 915, train loss: 0.01709, val loss: 0.01771\n",
      "Training epoch: 916, train loss: 0.01709, val loss: 0.01770\n",
      "Training epoch: 917, train loss: 0.01710, val loss: 0.01769\n",
      "Training epoch: 918, train loss: 0.01712, val loss: 0.01775\n",
      "Training epoch: 919, train loss: 0.01711, val loss: 0.01772\n",
      "Training epoch: 920, train loss: 0.01706, val loss: 0.01767\n",
      "Training epoch: 921, train loss: 0.01708, val loss: 0.01769\n",
      "Training epoch: 922, train loss: 0.01707, val loss: 0.01769\n",
      "Training epoch: 923, train loss: 0.01707, val loss: 0.01768\n",
      "Training epoch: 924, train loss: 0.01708, val loss: 0.01768\n",
      "Training epoch: 925, train loss: 0.01707, val loss: 0.01768\n",
      "Training epoch: 926, train loss: 0.01706, val loss: 0.01768\n",
      "Training epoch: 927, train loss: 0.01711, val loss: 0.01773\n",
      "Training epoch: 928, train loss: 0.01708, val loss: 0.01767\n",
      "Training epoch: 929, train loss: 0.01712, val loss: 0.01772\n",
      "Training epoch: 930, train loss: 0.01709, val loss: 0.01767\n",
      "Training epoch: 931, train loss: 0.01713, val loss: 0.01770\n",
      "Training epoch: 932, train loss: 0.01709, val loss: 0.01774\n",
      "Training epoch: 933, train loss: 0.01709, val loss: 0.01770\n",
      "Training epoch: 934, train loss: 0.01724, val loss: 0.01788\n",
      "Training epoch: 935, train loss: 0.01710, val loss: 0.01769\n",
      "Training epoch: 936, train loss: 0.01708, val loss: 0.01769\n",
      "Training epoch: 937, train loss: 0.01709, val loss: 0.01770\n",
      "Training epoch: 938, train loss: 0.01706, val loss: 0.01768\n",
      "Training epoch: 939, train loss: 0.01716, val loss: 0.01773\n",
      "Training epoch: 940, train loss: 0.01711, val loss: 0.01775\n",
      "Training epoch: 941, train loss: 0.01708, val loss: 0.01770\n",
      "Training epoch: 942, train loss: 0.01717, val loss: 0.01773\n",
      "Training epoch: 943, train loss: 0.01709, val loss: 0.01771\n",
      "Training epoch: 944, train loss: 0.01707, val loss: 0.01767\n",
      "Training epoch: 945, train loss: 0.01707, val loss: 0.01768\n",
      "Training epoch: 946, train loss: 0.01706, val loss: 0.01770\n",
      "Training epoch: 947, train loss: 0.01712, val loss: 0.01772\n",
      "Training epoch: 948, train loss: 0.01708, val loss: 0.01767\n",
      "Training epoch: 949, train loss: 0.01708, val loss: 0.01773\n",
      "Training epoch: 950, train loss: 0.01706, val loss: 0.01766\n",
      "Training epoch: 951, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 952, train loss: 0.01706, val loss: 0.01769\n",
      "Training epoch: 953, train loss: 0.01707, val loss: 0.01768\n",
      "Training epoch: 954, train loss: 0.01709, val loss: 0.01772\n",
      "Training epoch: 955, train loss: 0.01711, val loss: 0.01774\n",
      "Training epoch: 956, train loss: 0.01712, val loss: 0.01769\n",
      "Training epoch: 957, train loss: 0.01706, val loss: 0.01769\n",
      "Training epoch: 958, train loss: 0.01719, val loss: 0.01783\n",
      "Training epoch: 959, train loss: 0.01707, val loss: 0.01769\n",
      "Training epoch: 960, train loss: 0.01710, val loss: 0.01776\n",
      "Training epoch: 961, train loss: 0.01711, val loss: 0.01772\n",
      "Training epoch: 962, train loss: 0.01710, val loss: 0.01768\n",
      "Training epoch: 963, train loss: 0.01712, val loss: 0.01778\n",
      "Training epoch: 964, train loss: 0.01706, val loss: 0.01768\n",
      "Training epoch: 965, train loss: 0.01706, val loss: 0.01767\n",
      "Training epoch: 966, train loss: 0.01710, val loss: 0.01770\n",
      "Training epoch: 967, train loss: 0.01711, val loss: 0.01775\n",
      "Training epoch: 968, train loss: 0.01714, val loss: 0.01772\n",
      "Training epoch: 969, train loss: 0.01708, val loss: 0.01768\n",
      "Training epoch: 970, train loss: 0.01708, val loss: 0.01768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 971, train loss: 0.01710, val loss: 0.01773\n",
      "Training epoch: 972, train loss: 0.01707, val loss: 0.01768\n",
      "Training epoch: 973, train loss: 0.01708, val loss: 0.01767\n",
      "Training epoch: 974, train loss: 0.01710, val loss: 0.01775\n",
      "Training epoch: 975, train loss: 0.01709, val loss: 0.01771\n",
      "Training epoch: 976, train loss: 0.01713, val loss: 0.01775\n",
      "Training epoch: 977, train loss: 0.01708, val loss: 0.01768\n",
      "Training epoch: 978, train loss: 0.01709, val loss: 0.01771\n",
      "Training epoch: 979, train loss: 0.01705, val loss: 0.01768\n",
      "Training epoch: 980, train loss: 0.01705, val loss: 0.01765\n",
      "Training epoch: 981, train loss: 0.01706, val loss: 0.01765\n",
      "Training epoch: 982, train loss: 0.01714, val loss: 0.01775\n",
      "Training epoch: 983, train loss: 0.01711, val loss: 0.01775\n",
      "Training epoch: 984, train loss: 0.01705, val loss: 0.01767\n",
      "Training epoch: 985, train loss: 0.01706, val loss: 0.01769\n",
      "Training epoch: 986, train loss: 0.01708, val loss: 0.01767\n",
      "Training epoch: 987, train loss: 0.01707, val loss: 0.01770\n",
      "Training epoch: 988, train loss: 0.01707, val loss: 0.01770\n",
      "Training epoch: 989, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 990, train loss: 0.01705, val loss: 0.01768\n",
      "Training epoch: 991, train loss: 0.01709, val loss: 0.01772\n",
      "Training epoch: 992, train loss: 0.01707, val loss: 0.01766\n",
      "Training epoch: 993, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 994, train loss: 0.01708, val loss: 0.01767\n",
      "Training epoch: 995, train loss: 0.01708, val loss: 0.01769\n",
      "Training epoch: 996, train loss: 0.01706, val loss: 0.01767\n",
      "Training epoch: 997, train loss: 0.01707, val loss: 0.01768\n",
      "Training epoch: 998, train loss: 0.01708, val loss: 0.01768\n",
      "Training epoch: 999, train loss: 0.01709, val loss: 0.01772\n",
      "Training epoch: 1000, train loss: 0.01712, val loss: 0.01771\n",
      "Training epoch: 1001, train loss: 0.01707, val loss: 0.01768\n",
      "Training epoch: 1002, train loss: 0.01708, val loss: 0.01775\n",
      "Training epoch: 1003, train loss: 0.01706, val loss: 0.01767\n",
      "Training epoch: 1004, train loss: 0.01709, val loss: 0.01768\n",
      "Training epoch: 1005, train loss: 0.01707, val loss: 0.01768\n",
      "Training epoch: 1006, train loss: 0.01709, val loss: 0.01770\n",
      "Training epoch: 1007, train loss: 0.01705, val loss: 0.01767\n",
      "Training epoch: 1008, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 1009, train loss: 0.01705, val loss: 0.01768\n",
      "Training epoch: 1010, train loss: 0.01710, val loss: 0.01769\n",
      "Training epoch: 1011, train loss: 0.01712, val loss: 0.01775\n",
      "Training epoch: 1012, train loss: 0.01708, val loss: 0.01769\n",
      "Training epoch: 1013, train loss: 0.01708, val loss: 0.01766\n",
      "Training epoch: 1014, train loss: 0.01706, val loss: 0.01768\n",
      "Training epoch: 1015, train loss: 0.01706, val loss: 0.01765\n",
      "Training epoch: 1016, train loss: 0.01711, val loss: 0.01770\n",
      "Training epoch: 1017, train loss: 0.01706, val loss: 0.01767\n",
      "Training epoch: 1018, train loss: 0.01708, val loss: 0.01767\n",
      "Training epoch: 1019, train loss: 0.01709, val loss: 0.01765\n",
      "Training epoch: 1020, train loss: 0.01706, val loss: 0.01770\n",
      "Training epoch: 1021, train loss: 0.01710, val loss: 0.01773\n",
      "Training epoch: 1022, train loss: 0.01709, val loss: 0.01765\n",
      "Training epoch: 1023, train loss: 0.01708, val loss: 0.01770\n",
      "Training epoch: 1024, train loss: 0.01711, val loss: 0.01772\n",
      "Training epoch: 1025, train loss: 0.01708, val loss: 0.01766\n",
      "Training epoch: 1026, train loss: 0.01706, val loss: 0.01769\n",
      "Training epoch: 1027, train loss: 0.01712, val loss: 0.01776\n",
      "Training epoch: 1028, train loss: 0.01708, val loss: 0.01768\n",
      "Training epoch: 1029, train loss: 0.01706, val loss: 0.01768\n",
      "Training epoch: 1030, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 1031, train loss: 0.01705, val loss: 0.01765\n",
      "Training epoch: 1032, train loss: 0.01709, val loss: 0.01773\n",
      "Training epoch: 1033, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 1034, train loss: 0.01706, val loss: 0.01767\n",
      "Training epoch: 1035, train loss: 0.01706, val loss: 0.01771\n",
      "Training epoch: 1036, train loss: 0.01706, val loss: 0.01767\n",
      "Training epoch: 1037, train loss: 0.01712, val loss: 0.01774\n",
      "Training epoch: 1038, train loss: 0.01713, val loss: 0.01774\n",
      "Training epoch: 1039, train loss: 0.01709, val loss: 0.01768\n",
      "Training epoch: 1040, train loss: 0.01706, val loss: 0.01768\n",
      "Training epoch: 1041, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 1042, train loss: 0.01715, val loss: 0.01777\n",
      "Training epoch: 1043, train loss: 0.01713, val loss: 0.01773\n",
      "Training epoch: 1044, train loss: 0.01706, val loss: 0.01771\n",
      "Training epoch: 1045, train loss: 0.01713, val loss: 0.01776\n",
      "Training epoch: 1046, train loss: 0.01706, val loss: 0.01766\n",
      "Training epoch: 1047, train loss: 0.01709, val loss: 0.01773\n",
      "Training epoch: 1048, train loss: 0.01706, val loss: 0.01766\n",
      "Training epoch: 1049, train loss: 0.01710, val loss: 0.01771\n",
      "Training epoch: 1050, train loss: 0.01713, val loss: 0.01774\n",
      "Training epoch: 1051, train loss: 0.01716, val loss: 0.01780\n",
      "Training epoch: 1052, train loss: 0.01706, val loss: 0.01768\n",
      "Training epoch: 1053, train loss: 0.01713, val loss: 0.01773\n",
      "Training epoch: 1054, train loss: 0.01706, val loss: 0.01767\n",
      "Training epoch: 1055, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1056, train loss: 0.01712, val loss: 0.01773\n",
      "Training epoch: 1057, train loss: 0.01705, val loss: 0.01769\n",
      "Training epoch: 1058, train loss: 0.01707, val loss: 0.01769\n",
      "Training epoch: 1059, train loss: 0.01708, val loss: 0.01768\n",
      "Training epoch: 1060, train loss: 0.01705, val loss: 0.01765\n",
      "Training epoch: 1061, train loss: 0.01711, val loss: 0.01768\n",
      "Training epoch: 1062, train loss: 0.01707, val loss: 0.01767\n",
      "Training epoch: 1063, train loss: 0.01706, val loss: 0.01770\n",
      "Training epoch: 1064, train loss: 0.01704, val loss: 0.01769\n",
      "Training epoch: 1065, train loss: 0.01712, val loss: 0.01769\n",
      "Training epoch: 1066, train loss: 0.01705, val loss: 0.01768\n",
      "Training epoch: 1067, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1068, train loss: 0.01705, val loss: 0.01768\n",
      "Training epoch: 1069, train loss: 0.01705, val loss: 0.01767\n",
      "Training epoch: 1070, train loss: 0.01709, val loss: 0.01771\n",
      "Training epoch: 1071, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1072, train loss: 0.01706, val loss: 0.01770\n",
      "Training epoch: 1073, train loss: 0.01708, val loss: 0.01772\n",
      "Training epoch: 1074, train loss: 0.01706, val loss: 0.01769\n",
      "Training epoch: 1075, train loss: 0.01705, val loss: 0.01767\n",
      "Training epoch: 1076, train loss: 0.01708, val loss: 0.01773\n",
      "Training epoch: 1077, train loss: 0.01707, val loss: 0.01768\n",
      "Training epoch: 1078, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1079, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1080, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1081, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1082, train loss: 0.01706, val loss: 0.01765\n",
      "Training epoch: 1083, train loss: 0.01706, val loss: 0.01766\n",
      "Training epoch: 1084, train loss: 0.01709, val loss: 0.01774\n",
      "Training epoch: 1085, train loss: 0.01706, val loss: 0.01767\n",
      "Training epoch: 1086, train loss: 0.01714, val loss: 0.01774\n",
      "Training epoch: 1087, train loss: 0.01706, val loss: 0.01767\n",
      "Training epoch: 1088, train loss: 0.01705, val loss: 0.01767\n",
      "Training epoch: 1089, train loss: 0.01709, val loss: 0.01768\n",
      "Training epoch: 1090, train loss: 0.01706, val loss: 0.01770\n",
      "Training epoch: 1091, train loss: 0.01705, val loss: 0.01768\n",
      "Training epoch: 1092, train loss: 0.01706, val loss: 0.01770\n",
      "Training epoch: 1093, train loss: 0.01704, val loss: 0.01763\n",
      "Training epoch: 1094, train loss: 0.01706, val loss: 0.01767\n",
      "Training epoch: 1095, train loss: 0.01705, val loss: 0.01768\n",
      "Training epoch: 1096, train loss: 0.01710, val loss: 0.01770\n",
      "Training epoch: 1097, train loss: 0.01706, val loss: 0.01768\n",
      "Training epoch: 1098, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1099, train loss: 0.01708, val loss: 0.01767\n",
      "Training epoch: 1100, train loss: 0.01706, val loss: 0.01767\n",
      "Training epoch: 1101, train loss: 0.01705, val loss: 0.01769\n",
      "Training epoch: 1102, train loss: 0.01722, val loss: 0.01788\n",
      "Training epoch: 1103, train loss: 0.01711, val loss: 0.01771\n",
      "Training epoch: 1104, train loss: 0.01705, val loss: 0.01767\n",
      "Training epoch: 1105, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 1106, train loss: 0.01704, val loss: 0.01765\n",
      "Training epoch: 1107, train loss: 0.01707, val loss: 0.01768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1108, train loss: 0.01705, val loss: 0.01771\n",
      "Training epoch: 1109, train loss: 0.01710, val loss: 0.01774\n",
      "Training epoch: 1110, train loss: 0.01711, val loss: 0.01769\n",
      "Training epoch: 1111, train loss: 0.01707, val loss: 0.01771\n",
      "Training epoch: 1112, train loss: 0.01714, val loss: 0.01776\n",
      "Training epoch: 1113, train loss: 0.01727, val loss: 0.01788\n",
      "Training epoch: 1114, train loss: 0.01707, val loss: 0.01771\n",
      "Training epoch: 1115, train loss: 0.01704, val loss: 0.01764\n",
      "Training epoch: 1116, train loss: 0.01706, val loss: 0.01766\n",
      "Training epoch: 1117, train loss: 0.01706, val loss: 0.01768\n",
      "Training epoch: 1118, train loss: 0.01705, val loss: 0.01767\n",
      "Training epoch: 1119, train loss: 0.01704, val loss: 0.01768\n",
      "Training epoch: 1120, train loss: 0.01706, val loss: 0.01766\n",
      "Training epoch: 1121, train loss: 0.01709, val loss: 0.01768\n",
      "Training epoch: 1122, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1123, train loss: 0.01706, val loss: 0.01769\n",
      "Training epoch: 1124, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 1125, train loss: 0.01706, val loss: 0.01768\n",
      "Training epoch: 1126, train loss: 0.01708, val loss: 0.01768\n",
      "Training epoch: 1127, train loss: 0.01708, val loss: 0.01771\n",
      "Training epoch: 1128, train loss: 0.01710, val loss: 0.01768\n",
      "Training epoch: 1129, train loss: 0.01704, val loss: 0.01763\n",
      "Training epoch: 1130, train loss: 0.01704, val loss: 0.01764\n",
      "Training epoch: 1131, train loss: 0.01703, val loss: 0.01767\n",
      "Training epoch: 1132, train loss: 0.01706, val loss: 0.01770\n",
      "Training epoch: 1133, train loss: 0.01707, val loss: 0.01767\n",
      "Training epoch: 1134, train loss: 0.01707, val loss: 0.01768\n",
      "Training epoch: 1135, train loss: 0.01708, val loss: 0.01767\n",
      "Training epoch: 1136, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1137, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1138, train loss: 0.01709, val loss: 0.01771\n",
      "Training epoch: 1139, train loss: 0.01706, val loss: 0.01767\n",
      "Training epoch: 1140, train loss: 0.01705, val loss: 0.01765\n",
      "Training epoch: 1141, train loss: 0.01708, val loss: 0.01771\n",
      "Training epoch: 1142, train loss: 0.01714, val loss: 0.01781\n",
      "Training epoch: 1143, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 1144, train loss: 0.01705, val loss: 0.01767\n",
      "Training epoch: 1145, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1146, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1147, train loss: 0.01707, val loss: 0.01769\n",
      "Training epoch: 1148, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1149, train loss: 0.01709, val loss: 0.01771\n",
      "Training epoch: 1150, train loss: 0.01717, val loss: 0.01773\n",
      "Training epoch: 1151, train loss: 0.01714, val loss: 0.01781\n",
      "Training epoch: 1152, train loss: 0.01706, val loss: 0.01769\n",
      "Training epoch: 1153, train loss: 0.01705, val loss: 0.01764\n",
      "Training epoch: 1154, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1155, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 1156, train loss: 0.01705, val loss: 0.01767\n",
      "Training epoch: 1157, train loss: 0.01703, val loss: 0.01766\n",
      "Training epoch: 1158, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1159, train loss: 0.01705, val loss: 0.01765\n",
      "Training epoch: 1160, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1161, train loss: 0.01706, val loss: 0.01771\n",
      "Training epoch: 1162, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 1163, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1164, train loss: 0.01705, val loss: 0.01767\n",
      "Training epoch: 1165, train loss: 0.01710, val loss: 0.01772\n",
      "Training epoch: 1166, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1167, train loss: 0.01703, val loss: 0.01765\n",
      "Training epoch: 1168, train loss: 0.01704, val loss: 0.01765\n",
      "Training epoch: 1169, train loss: 0.01703, val loss: 0.01765\n",
      "Training epoch: 1170, train loss: 0.01707, val loss: 0.01769\n",
      "Training epoch: 1171, train loss: 0.01706, val loss: 0.01768\n",
      "Training epoch: 1172, train loss: 0.01708, val loss: 0.01768\n",
      "Training epoch: 1173, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1174, train loss: 0.01712, val loss: 0.01771\n",
      "Training epoch: 1175, train loss: 0.01708, val loss: 0.01768\n",
      "Training epoch: 1176, train loss: 0.01705, val loss: 0.01769\n",
      "Training epoch: 1177, train loss: 0.01713, val loss: 0.01776\n",
      "Training epoch: 1178, train loss: 0.01710, val loss: 0.01770\n",
      "Training epoch: 1179, train loss: 0.01704, val loss: 0.01768\n",
      "Training epoch: 1180, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1181, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1182, train loss: 0.01704, val loss: 0.01764\n",
      "Training epoch: 1183, train loss: 0.01703, val loss: 0.01765\n",
      "Training epoch: 1184, train loss: 0.01705, val loss: 0.01765\n",
      "Training epoch: 1185, train loss: 0.01711, val loss: 0.01777\n",
      "Training epoch: 1186, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 1187, train loss: 0.01703, val loss: 0.01763\n",
      "Training epoch: 1188, train loss: 0.01708, val loss: 0.01771\n",
      "Training epoch: 1189, train loss: 0.01703, val loss: 0.01766\n",
      "Training epoch: 1190, train loss: 0.01707, val loss: 0.01768\n",
      "Training epoch: 1191, train loss: 0.01705, val loss: 0.01765\n",
      "Training epoch: 1192, train loss: 0.01715, val loss: 0.01774\n",
      "Training epoch: 1193, train loss: 0.01727, val loss: 0.01788\n",
      "Training epoch: 1194, train loss: 0.01707, val loss: 0.01769\n",
      "Training epoch: 1195, train loss: 0.01708, val loss: 0.01769\n",
      "Training epoch: 1196, train loss: 0.01710, val loss: 0.01774\n",
      "Training epoch: 1197, train loss: 0.01717, val loss: 0.01777\n",
      "Training epoch: 1198, train loss: 0.01706, val loss: 0.01769\n",
      "Training epoch: 1199, train loss: 0.01707, val loss: 0.01767\n",
      "Training epoch: 1200, train loss: 0.01724, val loss: 0.01788\n",
      "Training epoch: 1201, train loss: 0.01717, val loss: 0.01782\n",
      "Training epoch: 1202, train loss: 0.01705, val loss: 0.01765\n",
      "Training epoch: 1203, train loss: 0.01706, val loss: 0.01765\n",
      "Training epoch: 1204, train loss: 0.01710, val loss: 0.01771\n",
      "Training epoch: 1205, train loss: 0.01703, val loss: 0.01768\n",
      "Training epoch: 1206, train loss: 0.01714, val loss: 0.01773\n",
      "Training epoch: 1207, train loss: 0.01724, val loss: 0.01788\n",
      "Training epoch: 1208, train loss: 0.01731, val loss: 0.01787\n",
      "Training epoch: 1209, train loss: 0.01709, val loss: 0.01774\n",
      "Training epoch: 1210, train loss: 0.01706, val loss: 0.01768\n",
      "Training epoch: 1211, train loss: 0.01707, val loss: 0.01767\n",
      "Training epoch: 1212, train loss: 0.01703, val loss: 0.01766\n",
      "Training epoch: 1213, train loss: 0.01706, val loss: 0.01767\n",
      "Training epoch: 1214, train loss: 0.01704, val loss: 0.01765\n",
      "Training epoch: 1215, train loss: 0.01703, val loss: 0.01767\n",
      "Training epoch: 1216, train loss: 0.01711, val loss: 0.01777\n",
      "Training epoch: 1217, train loss: 0.01710, val loss: 0.01771\n",
      "Training epoch: 1218, train loss: 0.01707, val loss: 0.01766\n",
      "Training epoch: 1219, train loss: 0.01706, val loss: 0.01764\n",
      "Training epoch: 1220, train loss: 0.01703, val loss: 0.01768\n",
      "Training epoch: 1221, train loss: 0.01706, val loss: 0.01768\n",
      "Training epoch: 1222, train loss: 0.01705, val loss: 0.01767\n",
      "Training epoch: 1223, train loss: 0.01707, val loss: 0.01771\n",
      "Training epoch: 1224, train loss: 0.01711, val loss: 0.01772\n",
      "Training epoch: 1225, train loss: 0.01704, val loss: 0.01769\n",
      "Training epoch: 1226, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 1227, train loss: 0.01704, val loss: 0.01764\n",
      "Training epoch: 1228, train loss: 0.01703, val loss: 0.01767\n",
      "Training epoch: 1229, train loss: 0.01714, val loss: 0.01774\n",
      "Training epoch: 1230, train loss: 0.01713, val loss: 0.01775\n",
      "Training epoch: 1231, train loss: 0.01718, val loss: 0.01777\n",
      "Training epoch: 1232, train loss: 0.01704, val loss: 0.01770\n",
      "Training epoch: 1233, train loss: 0.01715, val loss: 0.01777\n",
      "Training epoch: 1234, train loss: 0.01727, val loss: 0.01782\n",
      "Training epoch: 1235, train loss: 0.01716, val loss: 0.01780\n",
      "Training epoch: 1236, train loss: 0.01708, val loss: 0.01770\n",
      "Training epoch: 1237, train loss: 0.01705, val loss: 0.01770\n",
      "Training epoch: 1238, train loss: 0.01705, val loss: 0.01763\n",
      "Training epoch: 1239, train loss: 0.01703, val loss: 0.01765\n",
      "Training epoch: 1240, train loss: 0.01704, val loss: 0.01769\n",
      "Training epoch: 1241, train loss: 0.01704, val loss: 0.01765\n",
      "Training epoch: 1242, train loss: 0.01707, val loss: 0.01767\n",
      "Training epoch: 1243, train loss: 0.01703, val loss: 0.01768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1244, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1245, train loss: 0.01705, val loss: 0.01769\n",
      "Training epoch: 1246, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 1247, train loss: 0.01703, val loss: 0.01764\n",
      "Training epoch: 1248, train loss: 0.01703, val loss: 0.01765\n",
      "Training epoch: 1249, train loss: 0.01705, val loss: 0.01771\n",
      "Training epoch: 1250, train loss: 0.01703, val loss: 0.01766\n",
      "Training epoch: 1251, train loss: 0.01711, val loss: 0.01766\n",
      "Training epoch: 1252, train loss: 0.01703, val loss: 0.01769\n",
      "Training epoch: 1253, train loss: 0.01705, val loss: 0.01769\n",
      "Training epoch: 1254, train loss: 0.01708, val loss: 0.01766\n",
      "Training epoch: 1255, train loss: 0.01709, val loss: 0.01775\n",
      "Training epoch: 1256, train loss: 0.01705, val loss: 0.01768\n",
      "Training epoch: 1257, train loss: 0.01704, val loss: 0.01768\n",
      "Training epoch: 1258, train loss: 0.01704, val loss: 0.01765\n",
      "Training epoch: 1259, train loss: 0.01702, val loss: 0.01765\n",
      "Training epoch: 1260, train loss: 0.01705, val loss: 0.01767\n",
      "Training epoch: 1261, train loss: 0.01705, val loss: 0.01770\n",
      "Training epoch: 1262, train loss: 0.01703, val loss: 0.01764\n",
      "Training epoch: 1263, train loss: 0.01703, val loss: 0.01766\n",
      "Training epoch: 1264, train loss: 0.01703, val loss: 0.01765\n",
      "Training epoch: 1265, train loss: 0.01704, val loss: 0.01765\n",
      "Training epoch: 1266, train loss: 0.01704, val loss: 0.01771\n",
      "Training epoch: 1267, train loss: 0.01705, val loss: 0.01763\n",
      "Training epoch: 1268, train loss: 0.01702, val loss: 0.01765\n",
      "Training epoch: 1269, train loss: 0.01703, val loss: 0.01767\n",
      "Training epoch: 1270, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1271, train loss: 0.01702, val loss: 0.01766\n",
      "Training epoch: 1272, train loss: 0.01702, val loss: 0.01762\n",
      "Training epoch: 1273, train loss: 0.01706, val loss: 0.01769\n",
      "Training epoch: 1274, train loss: 0.01702, val loss: 0.01766\n",
      "Training epoch: 1275, train loss: 0.01704, val loss: 0.01768\n",
      "Training epoch: 1276, train loss: 0.01703, val loss: 0.01763\n",
      "Training epoch: 1277, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 1278, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 1279, train loss: 0.01703, val loss: 0.01763\n",
      "Training epoch: 1280, train loss: 0.01703, val loss: 0.01765\n",
      "Training epoch: 1281, train loss: 0.01702, val loss: 0.01765\n",
      "Training epoch: 1282, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 1283, train loss: 0.01702, val loss: 0.01765\n",
      "Training epoch: 1284, train loss: 0.01703, val loss: 0.01763\n",
      "Training epoch: 1285, train loss: 0.01707, val loss: 0.01769\n",
      "Training epoch: 1286, train loss: 0.01704, val loss: 0.01768\n",
      "Training epoch: 1287, train loss: 0.01702, val loss: 0.01765\n",
      "Training epoch: 1288, train loss: 0.01704, val loss: 0.01765\n",
      "Training epoch: 1289, train loss: 0.01702, val loss: 0.01762\n",
      "Training epoch: 1290, train loss: 0.01702, val loss: 0.01766\n",
      "Training epoch: 1291, train loss: 0.01704, val loss: 0.01765\n",
      "Training epoch: 1292, train loss: 0.01702, val loss: 0.01765\n",
      "Training epoch: 1293, train loss: 0.01703, val loss: 0.01770\n",
      "Training epoch: 1294, train loss: 0.01704, val loss: 0.01764\n",
      "Training epoch: 1295, train loss: 0.01709, val loss: 0.01773\n",
      "Training epoch: 1296, train loss: 0.01707, val loss: 0.01772\n",
      "Training epoch: 1297, train loss: 0.01704, val loss: 0.01768\n",
      "Training epoch: 1298, train loss: 0.01705, val loss: 0.01765\n",
      "Training epoch: 1299, train loss: 0.01705, val loss: 0.01765\n",
      "Training epoch: 1300, train loss: 0.01703, val loss: 0.01764\n",
      "Training epoch: 1301, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1302, train loss: 0.01703, val loss: 0.01765\n",
      "Training epoch: 1303, train loss: 0.01704, val loss: 0.01768\n",
      "Training epoch: 1304, train loss: 0.01705, val loss: 0.01765\n",
      "Training epoch: 1305, train loss: 0.01705, val loss: 0.01769\n",
      "Training epoch: 1306, train loss: 0.01704, val loss: 0.01764\n",
      "Training epoch: 1307, train loss: 0.01703, val loss: 0.01765\n",
      "Training epoch: 1308, train loss: 0.01705, val loss: 0.01767\n",
      "Training epoch: 1309, train loss: 0.01706, val loss: 0.01767\n",
      "Training epoch: 1310, train loss: 0.01702, val loss: 0.01763\n",
      "Training epoch: 1311, train loss: 0.01702, val loss: 0.01766\n",
      "Training epoch: 1312, train loss: 0.01704, val loss: 0.01764\n",
      "Training epoch: 1313, train loss: 0.01707, val loss: 0.01767\n",
      "Training epoch: 1314, train loss: 0.01703, val loss: 0.01766\n",
      "Training epoch: 1315, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1316, train loss: 0.01704, val loss: 0.01764\n",
      "Training epoch: 1317, train loss: 0.01703, val loss: 0.01766\n",
      "Training epoch: 1318, train loss: 0.01703, val loss: 0.01764\n",
      "Training epoch: 1319, train loss: 0.01709, val loss: 0.01772\n",
      "Training epoch: 1320, train loss: 0.01708, val loss: 0.01769\n",
      "Training epoch: 1321, train loss: 0.01706, val loss: 0.01769\n",
      "Training epoch: 1322, train loss: 0.01706, val loss: 0.01766\n",
      "Training epoch: 1323, train loss: 0.01704, val loss: 0.01769\n",
      "Training epoch: 1324, train loss: 0.01707, val loss: 0.01767\n",
      "Training epoch: 1325, train loss: 0.01702, val loss: 0.01766\n",
      "Training epoch: 1326, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 1327, train loss: 0.01703, val loss: 0.01762\n",
      "Training epoch: 1328, train loss: 0.01703, val loss: 0.01765\n",
      "Training epoch: 1329, train loss: 0.01709, val loss: 0.01774\n",
      "Training epoch: 1330, train loss: 0.01716, val loss: 0.01772\n",
      "Training epoch: 1331, train loss: 0.01706, val loss: 0.01768\n",
      "Training epoch: 1332, train loss: 0.01708, val loss: 0.01769\n",
      "Training epoch: 1333, train loss: 0.01702, val loss: 0.01765\n",
      "Training epoch: 1334, train loss: 0.01702, val loss: 0.01762\n",
      "Training epoch: 1335, train loss: 0.01702, val loss: 0.01765\n",
      "Training epoch: 1336, train loss: 0.01703, val loss: 0.01763\n",
      "Training epoch: 1337, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1338, train loss: 0.01702, val loss: 0.01765\n",
      "Training epoch: 1339, train loss: 0.01704, val loss: 0.01764\n",
      "Training epoch: 1340, train loss: 0.01707, val loss: 0.01765\n",
      "Training epoch: 1341, train loss: 0.01702, val loss: 0.01766\n",
      "Training epoch: 1342, train loss: 0.01701, val loss: 0.01762\n",
      "Training epoch: 1343, train loss: 0.01702, val loss: 0.01767\n",
      "Training epoch: 1344, train loss: 0.01701, val loss: 0.01765\n",
      "Training epoch: 1345, train loss: 0.01703, val loss: 0.01763\n",
      "Training epoch: 1346, train loss: 0.01704, val loss: 0.01764\n",
      "Training epoch: 1347, train loss: 0.01703, val loss: 0.01768\n",
      "Training epoch: 1348, train loss: 0.01702, val loss: 0.01762\n",
      "Training epoch: 1349, train loss: 0.01702, val loss: 0.01765\n",
      "Training epoch: 1350, train loss: 0.01702, val loss: 0.01762\n",
      "Training epoch: 1351, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1352, train loss: 0.01701, val loss: 0.01765\n",
      "Training epoch: 1353, train loss: 0.01706, val loss: 0.01764\n",
      "Training epoch: 1354, train loss: 0.01706, val loss: 0.01769\n",
      "Training epoch: 1355, train loss: 0.01710, val loss: 0.01770\n",
      "Training epoch: 1356, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 1357, train loss: 0.01712, val loss: 0.01775\n",
      "Training epoch: 1358, train loss: 0.01728, val loss: 0.01785\n",
      "Training epoch: 1359, train loss: 0.01711, val loss: 0.01775\n",
      "Training epoch: 1360, train loss: 0.01707, val loss: 0.01766\n",
      "Training epoch: 1361, train loss: 0.01704, val loss: 0.01771\n",
      "Training epoch: 1362, train loss: 0.01703, val loss: 0.01762\n",
      "Training epoch: 1363, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1364, train loss: 0.01702, val loss: 0.01765\n",
      "Training epoch: 1365, train loss: 0.01703, val loss: 0.01762\n",
      "Training epoch: 1366, train loss: 0.01703, val loss: 0.01765\n",
      "Training epoch: 1367, train loss: 0.01701, val loss: 0.01762\n",
      "Training epoch: 1368, train loss: 0.01702, val loss: 0.01763\n",
      "Training epoch: 1369, train loss: 0.01703, val loss: 0.01762\n",
      "Training epoch: 1370, train loss: 0.01702, val loss: 0.01767\n",
      "Training epoch: 1371, train loss: 0.01703, val loss: 0.01763\n",
      "Training epoch: 1372, train loss: 0.01702, val loss: 0.01763\n",
      "Training epoch: 1373, train loss: 0.01703, val loss: 0.01763\n",
      "Training epoch: 1374, train loss: 0.01703, val loss: 0.01767\n",
      "Training epoch: 1375, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1376, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1377, train loss: 0.01702, val loss: 0.01762\n",
      "Training epoch: 1378, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1379, train loss: 0.01705, val loss: 0.01769\n",
      "Training epoch: 1380, train loss: 0.01702, val loss: 0.01762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1381, train loss: 0.01702, val loss: 0.01762\n",
      "Training epoch: 1382, train loss: 0.01701, val loss: 0.01765\n",
      "Training epoch: 1383, train loss: 0.01702, val loss: 0.01763\n",
      "Training epoch: 1384, train loss: 0.01706, val loss: 0.01763\n",
      "Training epoch: 1385, train loss: 0.01702, val loss: 0.01767\n",
      "Training epoch: 1386, train loss: 0.01702, val loss: 0.01763\n",
      "Training epoch: 1387, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1388, train loss: 0.01702, val loss: 0.01762\n",
      "Training epoch: 1389, train loss: 0.01701, val loss: 0.01764\n",
      "Training epoch: 1390, train loss: 0.01704, val loss: 0.01762\n",
      "Training epoch: 1391, train loss: 0.01704, val loss: 0.01770\n",
      "Training epoch: 1392, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 1393, train loss: 0.01702, val loss: 0.01767\n",
      "Training epoch: 1394, train loss: 0.01704, val loss: 0.01765\n",
      "Training epoch: 1395, train loss: 0.01701, val loss: 0.01762\n",
      "Training epoch: 1396, train loss: 0.01706, val loss: 0.01769\n",
      "Training epoch: 1397, train loss: 0.01705, val loss: 0.01769\n",
      "Training epoch: 1398, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 1399, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1400, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 1401, train loss: 0.01702, val loss: 0.01763\n",
      "Training epoch: 1402, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1403, train loss: 0.01704, val loss: 0.01768\n",
      "Training epoch: 1404, train loss: 0.01705, val loss: 0.01771\n",
      "Training epoch: 1405, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1406, train loss: 0.01705, val loss: 0.01763\n",
      "Training epoch: 1407, train loss: 0.01702, val loss: 0.01765\n",
      "Training epoch: 1408, train loss: 0.01706, val loss: 0.01765\n",
      "Training epoch: 1409, train loss: 0.01703, val loss: 0.01766\n",
      "Training epoch: 1410, train loss: 0.01704, val loss: 0.01765\n",
      "Training epoch: 1411, train loss: 0.01703, val loss: 0.01762\n",
      "Training epoch: 1412, train loss: 0.01702, val loss: 0.01767\n",
      "Training epoch: 1413, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1414, train loss: 0.01703, val loss: 0.01764\n",
      "Training epoch: 1415, train loss: 0.01702, val loss: 0.01763\n",
      "Training epoch: 1416, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1417, train loss: 0.01703, val loss: 0.01764\n",
      "Training epoch: 1418, train loss: 0.01701, val loss: 0.01765\n",
      "Training epoch: 1419, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1420, train loss: 0.01703, val loss: 0.01764\n",
      "Training epoch: 1421, train loss: 0.01702, val loss: 0.01762\n",
      "Training epoch: 1422, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 1423, train loss: 0.01703, val loss: 0.01767\n",
      "Training epoch: 1424, train loss: 0.01701, val loss: 0.01764\n",
      "Training epoch: 1425, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1426, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 1427, train loss: 0.01705, val loss: 0.01768\n",
      "Training epoch: 1428, train loss: 0.01703, val loss: 0.01764\n",
      "Training epoch: 1429, train loss: 0.01702, val loss: 0.01765\n",
      "Training epoch: 1430, train loss: 0.01704, val loss: 0.01765\n",
      "Training epoch: 1431, train loss: 0.01701, val loss: 0.01764\n",
      "Training epoch: 1432, train loss: 0.01703, val loss: 0.01766\n",
      "Training epoch: 1433, train loss: 0.01703, val loss: 0.01763\n",
      "Training epoch: 1434, train loss: 0.01701, val loss: 0.01764\n",
      "Training epoch: 1435, train loss: 0.01705, val loss: 0.01761\n",
      "Training epoch: 1436, train loss: 0.01701, val loss: 0.01761\n",
      "Training epoch: 1437, train loss: 0.01703, val loss: 0.01766\n",
      "Training epoch: 1438, train loss: 0.01701, val loss: 0.01767\n",
      "Training epoch: 1439, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 1440, train loss: 0.01702, val loss: 0.01759\n",
      "Training epoch: 1441, train loss: 0.01701, val loss: 0.01761\n",
      "Training epoch: 1442, train loss: 0.01701, val loss: 0.01766\n",
      "Training epoch: 1443, train loss: 0.01707, val loss: 0.01770\n",
      "Training epoch: 1444, train loss: 0.01706, val loss: 0.01771\n",
      "Training epoch: 1445, train loss: 0.01702, val loss: 0.01762\n",
      "Training epoch: 1446, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1447, train loss: 0.01702, val loss: 0.01766\n",
      "Training epoch: 1448, train loss: 0.01703, val loss: 0.01762\n",
      "Training epoch: 1449, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1450, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 1451, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1452, train loss: 0.01701, val loss: 0.01767\n",
      "Training epoch: 1453, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 1454, train loss: 0.01701, val loss: 0.01762\n",
      "Training epoch: 1455, train loss: 0.01703, val loss: 0.01766\n",
      "Training epoch: 1456, train loss: 0.01702, val loss: 0.01763\n",
      "Training epoch: 1457, train loss: 0.01701, val loss: 0.01764\n",
      "Training epoch: 1458, train loss: 0.01701, val loss: 0.01764\n",
      "Training epoch: 1459, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1460, train loss: 0.01705, val loss: 0.01768\n",
      "Training epoch: 1461, train loss: 0.01707, val loss: 0.01771\n",
      "Training epoch: 1462, train loss: 0.01702, val loss: 0.01760\n",
      "Training epoch: 1463, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 1464, train loss: 0.01701, val loss: 0.01764\n",
      "Training epoch: 1465, train loss: 0.01702, val loss: 0.01763\n",
      "Training epoch: 1466, train loss: 0.01709, val loss: 0.01771\n",
      "Training epoch: 1467, train loss: 0.01706, val loss: 0.01765\n",
      "Training epoch: 1468, train loss: 0.01701, val loss: 0.01764\n",
      "Training epoch: 1469, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 1470, train loss: 0.01702, val loss: 0.01762\n",
      "Training epoch: 1471, train loss: 0.01701, val loss: 0.01760\n",
      "Training epoch: 1472, train loss: 0.01703, val loss: 0.01761\n",
      "Training epoch: 1473, train loss: 0.01704, val loss: 0.01769\n",
      "Training epoch: 1474, train loss: 0.01709, val loss: 0.01771\n",
      "Training epoch: 1475, train loss: 0.01706, val loss: 0.01769\n",
      "Training epoch: 1476, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1477, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1478, train loss: 0.01709, val loss: 0.01770\n",
      "Training epoch: 1479, train loss: 0.01707, val loss: 0.01763\n",
      "Training epoch: 1480, train loss: 0.01700, val loss: 0.01764\n",
      "Training epoch: 1481, train loss: 0.01701, val loss: 0.01764\n",
      "Training epoch: 1482, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1483, train loss: 0.01701, val loss: 0.01760\n",
      "Training epoch: 1484, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1485, train loss: 0.01701, val loss: 0.01761\n",
      "Training epoch: 1486, train loss: 0.01702, val loss: 0.01763\n",
      "Training epoch: 1487, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1488, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 1489, train loss: 0.01708, val loss: 0.01768\n",
      "Training epoch: 1490, train loss: 0.01710, val loss: 0.01776\n",
      "Training epoch: 1491, train loss: 0.01709, val loss: 0.01768\n",
      "Training epoch: 1492, train loss: 0.01702, val loss: 0.01766\n",
      "Training epoch: 1493, train loss: 0.01701, val loss: 0.01759\n",
      "Training epoch: 1494, train loss: 0.01706, val loss: 0.01760\n",
      "Training epoch: 1495, train loss: 0.01704, val loss: 0.01769\n",
      "Training epoch: 1496, train loss: 0.01702, val loss: 0.01766\n",
      "Training epoch: 1497, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1498, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1499, train loss: 0.01700, val loss: 0.01764\n",
      "Training epoch: 1500, train loss: 0.01702, val loss: 0.01766\n",
      "Training epoch: 1501, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1502, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 1503, train loss: 0.01702, val loss: 0.01759\n",
      "Training epoch: 1504, train loss: 0.01706, val loss: 0.01772\n",
      "Training epoch: 1505, train loss: 0.01707, val loss: 0.01769\n",
      "Training epoch: 1506, train loss: 0.01703, val loss: 0.01763\n",
      "Training epoch: 1507, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 1508, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 1509, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 1510, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1511, train loss: 0.01701, val loss: 0.01764\n",
      "Training epoch: 1512, train loss: 0.01702, val loss: 0.01762\n",
      "Training epoch: 1513, train loss: 0.01702, val loss: 0.01767\n",
      "Training epoch: 1514, train loss: 0.01703, val loss: 0.01764\n",
      "Training epoch: 1515, train loss: 0.01703, val loss: 0.01764\n",
      "Training epoch: 1516, train loss: 0.01702, val loss: 0.01764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1517, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1518, train loss: 0.01701, val loss: 0.01762\n",
      "Training epoch: 1519, train loss: 0.01703, val loss: 0.01763\n",
      "Training epoch: 1520, train loss: 0.01701, val loss: 0.01766\n",
      "Training epoch: 1521, train loss: 0.01704, val loss: 0.01765\n",
      "Training epoch: 1522, train loss: 0.01703, val loss: 0.01768\n",
      "Training epoch: 1523, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 1524, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1525, train loss: 0.01706, val loss: 0.01770\n",
      "Training epoch: 1526, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 1527, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 1528, train loss: 0.01701, val loss: 0.01766\n",
      "Training epoch: 1529, train loss: 0.01709, val loss: 0.01765\n",
      "Training epoch: 1530, train loss: 0.01713, val loss: 0.01775\n",
      "Training epoch: 1531, train loss: 0.01710, val loss: 0.01773\n",
      "Training epoch: 1532, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1533, train loss: 0.01703, val loss: 0.01766\n",
      "Training epoch: 1534, train loss: 0.01706, val loss: 0.01767\n",
      "Training epoch: 1535, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1536, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1537, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 1538, train loss: 0.01709, val loss: 0.01764\n",
      "Training epoch: 1539, train loss: 0.01707, val loss: 0.01773\n",
      "Training epoch: 1540, train loss: 0.01707, val loss: 0.01771\n",
      "Training epoch: 1541, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 1542, train loss: 0.01704, val loss: 0.01770\n",
      "Training epoch: 1543, train loss: 0.01703, val loss: 0.01763\n",
      "Training epoch: 1544, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 1545, train loss: 0.01700, val loss: 0.01764\n",
      "Training epoch: 1546, train loss: 0.01703, val loss: 0.01763\n",
      "Training epoch: 1547, train loss: 0.01701, val loss: 0.01765\n",
      "Training epoch: 1548, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 1549, train loss: 0.01704, val loss: 0.01764\n",
      "Training epoch: 1550, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1551, train loss: 0.01700, val loss: 0.01765\n",
      "Training epoch: 1552, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1553, train loss: 0.01701, val loss: 0.01761\n",
      "Training epoch: 1554, train loss: 0.01701, val loss: 0.01765\n",
      "Training epoch: 1555, train loss: 0.01706, val loss: 0.01768\n",
      "Training epoch: 1556, train loss: 0.01707, val loss: 0.01765\n",
      "Training epoch: 1557, train loss: 0.01703, val loss: 0.01766\n",
      "Training epoch: 1558, train loss: 0.01701, val loss: 0.01761\n",
      "Training epoch: 1559, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 1560, train loss: 0.01707, val loss: 0.01770\n",
      "Training epoch: 1561, train loss: 0.01707, val loss: 0.01766\n",
      "Training epoch: 1562, train loss: 0.01703, val loss: 0.01768\n",
      "Training epoch: 1563, train loss: 0.01703, val loss: 0.01766\n",
      "Training epoch: 1564, train loss: 0.01701, val loss: 0.01762\n",
      "Training epoch: 1565, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1566, train loss: 0.01701, val loss: 0.01764\n",
      "Training epoch: 1567, train loss: 0.01702, val loss: 0.01767\n",
      "Training epoch: 1568, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1569, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1570, train loss: 0.01705, val loss: 0.01769\n",
      "Training epoch: 1571, train loss: 0.01706, val loss: 0.01764\n",
      "Training epoch: 1572, train loss: 0.01701, val loss: 0.01766\n",
      "Training epoch: 1573, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 1574, train loss: 0.01708, val loss: 0.01763\n",
      "Training epoch: 1575, train loss: 0.01705, val loss: 0.01767\n",
      "Training epoch: 1576, train loss: 0.01710, val loss: 0.01772\n",
      "Training epoch: 1577, train loss: 0.01705, val loss: 0.01767\n",
      "Training epoch: 1578, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1579, train loss: 0.01702, val loss: 0.01769\n",
      "Training epoch: 1580, train loss: 0.01700, val loss: 0.01764\n",
      "Training epoch: 1581, train loss: 0.01701, val loss: 0.01764\n",
      "Training epoch: 1582, train loss: 0.01703, val loss: 0.01764\n",
      "Training epoch: 1583, train loss: 0.01701, val loss: 0.01764\n",
      "Training epoch: 1584, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1585, train loss: 0.01704, val loss: 0.01762\n",
      "Training epoch: 1586, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1587, train loss: 0.01708, val loss: 0.01769\n",
      "Training epoch: 1588, train loss: 0.01710, val loss: 0.01774\n",
      "Training epoch: 1589, train loss: 0.01703, val loss: 0.01763\n",
      "Training epoch: 1590, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1591, train loss: 0.01702, val loss: 0.01766\n",
      "Training epoch: 1592, train loss: 0.01701, val loss: 0.01762\n",
      "Training epoch: 1593, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 1594, train loss: 0.01702, val loss: 0.01762\n",
      "Training epoch: 1595, train loss: 0.01708, val loss: 0.01767\n",
      "Training epoch: 1596, train loss: 0.01701, val loss: 0.01766\n",
      "Training epoch: 1597, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1598, train loss: 0.01709, val loss: 0.01769\n",
      "Training epoch: 1599, train loss: 0.01702, val loss: 0.01765\n",
      "Training epoch: 1600, train loss: 0.01708, val loss: 0.01767\n",
      "Training epoch: 1601, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 1602, train loss: 0.01706, val loss: 0.01765\n",
      "Training epoch: 1603, train loss: 0.01700, val loss: 0.01764\n",
      "Training epoch: 1604, train loss: 0.01700, val loss: 0.01765\n",
      "Training epoch: 1605, train loss: 0.01701, val loss: 0.01760\n",
      "Training epoch: 1606, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 1607, train loss: 0.01707, val loss: 0.01769\n",
      "Training epoch: 1608, train loss: 0.01700, val loss: 0.01765\n",
      "Training epoch: 1609, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1610, train loss: 0.01704, val loss: 0.01763\n",
      "Training epoch: 1611, train loss: 0.01700, val loss: 0.01759\n",
      "Training epoch: 1612, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 1613, train loss: 0.01701, val loss: 0.01765\n",
      "Training epoch: 1614, train loss: 0.01701, val loss: 0.01761\n",
      "Training epoch: 1615, train loss: 0.01701, val loss: 0.01761\n",
      "Training epoch: 1616, train loss: 0.01699, val loss: 0.01764\n",
      "Training epoch: 1617, train loss: 0.01702, val loss: 0.01762\n",
      "Training epoch: 1618, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1619, train loss: 0.01702, val loss: 0.01765\n",
      "Training epoch: 1620, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1621, train loss: 0.01699, val loss: 0.01763\n",
      "Training epoch: 1622, train loss: 0.01706, val loss: 0.01768\n",
      "Training epoch: 1623, train loss: 0.01711, val loss: 0.01768\n",
      "Training epoch: 1624, train loss: 0.01702, val loss: 0.01769\n",
      "Training epoch: 1625, train loss: 0.01701, val loss: 0.01761\n",
      "Training epoch: 1626, train loss: 0.01700, val loss: 0.01759\n",
      "Training epoch: 1627, train loss: 0.01701, val loss: 0.01767\n",
      "Training epoch: 1628, train loss: 0.01701, val loss: 0.01762\n",
      "Training epoch: 1629, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 1630, train loss: 0.01701, val loss: 0.01766\n",
      "Training epoch: 1631, train loss: 0.01701, val loss: 0.01761\n",
      "Training epoch: 1632, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 1633, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1634, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 1635, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1636, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1637, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 1638, train loss: 0.01702, val loss: 0.01761\n",
      "Training epoch: 1639, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1640, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 1641, train loss: 0.01702, val loss: 0.01763\n",
      "Training epoch: 1642, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1643, train loss: 0.01701, val loss: 0.01762\n",
      "Training epoch: 1644, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1645, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1646, train loss: 0.01706, val loss: 0.01767\n",
      "Training epoch: 1647, train loss: 0.01701, val loss: 0.01762\n",
      "Training epoch: 1648, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1649, train loss: 0.01703, val loss: 0.01764\n",
      "Training epoch: 1650, train loss: 0.01702, val loss: 0.01762\n",
      "Training epoch: 1651, train loss: 0.01700, val loss: 0.01758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1652, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1653, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1654, train loss: 0.01708, val loss: 0.01768\n",
      "Training epoch: 1655, train loss: 0.01703, val loss: 0.01766\n",
      "Training epoch: 1656, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1657, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 1658, train loss: 0.01700, val loss: 0.01766\n",
      "Training epoch: 1659, train loss: 0.01700, val loss: 0.01758\n",
      "Training epoch: 1660, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1661, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1662, train loss: 0.01711, val loss: 0.01776\n",
      "Training epoch: 1663, train loss: 0.01720, val loss: 0.01779\n",
      "Training epoch: 1664, train loss: 0.01708, val loss: 0.01773\n",
      "Training epoch: 1665, train loss: 0.01708, val loss: 0.01765\n",
      "Training epoch: 1666, train loss: 0.01706, val loss: 0.01769\n",
      "Training epoch: 1667, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1668, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 1669, train loss: 0.01700, val loss: 0.01759\n",
      "Training epoch: 1670, train loss: 0.01699, val loss: 0.01763\n",
      "Training epoch: 1671, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1672, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1673, train loss: 0.01702, val loss: 0.01767\n",
      "Training epoch: 1674, train loss: 0.01702, val loss: 0.01760\n",
      "Training epoch: 1675, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1676, train loss: 0.01701, val loss: 0.01762\n",
      "Training epoch: 1677, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1678, train loss: 0.01701, val loss: 0.01762\n",
      "Training epoch: 1679, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1680, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 1681, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1682, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1683, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 1684, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1685, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1686, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1687, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1688, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 1689, train loss: 0.01700, val loss: 0.01759\n",
      "Training epoch: 1690, train loss: 0.01701, val loss: 0.01765\n",
      "Training epoch: 1691, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 1692, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1693, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 1694, train loss: 0.01701, val loss: 0.01760\n",
      "Training epoch: 1695, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 1696, train loss: 0.01700, val loss: 0.01757\n",
      "Training epoch: 1697, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1698, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 1699, train loss: 0.01703, val loss: 0.01760\n",
      "Training epoch: 1700, train loss: 0.01701, val loss: 0.01761\n",
      "Training epoch: 1701, train loss: 0.01701, val loss: 0.01765\n",
      "Training epoch: 1702, train loss: 0.01705, val loss: 0.01764\n",
      "Training epoch: 1703, train loss: 0.01703, val loss: 0.01766\n",
      "Training epoch: 1704, train loss: 0.01703, val loss: 0.01763\n",
      "Training epoch: 1705, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1706, train loss: 0.01699, val loss: 0.01758\n",
      "Training epoch: 1707, train loss: 0.01703, val loss: 0.01764\n",
      "Training epoch: 1708, train loss: 0.01699, val loss: 0.01765\n",
      "Training epoch: 1709, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1710, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 1711, train loss: 0.01703, val loss: 0.01763\n",
      "Training epoch: 1712, train loss: 0.01702, val loss: 0.01761\n",
      "Training epoch: 1713, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1714, train loss: 0.01699, val loss: 0.01764\n",
      "Training epoch: 1715, train loss: 0.01699, val loss: 0.01758\n",
      "Training epoch: 1716, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1717, train loss: 0.01702, val loss: 0.01759\n",
      "Training epoch: 1718, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 1719, train loss: 0.01700, val loss: 0.01764\n",
      "Training epoch: 1720, train loss: 0.01700, val loss: 0.01758\n",
      "Training epoch: 1721, train loss: 0.01699, val loss: 0.01758\n",
      "Training epoch: 1722, train loss: 0.01701, val loss: 0.01762\n",
      "Training epoch: 1723, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 1724, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1725, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1726, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1727, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 1728, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 1729, train loss: 0.01703, val loss: 0.01759\n",
      "Training epoch: 1730, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1731, train loss: 0.01707, val loss: 0.01766\n",
      "Training epoch: 1732, train loss: 0.01702, val loss: 0.01762\n",
      "Training epoch: 1733, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1734, train loss: 0.01702, val loss: 0.01766\n",
      "Training epoch: 1735, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 1736, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1737, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 1738, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 1739, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1740, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 1741, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1742, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1743, train loss: 0.01700, val loss: 0.01757\n",
      "Training epoch: 1744, train loss: 0.01699, val loss: 0.01765\n",
      "Training epoch: 1745, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 1746, train loss: 0.01699, val loss: 0.01758\n",
      "Training epoch: 1747, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1748, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 1749, train loss: 0.01699, val loss: 0.01763\n",
      "Training epoch: 1750, train loss: 0.01701, val loss: 0.01759\n",
      "Training epoch: 1751, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1752, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 1753, train loss: 0.01698, val loss: 0.01762\n",
      "Training epoch: 1754, train loss: 0.01701, val loss: 0.01760\n",
      "Training epoch: 1755, train loss: 0.01699, val loss: 0.01763\n",
      "Training epoch: 1756, train loss: 0.01709, val loss: 0.01768\n",
      "Training epoch: 1757, train loss: 0.01703, val loss: 0.01767\n",
      "Training epoch: 1758, train loss: 0.01700, val loss: 0.01757\n",
      "Training epoch: 1759, train loss: 0.01705, val loss: 0.01763\n",
      "Training epoch: 1760, train loss: 0.01713, val loss: 0.01779\n",
      "Training epoch: 1761, train loss: 0.01714, val loss: 0.01771\n",
      "Training epoch: 1762, train loss: 0.01704, val loss: 0.01768\n",
      "Training epoch: 1763, train loss: 0.01702, val loss: 0.01761\n",
      "Training epoch: 1764, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1765, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1766, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 1767, train loss: 0.01700, val loss: 0.01759\n",
      "Training epoch: 1768, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1769, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1770, train loss: 0.01705, val loss: 0.01767\n",
      "Training epoch: 1771, train loss: 0.01708, val loss: 0.01769\n",
      "Training epoch: 1772, train loss: 0.01709, val loss: 0.01772\n",
      "Training epoch: 1773, train loss: 0.01700, val loss: 0.01759\n",
      "Training epoch: 1774, train loss: 0.01700, val loss: 0.01765\n",
      "Training epoch: 1775, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1776, train loss: 0.01701, val loss: 0.01761\n",
      "Training epoch: 1777, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1778, train loss: 0.01700, val loss: 0.01765\n",
      "Training epoch: 1779, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1780, train loss: 0.01704, val loss: 0.01763\n",
      "Training epoch: 1781, train loss: 0.01708, val loss: 0.01770\n",
      "Training epoch: 1782, train loss: 0.01702, val loss: 0.01763\n",
      "Training epoch: 1783, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1784, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1785, train loss: 0.01703, val loss: 0.01766\n",
      "Training epoch: 1786, train loss: 0.01704, val loss: 0.01764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1787, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1788, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1789, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 1790, train loss: 0.01699, val loss: 0.01764\n",
      "Training epoch: 1791, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1792, train loss: 0.01703, val loss: 0.01760\n",
      "Training epoch: 1793, train loss: 0.01702, val loss: 0.01763\n",
      "Training epoch: 1794, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1795, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 1796, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 1797, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 1798, train loss: 0.01699, val loss: 0.01758\n",
      "Training epoch: 1799, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 1800, train loss: 0.01706, val loss: 0.01766\n",
      "Training epoch: 1801, train loss: 0.01704, val loss: 0.01768\n",
      "Training epoch: 1802, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1803, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 1804, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 1805, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1806, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1807, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 1808, train loss: 0.01699, val loss: 0.01764\n",
      "Training epoch: 1809, train loss: 0.01701, val loss: 0.01757\n",
      "Training epoch: 1810, train loss: 0.01704, val loss: 0.01766\n",
      "Training epoch: 1811, train loss: 0.01706, val loss: 0.01769\n",
      "Training epoch: 1812, train loss: 0.01702, val loss: 0.01763\n",
      "Training epoch: 1813, train loss: 0.01700, val loss: 0.01756\n",
      "Training epoch: 1814, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1815, train loss: 0.01699, val loss: 0.01765\n",
      "Training epoch: 1816, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1817, train loss: 0.01705, val loss: 0.01765\n",
      "Training epoch: 1818, train loss: 0.01704, val loss: 0.01764\n",
      "Training epoch: 1819, train loss: 0.01702, val loss: 0.01768\n",
      "Training epoch: 1820, train loss: 0.01700, val loss: 0.01759\n",
      "Training epoch: 1821, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1822, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 1823, train loss: 0.01700, val loss: 0.01759\n",
      "Training epoch: 1824, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 1825, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 1826, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1827, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 1828, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 1829, train loss: 0.01708, val loss: 0.01766\n",
      "Training epoch: 1830, train loss: 0.01706, val loss: 0.01769\n",
      "Training epoch: 1831, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1832, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1833, train loss: 0.01700, val loss: 0.01764\n",
      "Training epoch: 1834, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 1835, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1836, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 1837, train loss: 0.01700, val loss: 0.01764\n",
      "Training epoch: 1838, train loss: 0.01699, val loss: 0.01756\n",
      "Training epoch: 1839, train loss: 0.01701, val loss: 0.01762\n",
      "Training epoch: 1840, train loss: 0.01701, val loss: 0.01765\n",
      "Training epoch: 1841, train loss: 0.01705, val loss: 0.01759\n",
      "Training epoch: 1842, train loss: 0.01700, val loss: 0.01764\n",
      "Training epoch: 1843, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1844, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 1845, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 1846, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 1847, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1848, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1849, train loss: 0.01703, val loss: 0.01767\n",
      "Training epoch: 1850, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1851, train loss: 0.01699, val loss: 0.01765\n",
      "Training epoch: 1852, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 1853, train loss: 0.01703, val loss: 0.01758\n",
      "Training epoch: 1854, train loss: 0.01705, val loss: 0.01769\n",
      "Training epoch: 1855, train loss: 0.01702, val loss: 0.01763\n",
      "Training epoch: 1856, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1857, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1858, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1859, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 1860, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 1861, train loss: 0.01704, val loss: 0.01762\n",
      "Training epoch: 1862, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 1863, train loss: 0.01699, val loss: 0.01763\n",
      "Training epoch: 1864, train loss: 0.01699, val loss: 0.01758\n",
      "Training epoch: 1865, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 1866, train loss: 0.01699, val loss: 0.01757\n",
      "Training epoch: 1867, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 1868, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1869, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 1870, train loss: 0.01702, val loss: 0.01765\n",
      "Training epoch: 1871, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1872, train loss: 0.01699, val loss: 0.01758\n",
      "Training epoch: 1873, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 1874, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 1875, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1876, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1877, train loss: 0.01710, val loss: 0.01768\n",
      "Training epoch: 1878, train loss: 0.01719, val loss: 0.01783\n",
      "Training epoch: 1879, train loss: 0.01711, val loss: 0.01766\n",
      "Training epoch: 1880, train loss: 0.01701, val loss: 0.01765\n",
      "Training epoch: 1881, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1882, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 1883, train loss: 0.01702, val loss: 0.01761\n",
      "Training epoch: 1884, train loss: 0.01699, val loss: 0.01763\n",
      "Training epoch: 1885, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1886, train loss: 0.01699, val loss: 0.01757\n",
      "Training epoch: 1887, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1888, train loss: 0.01707, val loss: 0.01769\n",
      "Training epoch: 1889, train loss: 0.01701, val loss: 0.01760\n",
      "Training epoch: 1890, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 1891, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 1892, train loss: 0.01698, val loss: 0.01756\n",
      "Training epoch: 1893, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 1894, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 1895, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 1896, train loss: 0.01698, val loss: 0.01762\n",
      "Training epoch: 1897, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1898, train loss: 0.01700, val loss: 0.01756\n",
      "Training epoch: 1899, train loss: 0.01698, val loss: 0.01762\n",
      "Training epoch: 1900, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 1901, train loss: 0.01703, val loss: 0.01759\n",
      "Training epoch: 1902, train loss: 0.01699, val loss: 0.01763\n",
      "Training epoch: 1903, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 1904, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1905, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1906, train loss: 0.01700, val loss: 0.01757\n",
      "Training epoch: 1907, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 1908, train loss: 0.01702, val loss: 0.01765\n",
      "Training epoch: 1909, train loss: 0.01703, val loss: 0.01765\n",
      "Training epoch: 1910, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1911, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1912, train loss: 0.01699, val loss: 0.01763\n",
      "Training epoch: 1913, train loss: 0.01699, val loss: 0.01758\n",
      "Training epoch: 1914, train loss: 0.01700, val loss: 0.01765\n",
      "Training epoch: 1915, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1916, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1917, train loss: 0.01699, val loss: 0.01758\n",
      "Training epoch: 1918, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 1919, train loss: 0.01698, val loss: 0.01764\n",
      "Training epoch: 1920, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 1921, train loss: 0.01698, val loss: 0.01758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1922, train loss: 0.01703, val loss: 0.01766\n",
      "Training epoch: 1923, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 1924, train loss: 0.01700, val loss: 0.01757\n",
      "Training epoch: 1925, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 1926, train loss: 0.01700, val loss: 0.01764\n",
      "Training epoch: 1927, train loss: 0.01701, val loss: 0.01760\n",
      "Training epoch: 1928, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1929, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 1930, train loss: 0.01700, val loss: 0.01758\n",
      "Training epoch: 1931, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 1932, train loss: 0.01701, val loss: 0.01762\n",
      "Training epoch: 1933, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 1934, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1935, train loss: 0.01701, val loss: 0.01759\n",
      "Training epoch: 1936, train loss: 0.01700, val loss: 0.01764\n",
      "Training epoch: 1937, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 1938, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 1939, train loss: 0.01698, val loss: 0.01762\n",
      "Training epoch: 1940, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 1941, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 1942, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1943, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 1944, train loss: 0.01698, val loss: 0.01756\n",
      "Training epoch: 1945, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 1946, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 1947, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1948, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 1949, train loss: 0.01698, val loss: 0.01762\n",
      "Training epoch: 1950, train loss: 0.01700, val loss: 0.01758\n",
      "Training epoch: 1951, train loss: 0.01699, val loss: 0.01763\n",
      "Training epoch: 1952, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 1953, train loss: 0.01699, val loss: 0.01756\n",
      "Training epoch: 1954, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1955, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 1956, train loss: 0.01703, val loss: 0.01761\n",
      "Training epoch: 1957, train loss: 0.01703, val loss: 0.01758\n",
      "Training epoch: 1958, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1959, train loss: 0.01699, val loss: 0.01763\n",
      "Training epoch: 1960, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 1961, train loss: 0.01699, val loss: 0.01757\n",
      "Training epoch: 1962, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1963, train loss: 0.01706, val loss: 0.01771\n",
      "Training epoch: 1964, train loss: 0.01703, val loss: 0.01765\n",
      "Training epoch: 1965, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1966, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1967, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1968, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 1969, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 1970, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 1971, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 1972, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 1973, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 1974, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 1975, train loss: 0.01701, val loss: 0.01764\n",
      "Training epoch: 1976, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 1977, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 1978, train loss: 0.01700, val loss: 0.01759\n",
      "Training epoch: 1979, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 1980, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 1981, train loss: 0.01698, val loss: 0.01762\n",
      "Training epoch: 1982, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 1983, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 1984, train loss: 0.01699, val loss: 0.01758\n",
      "Training epoch: 1985, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 1986, train loss: 0.01698, val loss: 0.01762\n",
      "Training epoch: 1987, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 1988, train loss: 0.01699, val loss: 0.01758\n",
      "Training epoch: 1989, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 1990, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 1991, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 1992, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1993, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 1994, train loss: 0.01702, val loss: 0.01761\n",
      "Training epoch: 1995, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 1996, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 1997, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 1998, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 1999, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 2000, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2001, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2002, train loss: 0.01701, val loss: 0.01759\n",
      "Training epoch: 2003, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 2004, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 2005, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2006, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2007, train loss: 0.01699, val loss: 0.01758\n",
      "Training epoch: 2008, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 2009, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2010, train loss: 0.01703, val loss: 0.01760\n",
      "Training epoch: 2011, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2012, train loss: 0.01701, val loss: 0.01759\n",
      "Training epoch: 2013, train loss: 0.01706, val loss: 0.01770\n",
      "Training epoch: 2014, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 2015, train loss: 0.01699, val loss: 0.01758\n",
      "Training epoch: 2016, train loss: 0.01701, val loss: 0.01759\n",
      "Training epoch: 2017, train loss: 0.01700, val loss: 0.01764\n",
      "Training epoch: 2018, train loss: 0.01702, val loss: 0.01762\n",
      "Training epoch: 2019, train loss: 0.01700, val loss: 0.01756\n",
      "Training epoch: 2020, train loss: 0.01698, val loss: 0.01762\n",
      "Training epoch: 2021, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 2022, train loss: 0.01701, val loss: 0.01760\n",
      "Training epoch: 2023, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2024, train loss: 0.01701, val loss: 0.01766\n",
      "Training epoch: 2025, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 2026, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2027, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2028, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 2029, train loss: 0.01706, val loss: 0.01768\n",
      "Training epoch: 2030, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 2031, train loss: 0.01698, val loss: 0.01754\n",
      "Training epoch: 2032, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 2033, train loss: 0.01700, val loss: 0.01758\n",
      "Training epoch: 2034, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 2035, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 2036, train loss: 0.01700, val loss: 0.01759\n",
      "Training epoch: 2037, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 2038, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 2039, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2040, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2041, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2042, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 2043, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2044, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 2045, train loss: 0.01699, val loss: 0.01758\n",
      "Training epoch: 2046, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 2047, train loss: 0.01709, val loss: 0.01765\n",
      "Training epoch: 2048, train loss: 0.01709, val loss: 0.01773\n",
      "Training epoch: 2049, train loss: 0.01702, val loss: 0.01761\n",
      "Training epoch: 2050, train loss: 0.01707, val loss: 0.01768\n",
      "Training epoch: 2051, train loss: 0.01704, val loss: 0.01764\n",
      "Training epoch: 2052, train loss: 0.01698, val loss: 0.01763\n",
      "Training epoch: 2053, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2054, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2055, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2056, train loss: 0.01697, val loss: 0.01758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 2057, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 2058, train loss: 0.01698, val loss: 0.01764\n",
      "Training epoch: 2059, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2060, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 2061, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 2062, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2063, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2064, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2065, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2066, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2067, train loss: 0.01698, val loss: 0.01762\n",
      "Training epoch: 2068, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2069, train loss: 0.01700, val loss: 0.01755\n",
      "Training epoch: 2070, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 2071, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2072, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2073, train loss: 0.01700, val loss: 0.01758\n",
      "Training epoch: 2074, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 2075, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2076, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 2077, train loss: 0.01701, val loss: 0.01760\n",
      "Training epoch: 2078, train loss: 0.01702, val loss: 0.01761\n",
      "Training epoch: 2079, train loss: 0.01702, val loss: 0.01765\n",
      "Training epoch: 2080, train loss: 0.01702, val loss: 0.01762\n",
      "Training epoch: 2081, train loss: 0.01704, val loss: 0.01763\n",
      "Training epoch: 2082, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 2083, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 2084, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2085, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2086, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 2087, train loss: 0.01700, val loss: 0.01757\n",
      "Training epoch: 2088, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 2089, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2090, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2091, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2092, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2093, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 2094, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 2095, train loss: 0.01701, val loss: 0.01758\n",
      "Training epoch: 2096, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2097, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2098, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2099, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2100, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2101, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2102, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2103, train loss: 0.01699, val loss: 0.01756\n",
      "Training epoch: 2104, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2105, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2106, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 2107, train loss: 0.01705, val loss: 0.01764\n",
      "Training epoch: 2108, train loss: 0.01709, val loss: 0.01770\n",
      "Training epoch: 2109, train loss: 0.01710, val loss: 0.01772\n",
      "Training epoch: 2110, train loss: 0.01706, val loss: 0.01760\n",
      "Training epoch: 2111, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2112, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2113, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2114, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2115, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 2116, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2117, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2118, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2119, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2120, train loss: 0.01700, val loss: 0.01759\n",
      "Training epoch: 2121, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2122, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 2123, train loss: 0.01699, val loss: 0.01763\n",
      "Training epoch: 2124, train loss: 0.01701, val loss: 0.01762\n",
      "Training epoch: 2125, train loss: 0.01700, val loss: 0.01758\n",
      "Training epoch: 2126, train loss: 0.01699, val loss: 0.01757\n",
      "Training epoch: 2127, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2128, train loss: 0.01703, val loss: 0.01762\n",
      "Training epoch: 2129, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 2130, train loss: 0.01702, val loss: 0.01760\n",
      "Training epoch: 2131, train loss: 0.01697, val loss: 0.01761\n",
      "Training epoch: 2132, train loss: 0.01698, val loss: 0.01755\n",
      "Training epoch: 2133, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2134, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2135, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2136, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2137, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2138, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 2139, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2140, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2141, train loss: 0.01701, val loss: 0.01759\n",
      "Training epoch: 2142, train loss: 0.01709, val loss: 0.01766\n",
      "Training epoch: 2143, train loss: 0.01702, val loss: 0.01766\n",
      "Training epoch: 2144, train loss: 0.01703, val loss: 0.01762\n",
      "Training epoch: 2145, train loss: 0.01704, val loss: 0.01767\n",
      "Training epoch: 2146, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 2147, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2148, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2149, train loss: 0.01700, val loss: 0.01759\n",
      "Training epoch: 2150, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2151, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2152, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2153, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2154, train loss: 0.01701, val loss: 0.01759\n",
      "Training epoch: 2155, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2156, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2157, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2158, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2159, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2160, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2161, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2162, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2163, train loss: 0.01704, val loss: 0.01761\n",
      "Training epoch: 2164, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2165, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2166, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2167, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2168, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2169, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2170, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2171, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2172, train loss: 0.01702, val loss: 0.01762\n",
      "Training epoch: 2173, train loss: 0.01705, val loss: 0.01760\n",
      "Training epoch: 2174, train loss: 0.01700, val loss: 0.01765\n",
      "Training epoch: 2175, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2176, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2177, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2178, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2179, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2180, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2181, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2182, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2183, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2184, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2185, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2186, train loss: 0.01700, val loss: 0.01758\n",
      "Training epoch: 2187, train loss: 0.01699, val loss: 0.01764\n",
      "Training epoch: 2188, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2189, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2190, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 2191, train loss: 0.01702, val loss: 0.01761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 2192, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 2193, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2194, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2195, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2196, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2197, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2198, train loss: 0.01699, val loss: 0.01756\n",
      "Training epoch: 2199, train loss: 0.01699, val loss: 0.01764\n",
      "Training epoch: 2200, train loss: 0.01697, val loss: 0.01755\n",
      "Training epoch: 2201, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2202, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 2203, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2204, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2205, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2206, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2207, train loss: 0.01699, val loss: 0.01757\n",
      "Training epoch: 2208, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2209, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2210, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 2211, train loss: 0.01700, val loss: 0.01759\n",
      "Training epoch: 2212, train loss: 0.01699, val loss: 0.01758\n",
      "Training epoch: 2213, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 2214, train loss: 0.01697, val loss: 0.01754\n",
      "Training epoch: 2215, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2216, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2217, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2218, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2219, train loss: 0.01698, val loss: 0.01755\n",
      "Training epoch: 2220, train loss: 0.01696, val loss: 0.01755\n",
      "Training epoch: 2221, train loss: 0.01701, val loss: 0.01764\n",
      "Training epoch: 2222, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2223, train loss: 0.01701, val loss: 0.01759\n",
      "Training epoch: 2224, train loss: 0.01697, val loss: 0.01754\n",
      "Training epoch: 2225, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2226, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2227, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2228, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2229, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2230, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 2231, train loss: 0.01705, val loss: 0.01760\n",
      "Training epoch: 2232, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 2233, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2234, train loss: 0.01701, val loss: 0.01761\n",
      "Training epoch: 2235, train loss: 0.01700, val loss: 0.01758\n",
      "Training epoch: 2236, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 2237, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2238, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2239, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2240, train loss: 0.01699, val loss: 0.01763\n",
      "Training epoch: 2241, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2242, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2243, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2244, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 2245, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2246, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2247, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2248, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 2249, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2250, train loss: 0.01698, val loss: 0.01762\n",
      "Training epoch: 2251, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2252, train loss: 0.01701, val loss: 0.01757\n",
      "Training epoch: 2253, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2254, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2255, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2256, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2257, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2258, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2259, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2260, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2261, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2262, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2263, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2264, train loss: 0.01697, val loss: 0.01753\n",
      "Training epoch: 2265, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2266, train loss: 0.01697, val loss: 0.01762\n",
      "Training epoch: 2267, train loss: 0.01697, val loss: 0.01755\n",
      "Training epoch: 2268, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2269, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2270, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2271, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2272, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2273, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2274, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2275, train loss: 0.01701, val loss: 0.01761\n",
      "Training epoch: 2276, train loss: 0.01697, val loss: 0.01761\n",
      "Training epoch: 2277, train loss: 0.01700, val loss: 0.01758\n",
      "Training epoch: 2278, train loss: 0.01704, val loss: 0.01768\n",
      "Training epoch: 2279, train loss: 0.01709, val loss: 0.01768\n",
      "Training epoch: 2280, train loss: 0.01702, val loss: 0.01765\n",
      "Training epoch: 2281, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2282, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2283, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2284, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 2285, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2286, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2287, train loss: 0.01696, val loss: 0.01755\n",
      "Training epoch: 2288, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 2289, train loss: 0.01699, val loss: 0.01757\n",
      "Training epoch: 2290, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2291, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2292, train loss: 0.01699, val loss: 0.01754\n",
      "Training epoch: 2293, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2294, train loss: 0.01702, val loss: 0.01767\n",
      "Training epoch: 2295, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 2296, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2297, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2298, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2299, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2300, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2301, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2302, train loss: 0.01701, val loss: 0.01761\n",
      "Training epoch: 2303, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2304, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2305, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2306, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2307, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2308, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2309, train loss: 0.01701, val loss: 0.01761\n",
      "Training epoch: 2310, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2311, train loss: 0.01698, val loss: 0.01762\n",
      "Training epoch: 2312, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2313, train loss: 0.01697, val loss: 0.01755\n",
      "Training epoch: 2314, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2315, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2316, train loss: 0.01696, val loss: 0.01760\n",
      "Training epoch: 2317, train loss: 0.01697, val loss: 0.01755\n",
      "Training epoch: 2318, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2319, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2320, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2321, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2322, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2323, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2324, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2325, train loss: 0.01699, val loss: 0.01763\n",
      "Training epoch: 2326, train loss: 0.01696, val loss: 0.01756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 2327, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2328, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2329, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 2330, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 2331, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2332, train loss: 0.01701, val loss: 0.01757\n",
      "Training epoch: 2333, train loss: 0.01701, val loss: 0.01768\n",
      "Training epoch: 2334, train loss: 0.01703, val loss: 0.01763\n",
      "Training epoch: 2335, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2336, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2337, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2338, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2339, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2340, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2341, train loss: 0.01699, val loss: 0.01758\n",
      "Training epoch: 2342, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2343, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2344, train loss: 0.01697, val loss: 0.01761\n",
      "Training epoch: 2345, train loss: 0.01698, val loss: 0.01756\n",
      "Training epoch: 2346, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2347, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2348, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2349, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2350, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2351, train loss: 0.01698, val loss: 0.01756\n",
      "Training epoch: 2352, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2353, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2354, train loss: 0.01701, val loss: 0.01759\n",
      "Training epoch: 2355, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 2356, train loss: 0.01703, val loss: 0.01764\n",
      "Training epoch: 2357, train loss: 0.01701, val loss: 0.01766\n",
      "Training epoch: 2358, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2359, train loss: 0.01700, val loss: 0.01758\n",
      "Training epoch: 2360, train loss: 0.01699, val loss: 0.01763\n",
      "Training epoch: 2361, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2362, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2363, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2364, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2365, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2366, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2367, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2368, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2369, train loss: 0.01704, val loss: 0.01765\n",
      "Training epoch: 2370, train loss: 0.01699, val loss: 0.01758\n",
      "Training epoch: 2371, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2372, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2373, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2374, train loss: 0.01696, val loss: 0.01760\n",
      "Training epoch: 2375, train loss: 0.01697, val loss: 0.01755\n",
      "Training epoch: 2376, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2377, train loss: 0.01700, val loss: 0.01763\n",
      "Training epoch: 2378, train loss: 0.01699, val loss: 0.01764\n",
      "Training epoch: 2379, train loss: 0.01699, val loss: 0.01756\n",
      "Training epoch: 2380, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2381, train loss: 0.01698, val loss: 0.01762\n",
      "Training epoch: 2382, train loss: 0.01696, val loss: 0.01760\n",
      "Training epoch: 2383, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2384, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2385, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 2386, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2387, train loss: 0.01697, val loss: 0.01754\n",
      "Training epoch: 2388, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2389, train loss: 0.01697, val loss: 0.01761\n",
      "Training epoch: 2390, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2391, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2392, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2393, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2394, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2395, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2396, train loss: 0.01700, val loss: 0.01759\n",
      "Training epoch: 2397, train loss: 0.01701, val loss: 0.01765\n",
      "Training epoch: 2398, train loss: 0.01701, val loss: 0.01759\n",
      "Training epoch: 2399, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 2400, train loss: 0.01698, val loss: 0.01756\n",
      "Training epoch: 2401, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2402, train loss: 0.01697, val loss: 0.01761\n",
      "Training epoch: 2403, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2404, train loss: 0.01698, val loss: 0.01755\n",
      "Training epoch: 2405, train loss: 0.01701, val loss: 0.01766\n",
      "Training epoch: 2406, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 2407, train loss: 0.01700, val loss: 0.01766\n",
      "Training epoch: 2408, train loss: 0.01700, val loss: 0.01759\n",
      "Training epoch: 2409, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 2410, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2411, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 2412, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 2413, train loss: 0.01698, val loss: 0.01762\n",
      "Training epoch: 2414, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 2415, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2416, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2417, train loss: 0.01696, val loss: 0.01760\n",
      "Training epoch: 2418, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2419, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2420, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2421, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2422, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2423, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2424, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2425, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2426, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2427, train loss: 0.01697, val loss: 0.01754\n",
      "Training epoch: 2428, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2429, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2430, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2431, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2432, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2433, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2434, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2435, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2436, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2437, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2438, train loss: 0.01696, val loss: 0.01760\n",
      "Training epoch: 2439, train loss: 0.01698, val loss: 0.01756\n",
      "Training epoch: 2440, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2441, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2442, train loss: 0.01702, val loss: 0.01763\n",
      "Training epoch: 2443, train loss: 0.01699, val loss: 0.01755\n",
      "Training epoch: 2444, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 2445, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2446, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2447, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2448, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2449, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2450, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2451, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2452, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2453, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2454, train loss: 0.01697, val loss: 0.01754\n",
      "Training epoch: 2455, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2456, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2457, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 2458, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2459, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2460, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2461, train loss: 0.01697, val loss: 0.01759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 2462, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2463, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2464, train loss: 0.01699, val loss: 0.01762\n",
      "Training epoch: 2465, train loss: 0.01701, val loss: 0.01760\n",
      "Training epoch: 2466, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 2467, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 2468, train loss: 0.01696, val loss: 0.01760\n",
      "Training epoch: 2469, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2470, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2471, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2472, train loss: 0.01700, val loss: 0.01759\n",
      "Training epoch: 2473, train loss: 0.01700, val loss: 0.01764\n",
      "Training epoch: 2474, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2475, train loss: 0.01698, val loss: 0.01756\n",
      "Training epoch: 2476, train loss: 0.01705, val loss: 0.01770\n",
      "Training epoch: 2477, train loss: 0.01705, val loss: 0.01766\n",
      "Training epoch: 2478, train loss: 0.01704, val loss: 0.01765\n",
      "Training epoch: 2479, train loss: 0.01704, val loss: 0.01763\n",
      "Training epoch: 2480, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2481, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2482, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2483, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2484, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2485, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2486, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2487, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2488, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2489, train loss: 0.01697, val loss: 0.01761\n",
      "Training epoch: 2490, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2491, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2492, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2493, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2494, train loss: 0.01696, val loss: 0.01755\n",
      "Training epoch: 2495, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2496, train loss: 0.01701, val loss: 0.01764\n",
      "Training epoch: 2497, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 2498, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2499, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2500, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2501, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2502, train loss: 0.01696, val loss: 0.01754\n",
      "Training epoch: 2503, train loss: 0.01700, val loss: 0.01758\n",
      "Training epoch: 2504, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2505, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2506, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2507, train loss: 0.01696, val loss: 0.01760\n",
      "Training epoch: 2508, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2509, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2510, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2511, train loss: 0.01696, val loss: 0.01760\n",
      "Training epoch: 2512, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2513, train loss: 0.01696, val loss: 0.01755\n",
      "Training epoch: 2514, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2515, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2516, train loss: 0.01697, val loss: 0.01761\n",
      "Training epoch: 2517, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2518, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2519, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2520, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2521, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 2522, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2523, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2524, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2525, train loss: 0.01696, val loss: 0.01755\n",
      "Training epoch: 2526, train loss: 0.01696, val loss: 0.01760\n",
      "Training epoch: 2527, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2528, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2529, train loss: 0.01698, val loss: 0.01763\n",
      "Training epoch: 2530, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2531, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2532, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2533, train loss: 0.01695, val loss: 0.01756\n",
      "Training epoch: 2534, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2535, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2536, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2537, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2538, train loss: 0.01696, val loss: 0.01762\n",
      "Training epoch: 2539, train loss: 0.01700, val loss: 0.01759\n",
      "Training epoch: 2540, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2541, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2542, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 2543, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2544, train loss: 0.01698, val loss: 0.01755\n",
      "Training epoch: 2545, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2546, train loss: 0.01697, val loss: 0.01762\n",
      "Training epoch: 2547, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2548, train loss: 0.01697, val loss: 0.01754\n",
      "Training epoch: 2549, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2550, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2551, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2552, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2553, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2554, train loss: 0.01696, val loss: 0.01754\n",
      "Training epoch: 2555, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2556, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2557, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2558, train loss: 0.01696, val loss: 0.01760\n",
      "Training epoch: 2559, train loss: 0.01696, val loss: 0.01760\n",
      "Training epoch: 2560, train loss: 0.01698, val loss: 0.01756\n",
      "Training epoch: 2561, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 2562, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 2563, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2564, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2565, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2566, train loss: 0.01697, val loss: 0.01755\n",
      "Training epoch: 2567, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2568, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2569, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2570, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 2571, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2572, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2573, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2574, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2575, train loss: 0.01700, val loss: 0.01762\n",
      "Training epoch: 2576, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 2577, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2578, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2579, train loss: 0.01697, val loss: 0.01763\n",
      "Training epoch: 2580, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2581, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2582, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2583, train loss: 0.01699, val loss: 0.01761\n",
      "Training epoch: 2584, train loss: 0.01697, val loss: 0.01754\n",
      "Training epoch: 2585, train loss: 0.01697, val loss: 0.01761\n",
      "Training epoch: 2586, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2587, train loss: 0.01696, val loss: 0.01761\n",
      "Training epoch: 2588, train loss: 0.01696, val loss: 0.01755\n",
      "Training epoch: 2589, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2590, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2591, train loss: 0.01697, val loss: 0.01761\n",
      "Training epoch: 2592, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2593, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2594, train loss: 0.01696, val loss: 0.01760\n",
      "Training epoch: 2595, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2596, train loss: 0.01696, val loss: 0.01754\n",
      "Training epoch: 2597, train loss: 0.01696, val loss: 0.01757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 2598, train loss: 0.01697, val loss: 0.01761\n",
      "Training epoch: 2599, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2600, train loss: 0.01701, val loss: 0.01758\n",
      "Training epoch: 2601, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2602, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2603, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 2604, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2605, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2606, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2607, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2608, train loss: 0.01697, val loss: 0.01761\n",
      "Training epoch: 2609, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2610, train loss: 0.01701, val loss: 0.01760\n",
      "Training epoch: 2611, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 2612, train loss: 0.01699, val loss: 0.01758\n",
      "Training epoch: 2613, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2614, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2615, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2616, train loss: 0.01696, val loss: 0.01755\n",
      "Training epoch: 2617, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2618, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2619, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2620, train loss: 0.01696, val loss: 0.01754\n",
      "Training epoch: 2621, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2622, train loss: 0.01698, val loss: 0.01763\n",
      "Training epoch: 2623, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2624, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2625, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2626, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2627, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2628, train loss: 0.01695, val loss: 0.01758\n",
      "Training epoch: 2629, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2630, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2631, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 2632, train loss: 0.01700, val loss: 0.01759\n",
      "Training epoch: 2633, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2634, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2635, train loss: 0.01700, val loss: 0.01755\n",
      "Training epoch: 2636, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2637, train loss: 0.01696, val loss: 0.01760\n",
      "Training epoch: 2638, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2639, train loss: 0.01698, val loss: 0.01757\n",
      "Training epoch: 2640, train loss: 0.01695, val loss: 0.01756\n",
      "Training epoch: 2641, train loss: 0.01696, val loss: 0.01754\n",
      "Training epoch: 2642, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2643, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2644, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2645, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2646, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2647, train loss: 0.01702, val loss: 0.01761\n",
      "Training epoch: 2648, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2649, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2650, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2651, train loss: 0.01695, val loss: 0.01756\n",
      "Training epoch: 2652, train loss: 0.01695, val loss: 0.01756\n",
      "Training epoch: 2653, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2654, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2655, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2656, train loss: 0.01696, val loss: 0.01754\n",
      "Training epoch: 2657, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2658, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 2659, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2660, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2661, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2662, train loss: 0.01696, val loss: 0.01754\n",
      "Training epoch: 2663, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2664, train loss: 0.01695, val loss: 0.01759\n",
      "Training epoch: 2665, train loss: 0.01695, val loss: 0.01754\n",
      "Training epoch: 2666, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2667, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2668, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2669, train loss: 0.01698, val loss: 0.01756\n",
      "Training epoch: 2670, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2671, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2672, train loss: 0.01699, val loss: 0.01760\n",
      "Training epoch: 2673, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2674, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2675, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2676, train loss: 0.01696, val loss: 0.01760\n",
      "Training epoch: 2677, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2678, train loss: 0.01696, val loss: 0.01754\n",
      "Training epoch: 2679, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2680, train loss: 0.01696, val loss: 0.01760\n",
      "Training epoch: 2681, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2682, train loss: 0.01700, val loss: 0.01761\n",
      "Training epoch: 2683, train loss: 0.01699, val loss: 0.01759\n",
      "Training epoch: 2684, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2685, train loss: 0.01697, val loss: 0.01761\n",
      "Training epoch: 2686, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2687, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2688, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 2689, train loss: 0.01707, val loss: 0.01771\n",
      "Training epoch: 2690, train loss: 0.01709, val loss: 0.01763\n",
      "Training epoch: 2691, train loss: 0.01705, val loss: 0.01770\n",
      "Training epoch: 2692, train loss: 0.01709, val loss: 0.01770\n",
      "Training epoch: 2693, train loss: 0.01700, val loss: 0.01765\n",
      "Training epoch: 2694, train loss: 0.01698, val loss: 0.01758\n",
      "Training epoch: 2695, train loss: 0.01701, val loss: 0.01763\n",
      "Training epoch: 2696, train loss: 0.01704, val loss: 0.01764\n",
      "Training epoch: 2697, train loss: 0.01702, val loss: 0.01764\n",
      "Training epoch: 2698, train loss: 0.01701, val loss: 0.01762\n",
      "Training epoch: 2699, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2700, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2701, train loss: 0.01697, val loss: 0.01755\n",
      "Training epoch: 2702, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 2703, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2704, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 2705, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2706, train loss: 0.01695, val loss: 0.01758\n",
      "Training epoch: 2707, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2708, train loss: 0.01696, val loss: 0.01755\n",
      "Training epoch: 2709, train loss: 0.01696, val loss: 0.01760\n",
      "Training epoch: 2710, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2711, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2712, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2713, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2714, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2715, train loss: 0.01697, val loss: 0.01756\n",
      "Training epoch: 2716, train loss: 0.01696, val loss: 0.01761\n",
      "Training epoch: 2717, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2718, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2719, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2720, train loss: 0.01697, val loss: 0.01763\n",
      "Training epoch: 2721, train loss: 0.01697, val loss: 0.01762\n",
      "Training epoch: 2722, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2723, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2724, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2725, train loss: 0.01696, val loss: 0.01761\n",
      "Training epoch: 2726, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2727, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2728, train loss: 0.01698, val loss: 0.01762\n",
      "Training epoch: 2729, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2730, train loss: 0.01698, val loss: 0.01753\n",
      "Training epoch: 2731, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2732, train loss: 0.01698, val loss: 0.01765\n",
      "Training epoch: 2733, train loss: 0.01696, val loss: 0.01760\n",
      "Training epoch: 2734, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2735, train loss: 0.01696, val loss: 0.01757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 2736, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2737, train loss: 0.01696, val loss: 0.01762\n",
      "Training epoch: 2738, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2739, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2740, train loss: 0.01695, val loss: 0.01756\n",
      "Training epoch: 2741, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2742, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2743, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2744, train loss: 0.01698, val loss: 0.01759\n",
      "Training epoch: 2745, train loss: 0.01700, val loss: 0.01757\n",
      "Training epoch: 2746, train loss: 0.01697, val loss: 0.01760\n",
      "Training epoch: 2747, train loss: 0.01696, val loss: 0.01757\n",
      "Training epoch: 2748, train loss: 0.01697, val loss: 0.01758\n",
      "Training epoch: 2749, train loss: 0.01696, val loss: 0.01755\n",
      "Training epoch: 2750, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2751, train loss: 0.01697, val loss: 0.01755\n",
      "Training epoch: 2752, train loss: 0.01696, val loss: 0.01756\n",
      "Training epoch: 2753, train loss: 0.01697, val loss: 0.01759\n",
      "Training epoch: 2754, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2755, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2756, train loss: 0.01696, val loss: 0.01759\n",
      "Training epoch: 2757, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2758, train loss: 0.01696, val loss: 0.01760\n",
      "Training epoch: 2759, train loss: 0.01696, val loss: 0.01758\n",
      "Training epoch: 2760, train loss: 0.01698, val loss: 0.01760\n",
      "Training epoch: 2761, train loss: 0.01700, val loss: 0.01760\n",
      "Training epoch: 2762, train loss: 0.01698, val loss: 0.01761\n",
      "Training epoch: 2763, train loss: 0.01697, val loss: 0.01757\n",
      "Training epoch: 2764, train loss: 0.01697, val loss: 0.01761\n",
      "Training epoch: 2765, train loss: 0.01696, val loss: 0.01758\n",
      "Early stop at epoch 2765, With Testing Error: 0.01758\n",
      "Subnetwork pruning.\n",
      "Fine tuning.\n",
      "Tuning epoch: 1, train loss: 0.01700, val loss: 0.01760\n",
      "Tuning epoch: 2, train loss: 0.01698, val loss: 0.01757\n",
      "Tuning epoch: 3, train loss: 0.01699, val loss: 0.01759\n",
      "Tuning epoch: 4, train loss: 0.01699, val loss: 0.01757\n",
      "Tuning epoch: 5, train loss: 0.01700, val loss: 0.01756\n",
      "Tuning epoch: 6, train loss: 0.01699, val loss: 0.01757\n",
      "Tuning epoch: 7, train loss: 0.01699, val loss: 0.01761\n",
      "Tuning epoch: 8, train loss: 0.01699, val loss: 0.01757\n",
      "Tuning epoch: 9, train loss: 0.01699, val loss: 0.01757\n",
      "Tuning epoch: 10, train loss: 0.01699, val loss: 0.01759\n",
      "Tuning epoch: 11, train loss: 0.01699, val loss: 0.01758\n",
      "Tuning epoch: 12, train loss: 0.01698, val loss: 0.01757\n",
      "Tuning epoch: 13, train loss: 0.01698, val loss: 0.01758\n",
      "Tuning epoch: 14, train loss: 0.01699, val loss: 0.01757\n",
      "Tuning epoch: 15, train loss: 0.01699, val loss: 0.01758\n",
      "Tuning epoch: 16, train loss: 0.01699, val loss: 0.01760\n",
      "Tuning epoch: 17, train loss: 0.01700, val loss: 0.01760\n",
      "Tuning epoch: 18, train loss: 0.01700, val loss: 0.01760\n",
      "Tuning epoch: 19, train loss: 0.01699, val loss: 0.01756\n",
      "Tuning epoch: 20, train loss: 0.01699, val loss: 0.01760\n",
      "Tuning epoch: 21, train loss: 0.01700, val loss: 0.01760\n",
      "Tuning epoch: 22, train loss: 0.01699, val loss: 0.01757\n",
      "Tuning epoch: 23, train loss: 0.01698, val loss: 0.01758\n",
      "Tuning epoch: 24, train loss: 0.01699, val loss: 0.01757\n",
      "Tuning epoch: 25, train loss: 0.01701, val loss: 0.01758\n",
      "Tuning epoch: 26, train loss: 0.01700, val loss: 0.01761\n",
      "Tuning epoch: 27, train loss: 0.01699, val loss: 0.01758\n",
      "Tuning epoch: 28, train loss: 0.01700, val loss: 0.01759\n",
      "Tuning epoch: 29, train loss: 0.01699, val loss: 0.01759\n",
      "Tuning epoch: 30, train loss: 0.01699, val loss: 0.01757\n",
      "Tuning epoch: 31, train loss: 0.01700, val loss: 0.01757\n",
      "Tuning epoch: 32, train loss: 0.01701, val loss: 0.01762\n",
      "Tuning epoch: 33, train loss: 0.01699, val loss: 0.01760\n",
      "Tuning epoch: 34, train loss: 0.01701, val loss: 0.01755\n",
      "Tuning epoch: 35, train loss: 0.01698, val loss: 0.01758\n",
      "Tuning epoch: 36, train loss: 0.01700, val loss: 0.01759\n",
      "Tuning epoch: 37, train loss: 0.01699, val loss: 0.01757\n",
      "Tuning epoch: 38, train loss: 0.01699, val loss: 0.01756\n",
      "Tuning epoch: 39, train loss: 0.01699, val loss: 0.01759\n",
      "Tuning epoch: 40, train loss: 0.01699, val loss: 0.01756\n",
      "Tuning epoch: 41, train loss: 0.01700, val loss: 0.01759\n",
      "Tuning epoch: 42, train loss: 0.01700, val loss: 0.01760\n",
      "Tuning epoch: 43, train loss: 0.01700, val loss: 0.01758\n",
      "Tuning epoch: 44, train loss: 0.01699, val loss: 0.01757\n",
      "Tuning epoch: 45, train loss: 0.01699, val loss: 0.01759\n",
      "Tuning epoch: 46, train loss: 0.01698, val loss: 0.01758\n",
      "Tuning epoch: 47, train loss: 0.01699, val loss: 0.01757\n",
      "Tuning epoch: 48, train loss: 0.01699, val loss: 0.01756\n",
      "Tuning epoch: 49, train loss: 0.01698, val loss: 0.01758\n",
      "Tuning epoch: 50, train loss: 0.01703, val loss: 0.01761\n",
      "Tuning epoch: 51, train loss: 0.01706, val loss: 0.01765\n",
      "Tuning epoch: 52, train loss: 0.01701, val loss: 0.01760\n",
      "Tuning epoch: 53, train loss: 0.01699, val loss: 0.01756\n",
      "Tuning epoch: 54, train loss: 0.01700, val loss: 0.01761\n",
      "Tuning epoch: 55, train loss: 0.01700, val loss: 0.01759\n",
      "Tuning epoch: 56, train loss: 0.01700, val loss: 0.01758\n",
      "Tuning epoch: 57, train loss: 0.01701, val loss: 0.01759\n",
      "Tuning epoch: 58, train loss: 0.01699, val loss: 0.01756\n",
      "Tuning epoch: 59, train loss: 0.01699, val loss: 0.01759\n",
      "Tuning epoch: 60, train loss: 0.01698, val loss: 0.01757\n",
      "Tuning epoch: 61, train loss: 0.01698, val loss: 0.01757\n",
      "Tuning epoch: 62, train loss: 0.01699, val loss: 0.01759\n",
      "Tuning epoch: 63, train loss: 0.01699, val loss: 0.01757\n",
      "Tuning epoch: 64, train loss: 0.01700, val loss: 0.01758\n",
      "Tuning epoch: 65, train loss: 0.01701, val loss: 0.01760\n",
      "Tuning epoch: 66, train loss: 0.01699, val loss: 0.01760\n",
      "Tuning epoch: 67, train loss: 0.01700, val loss: 0.01757\n",
      "Tuning epoch: 68, train loss: 0.01699, val loss: 0.01755\n",
      "Tuning epoch: 69, train loss: 0.01699, val loss: 0.01759\n",
      "Tuning epoch: 70, train loss: 0.01699, val loss: 0.01756\n",
      "Tuning epoch: 71, train loss: 0.01698, val loss: 0.01756\n",
      "Tuning epoch: 72, train loss: 0.01700, val loss: 0.01762\n",
      "Tuning epoch: 73, train loss: 0.01698, val loss: 0.01756\n",
      "Tuning epoch: 74, train loss: 0.01699, val loss: 0.01759\n",
      "Tuning epoch: 75, train loss: 0.01699, val loss: 0.01759\n",
      "Tuning epoch: 76, train loss: 0.01700, val loss: 0.01756\n",
      "Tuning epoch: 77, train loss: 0.01699, val loss: 0.01760\n",
      "Tuning epoch: 78, train loss: 0.01698, val loss: 0.01755\n",
      "Tuning epoch: 79, train loss: 0.01699, val loss: 0.01759\n",
      "Tuning epoch: 80, train loss: 0.01702, val loss: 0.01760\n",
      "Tuning epoch: 81, train loss: 0.01701, val loss: 0.01761\n",
      "Tuning epoch: 82, train loss: 0.01699, val loss: 0.01758\n",
      "Tuning epoch: 83, train loss: 0.01699, val loss: 0.01759\n",
      "Tuning epoch: 84, train loss: 0.01699, val loss: 0.01756\n",
      "Tuning epoch: 85, train loss: 0.01700, val loss: 0.01759\n",
      "Tuning epoch: 86, train loss: 0.01704, val loss: 0.01761\n",
      "Tuning epoch: 87, train loss: 0.01704, val loss: 0.01768\n",
      "Tuning epoch: 88, train loss: 0.01702, val loss: 0.01761\n",
      "Tuning epoch: 89, train loss: 0.01699, val loss: 0.01758\n",
      "Tuning epoch: 90, train loss: 0.01701, val loss: 0.01759\n",
      "Tuning epoch: 91, train loss: 0.01700, val loss: 0.01760\n",
      "Tuning epoch: 92, train loss: 0.01701, val loss: 0.01761\n",
      "Tuning epoch: 93, train loss: 0.01700, val loss: 0.01760\n",
      "Tuning epoch: 94, train loss: 0.01699, val loss: 0.01756\n",
      "Tuning epoch: 95, train loss: 0.01698, val loss: 0.01758\n",
      "Tuning epoch: 96, train loss: 0.01699, val loss: 0.01758\n",
      "Tuning epoch: 97, train loss: 0.01699, val loss: 0.01756\n",
      "Tuning epoch: 98, train loss: 0.01699, val loss: 0.01756\n",
      "Tuning epoch: 99, train loss: 0.01699, val loss: 0.01762\n",
      "Tuning epoch: 100, train loss: 0.01700, val loss: 0.01759\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x2232 with 14 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = GAMNet(input_num=train_x.shape[1],\n",
    "               meta_info=meta_info,\n",
    "               subnet_arch=[10, 6],\n",
    "               task_type=task_type,\n",
    "               activation_func=tf.tanh,\n",
    "               batch_size=min(1000, int(train_x.shape[0] * 0.2)),\n",
    "               training_epochs=10000,\n",
    "               lr_bp=0.001,\n",
    "               beta_threshold=0.05,\n",
    "               tuning_epochs=100,\n",
    "               l1_subnet=0.001,\n",
    "               verbose=True,\n",
    "               val_ratio=0.2,\n",
    "               early_stop_thres=500)\n",
    "model.fit(train_x, train_y)\n",
    "model.visualize(\"./\", \"gamnet_demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.12661 1.1656  1.1016 ]\n"
     ]
    }
   ],
   "source": [
    "tr_pred = model.predict(model.tr_x) \n",
    "val_pred = model.predict(model.val_x) \n",
    "pred_test = model.predict(test_x)\n",
    "\n",
    "mse_stat = np.hstack([np.round(np.mean((meta_info[\"Y\"][\"scaler\"].inverse_transform(tr_pred) - meta_info[\"Y\"][\"scaler\"].inverse_transform(model.tr_y))**2),5),\\\n",
    "                             np.round(np.mean((meta_info[\"Y\"][\"scaler\"].inverse_transform(val_pred) - meta_info[\"Y\"][\"scaler\"].inverse_transform(model.val_y))**2),5),\\\n",
    "               np.round(np.mean((meta_info[\"Y\"][\"scaler\"].inverse_transform(pred_test) - meta_info[\"Y\"][\"scaler\"].inverse_transform(test_y))**2),5)])\n",
    "print(mse_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf2)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
