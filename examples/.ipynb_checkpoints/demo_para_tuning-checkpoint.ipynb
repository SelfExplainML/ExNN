{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo for hyperparameter tunning with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.lines as mlines\n",
    "from matplotlib import pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from xnn.sosxnn import SOSxNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation\n",
    "corr = 0.5\n",
    "noise_sigma = 1\n",
    "DummyNum = 0\n",
    "FeatureNum = 10\n",
    "TestNum = 10000\n",
    "DataNum = 10000\n",
    "\n",
    "# Optimization \n",
    "training_epochs = 10000\n",
    "num_cores = 10\n",
    "repeat_num = 10\n",
    "\n",
    "ortho_matrix = np.zeros((FeatureNum,4))\n",
    "ortho_matrix[:7, 0] = np.array([1,0,0,0,0,0,0])\n",
    "ortho_matrix[:7, 1] = np.array([0,1,0,0,0,0,0])\n",
    "ortho_matrix[:7, 2] = np.array([0,0,0.5,0.5,0,0,0])\n",
    "ortho_matrix[:7, 3] = np.array([0,0,0,0,0.2,0.3,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator1(DataNum, FeatureNum, corr, proj_matrix, noise_sigma):\n",
    "    u = np.random.uniform(-1,1, [DataNum, 1])\n",
    "    t= np.sqrt(corr/(1-corr))\n",
    "    X = np.zeros((DataNum, FeatureNum))\n",
    "    for i in range(FeatureNum):\n",
    "        X[:, i:i+1] = (np.random.uniform(-1,1,[DataNum,1])+t*u)/(1+t)\n",
    "    Y = np.reshape(2*np.dot(X, proj_matrix[:,0])+0.2*np.exp(-4*np.dot(X, proj_matrix[:,1])) + \\\n",
    "              3*(np.dot(X, proj_matrix[:,2]))**2+2.5*np.sin(np.pi*np.dot(X, proj_matrix[:,3])), [-1,1]) + \\\n",
    "              noise_sigma*np.random.normal(0,1, [DataNum,1])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X, Y = data_generator1(DataNum+TestNum, FeatureNum, corr, ortho_matrix, noise_sigma)\n",
    "scaler_x = MinMaxScaler((-1, 1)); scaler_y = MinMaxScaler((-1, 1))\n",
    "sX = scaler_x.fit_transform(X); sY = scaler_y.fit_transform(Y)\n",
    "train_x, test_x, train_y, test_y = train_test_split(sX, sY, test_size = TestNum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search in Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L1_Penalty_Subnet = [$10^{-1}, 10^{-2}, 10^{-3}$]\n",
    "- L1_Penalty_Proj = [$10^{-1}, 10^{-2}, 10^{-3}$]\n",
    "- Smooth_Labmda = [$10^{-5}, 10^{-6}, 10^{-7}$]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse(scaler_y):\n",
    "    def metric(label, pred):\n",
    "        pred = scaler_y.inverse_transform(pred)\n",
    "        label = scaler_y.inverse_transform(label)\n",
    "        return np.mean((pred - label)**2)\n",
    "    return metric\n",
    "\n",
    "def get_auc(label, pred):\n",
    "    return roc_auc_score\n",
    "\n",
    "def sosxnn_tune(simu_dir, task_name, train_x, train_y, test_x, test_y, metric=None,\n",
    "         input_dummy_num=0,\n",
    "         subnet_num=10,\n",
    "         subnet_arch=[10, 6],\n",
    "         task=\"Regression\",\n",
    "         activation_func=tf.tanh,\n",
    "         bn_flag=True,\n",
    "         lr_bp=0.001,\n",
    "         lr_cl=0.1,\n",
    "         l1_proj=0.001,\n",
    "         l1_subnet=0.001,\n",
    "         smooth_lambda=0.00001,\n",
    "         batch_size=1000,\n",
    "         training_epochs=10000,\n",
    "         tuning_epochs=500,\n",
    "         beta_threshold=0.01,\n",
    "         verbose=False,\n",
    "         val_ratio=0.2,\n",
    "         early_stop_thres=1000,\n",
    "         dummy_name=None):\n",
    "\n",
    "    np.random.seed(1)\n",
    "    tf.random.set_seed(1)\n",
    "    input_num = train_x.shape[1] - input_dummy_num\n",
    "    model = SOSxNN(input_num=input_num, \n",
    "                input_dummy_num=input_dummy_num,\n",
    "                subnet_num=min(input_num, 10), \n",
    "                subnet_arch=subnet_arch,\n",
    "                task=task,\n",
    "                activation_func=tf.tanh,\n",
    "                batch_size=batch_size,\n",
    "                training_epochs=training_epochs,\n",
    "                lr_bp=lr_bp,\n",
    "                lr_cl=lr_cl,\n",
    "                beta_threshold=beta_threshold,\n",
    "                tuning_epochs=tuning_epochs,\n",
    "                l1_proj=l1_proj,\n",
    "                l1_subnet=l1_subnet,\n",
    "                smooth_lambda=smooth_lambda,\n",
    "                verbose=True,\n",
    "                val_ratio=val_ratio,\n",
    "                early_stop_thres=early_stop_thres)\n",
    "    model.fit(train_x, train_y)  \n",
    "    model.visualize(folder=simu_dir + task_name + \"/\", \n",
    "              name=str(-np.log10(l1_proj)).zfill(2) + \"_\" + str(-np.log10(l1_subnet)).zfill(2) + \"_\" +\n",
    "                    str(-np.log10(smooth_lambda)).zfill(2), \n",
    "              dummy_name=dummy_name,\n",
    "              save_eps=False)\n",
    "    \n",
    "    tr_pred = model.predict(model.tr_x) \n",
    "    val_pred = model.predict(model.val_x) \n",
    "    pred_test = model.predict(test_x)\n",
    "\n",
    "    if task==\"Regression\":\n",
    "        stat = np.hstack([np.round(metric(model.tr_y, tr_pred),5),\\\n",
    "               np.round(metric(model.val_y, val_pred),5),\\\n",
    "               np.round(metric(test_y, pred_test),5)])\n",
    "    elif task==\"Classification\":\n",
    "        stat = np.hstack([np.round(metric(model.tr_y, tr_pred),5),\\\n",
    "               np.round(metric(model.val_y, val_pred),5),\\\n",
    "               np.round(metric(test_y, pred_test),5)])\n",
    "\n",
    "    res_stat = pd.DataFrame(np.vstack([stat[0],stat[1],stat[2]]).T, columns = ['train_metric', \"val_metric\", \"test_metric\"])\n",
    "    res_stat[\"Subnet_Number\"] = min(input_num, 10)\n",
    "    res_stat[\"lr_BP\"] = lr_bp\n",
    "    res_stat[\"lr_CL\"] = lr_cl\n",
    "    res_stat[\"L1_Penalty_Proj\"] = l1_proj\n",
    "    res_stat[\"L1_Penalty_Subnet\"] = l1_subnet\n",
    "    res_stat[\"Smooth_labmda\"] = smooth_lambda\n",
    "    res_stat[\"Training_Epochs\"] = training_epochs\n",
    "    return res_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_results = Parallel(n_jobs=14)(delayed(sosxnn_tune)(\"./results/\", \"S1_tune\", train_x, train_y, test_x, test_y,\\\n",
    "                                                      subnet_arch=[10,6], metric=get_mse(scaler_y), input_dummy_num=0,\\\n",
    "                      l1_proj=10**(-1-i), l1_subnet=10**(-1-j), smooth_lambda=10**(-5-k), \\\n",
    "                      training_epochs=5000, lr_bp=0.001, lr_cl=0.1, batch_size=1000, early_stop_thres=2500, tuning_epochs=200, \\\n",
    "                      dummy_name=None) for i in range(3) for j in range(3) for k in range(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_metric</th>\n",
       "      <th>val_metric</th>\n",
       "      <th>test_metric</th>\n",
       "      <th>Subnet_Number</th>\n",
       "      <th>lr_BP</th>\n",
       "      <th>lr_CL</th>\n",
       "      <th>L1_Penalty_Proj</th>\n",
       "      <th>L1_Penalty_Subnet</th>\n",
       "      <th>Smooth_labmda</th>\n",
       "      <th>Training_Epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.02050</td>\n",
       "      <td>1.03970</td>\n",
       "      <td>1.04613</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.02037</td>\n",
       "      <td>1.04259</td>\n",
       "      <td>1.04820</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.05516</td>\n",
       "      <td>1.08506</td>\n",
       "      <td>1.08603</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.05702</td>\n",
       "      <td>1.09011</td>\n",
       "      <td>1.08804</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.07874</td>\n",
       "      <td>1.10838</td>\n",
       "      <td>1.10596</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.08374</td>\n",
       "      <td>1.11091</td>\n",
       "      <td>1.10990</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.10265</td>\n",
       "      <td>1.13900</td>\n",
       "      <td>1.13743</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.10580</td>\n",
       "      <td>1.14341</td>\n",
       "      <td>1.13584</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.10691</td>\n",
       "      <td>1.14573</td>\n",
       "      <td>1.13758</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.10699</td>\n",
       "      <td>1.14689</td>\n",
       "      <td>1.13899</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.10753</td>\n",
       "      <td>1.14820</td>\n",
       "      <td>1.13923</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.11727</td>\n",
       "      <td>1.15083</td>\n",
       "      <td>1.14745</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.11368</td>\n",
       "      <td>1.15356</td>\n",
       "      <td>1.14436</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.11574</td>\n",
       "      <td>1.16032</td>\n",
       "      <td>1.14286</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.11708</td>\n",
       "      <td>1.16308</td>\n",
       "      <td>1.14401</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.11716</td>\n",
       "      <td>1.16315</td>\n",
       "      <td>1.14251</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.12833</td>\n",
       "      <td>1.16911</td>\n",
       "      <td>1.15601</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.13955</td>\n",
       "      <td>1.17279</td>\n",
       "      <td>1.16294</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.14599</td>\n",
       "      <td>1.18890</td>\n",
       "      <td>1.17114</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.15103</td>\n",
       "      <td>1.19408</td>\n",
       "      <td>1.17448</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.15738</td>\n",
       "      <td>1.20388</td>\n",
       "      <td>1.18097</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.19282</td>\n",
       "      <td>1.25441</td>\n",
       "      <td>1.21880</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.19503</td>\n",
       "      <td>1.25668</td>\n",
       "      <td>1.21812</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.19438</td>\n",
       "      <td>1.25883</td>\n",
       "      <td>1.21840</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.37266</td>\n",
       "      <td>1.38724</td>\n",
       "      <td>1.37162</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.37119</td>\n",
       "      <td>1.38942</td>\n",
       "      <td>1.37174</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.37979</td>\n",
       "      <td>1.39732</td>\n",
       "      <td>1.37723</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_metric  val_metric  test_metric  Subnet_Number  lr_BP  lr_CL  \\\n",
       "0       1.02050     1.03970      1.04613             10  0.001    0.1   \n",
       "0       1.02037     1.04259      1.04820             10  0.001    0.1   \n",
       "0       1.05516     1.08506      1.08603             10  0.001    0.1   \n",
       "0       1.05702     1.09011      1.08804             10  0.001    0.1   \n",
       "0       1.07874     1.10838      1.10596             10  0.001    0.1   \n",
       "0       1.08374     1.11091      1.10990             10  0.001    0.1   \n",
       "0       1.10265     1.13900      1.13743             10  0.001    0.1   \n",
       "0       1.10580     1.14341      1.13584             10  0.001    0.1   \n",
       "0       1.10691     1.14573      1.13758             10  0.001    0.1   \n",
       "0       1.10699     1.14689      1.13899             10  0.001    0.1   \n",
       "0       1.10753     1.14820      1.13923             10  0.001    0.1   \n",
       "0       1.11727     1.15083      1.14745             10  0.001    0.1   \n",
       "0       1.11368     1.15356      1.14436             10  0.001    0.1   \n",
       "0       1.11574     1.16032      1.14286             10  0.001    0.1   \n",
       "0       1.11708     1.16308      1.14401             10  0.001    0.1   \n",
       "0       1.11716     1.16315      1.14251             10  0.001    0.1   \n",
       "0       1.12833     1.16911      1.15601             10  0.001    0.1   \n",
       "0       1.13955     1.17279      1.16294             10  0.001    0.1   \n",
       "0       1.14599     1.18890      1.17114             10  0.001    0.1   \n",
       "0       1.15103     1.19408      1.17448             10  0.001    0.1   \n",
       "0       1.15738     1.20388      1.18097             10  0.001    0.1   \n",
       "0       1.19282     1.25441      1.21880             10  0.001    0.1   \n",
       "0       1.19503     1.25668      1.21812             10  0.001    0.1   \n",
       "0       1.19438     1.25883      1.21840             10  0.001    0.1   \n",
       "0       1.37266     1.38724      1.37162             10  0.001    0.1   \n",
       "0       1.37119     1.38942      1.37174             10  0.001    0.1   \n",
       "0       1.37979     1.39732      1.37723             10  0.001    0.1   \n",
       "\n",
       "   L1_Penalty_Proj  L1_Penalty_Subnet  Smooth_labmda  Training_Epochs  \n",
       "0            0.001              0.010   1.000000e-06             5000  \n",
       "0            0.001              0.010   1.000000e-05             5000  \n",
       "0            0.001              0.001   1.000000e-05             5000  \n",
       "0            0.001              0.010   1.000000e-07             5000  \n",
       "0            0.001              0.001   1.000000e-07             5000  \n",
       "0            0.001              0.001   1.000000e-06             5000  \n",
       "0            0.100              0.010   1.000000e-07             5000  \n",
       "0            0.100              0.010   1.000000e-06             5000  \n",
       "0            0.010              0.001   1.000000e-06             5000  \n",
       "0            0.010              0.010   1.000000e-07             5000  \n",
       "0            0.010              0.001   1.000000e-07             5000  \n",
       "0            0.010              0.001   1.000000e-05             5000  \n",
       "0            0.100              0.100   1.000000e-07             5000  \n",
       "0            0.010              0.010   1.000000e-05             5000  \n",
       "0            0.100              0.010   1.000000e-05             5000  \n",
       "0            0.010              0.010   1.000000e-06             5000  \n",
       "0            0.100              0.100   1.000000e-05             5000  \n",
       "0            0.100              0.001   1.000000e-05             5000  \n",
       "0            0.100              0.100   1.000000e-06             5000  \n",
       "0            0.100              0.001   1.000000e-07             5000  \n",
       "0            0.100              0.001   1.000000e-06             5000  \n",
       "0            0.010              0.100   1.000000e-07             5000  \n",
       "0            0.010              0.100   1.000000e-05             5000  \n",
       "0            0.010              0.100   1.000000e-06             5000  \n",
       "0            0.001              0.100   1.000000e-06             5000  \n",
       "0            0.001              0.100   1.000000e-05             5000  \n",
       "0            0.001              0.100   1.000000e-07             5000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat = pd.concat(cv_results)\n",
    "stat.sort_values(\"val_metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf2)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
